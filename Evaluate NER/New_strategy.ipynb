{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP version:  2.7.3\n",
      "Apache Spark version:  2.4.4\n"
     ]
    }
   ],
   "source": [
    "# call relevant packages\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.common import *\n",
    "from sparknlp.base import *\n",
    "\n",
    "import sparknlp\n",
    "\n",
    "# to use GPU \n",
    "spark = sparknlp.start()\n",
    "\n",
    "print(\"Spark NLP version: \", sparknlp.version())\n",
    "print(\"Apache Spark version: \", spark.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a composite CoNLL file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the training file\n",
    "with open(\"/Users/ramybal/Downloads/bio/train/onto.bn.ner\") as fp:\n",
    "    text = fp.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\".join(text[1:]).split(\"\\n\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This\\tDT\\t(TOP(S(NP*)\\tO\\nis\\tVBZ\\t(VP*\\tO\\nThe\\tDT\\t(NP(NP*\\tB-ORG\\nWorld\\tNNP\\t*)\\tI-ORG\\n,\\t,\\t*\\tO\\na\\tDT\\t(NP(NP*\\tO\\nco-production\\tNN\\t*)\\tO\\nof\\tIN\\t(PP*\\tO\\nthe\\tDT\\t(NP(NP*\\tB-ORG\\nBBC\\tNNP\\t*\\tI-ORG\\nWorld\\tNNP\\t*\\tI-ORG\\nService\\tNNP\\t*)\\tI-ORG\\n,\\t,\\t*\\tO\\nPRI\\tNNP\\t(NP*)\\tB-ORG\\n,\\t,\\t*\\tO\\nand\\tCC\\t*\\tO\\nWGBH\\tNNP\\t(NP(NP*)\\tB-ORG\\nin\\tIN\\t(PP*\\tO\\nBoston\\tNNP\\t(NP*))))))))\\tB-GPE\\n.\\t.\\t*))\\tO',\n",
       " 'I\\tPRP\\t(TOP(S(NP*)\\tO\\nam\\tVBP\\t(VP*\\tO\\nLisa\\tNNP\\t(NP*\\tB-PERSON\\nMullins\\tNNP\\t*))\\tI-PERSON\\n.\\t.\\t*))\\tO',\n",
       " \"A\\tDT\\t(TOP(S(NP*\\tO\\nplan\\tNN\\t*)\\tO\\nwas\\tVBD\\t(VP*\\tO\\nannounced\\tVBN\\t(VP*\\tO\\ntoday\\tNN\\t(NP*)\\tB-DATE\\nto\\tTO\\t(S(VP*\\tO\\nraise\\tVB\\t(VP*\\tO\\nthe\\tDT\\t(NP(NP*\\tO\\nRussian\\tJJ\\t*\\tB-NORP\\nnuclear\\tJJ\\t*\\tO\\nsubmarine\\tNN\\t*)\\tO\\n`\\t''\\t(NP*\\tO\\nKursk\\tNNP\\t*\\tB-PRODUCT\\n'\\t''\\t*))\\tO\\n,\\t,\\t*\\tO\\nnext\\tJJ\\t(NP(NP*\\tB-DATE\\nsummer\\tNN\\t*)\\tI-DATE\\n,\\t,\\t*\\tO\\nalmost\\tRB\\t(SBAR(NP(QP*\\tB-DATE\\na\\tDT\\t*)\\tI-DATE\\nyear\\tNN\\t*)\\tI-DATE\\nafter\\tIN\\t*\\tO\\nit\\tPRP\\t(S(NP*)\\tO\\nhit\\tVBD\\t(VP*\\tO\\nthe\\tDT\\t(NP(NP*\\tO\\nbottom\\tNN\\t*)\\tO\\nof\\tIN\\t(PP*\\tO\\nthe\\tDT\\t(NP*\\tB-LOC\\nBarents\\tNNP\\t*\\tI-LOC\\nSea\\tNNP\\t*)))\\tI-LOC\\nfollowing\\tVBG\\t(PP*\\tO\\na\\tDT\\t(NP*\\tO\\nmysterious\\tJJ\\t*\\tO\\naccident\\tNN\\t*)))))))))))\\tO\\n.\\t.\\t*))\\tO\",\n",
       " 'The\\tDT\\t(TOP(S(NP(NP*\\tB-ORG\\nKursk\\tNNP\\t*\\tI-ORG\\nFoundation\\tNNP\\t*)\\tI-ORG\\n,\\t,\\t*\\tO\\nan\\tDT\\t(NP(NP*\\tO\\ninternational\\tJJ\\t*\\tO\\nconsortium\\tNN\\t*)\\tO\\nled\\tVBN\\t(VP*\\tO\\nby\\tIN\\t(PP*\\tO\\nthe\\tDT\\t(NP(NP*\\tO\\ngovernments\\tNNS\\t*)\\tO\\nof\\tIN\\t(PP*\\tO\\nRussia\\tNNP\\t(NP(NP*)\\tB-GPE\\nand\\tCC\\t*\\tO\\nThe\\tDT\\t(NP*\\tB-GPE\\nNetherlands\\tNNP\\t*))))))))\\tI-GPE\\nsays\\tVBZ\\t(VP*\\tO\\nit\\tPRP\\t(SBAR(S(NP*)\\tO\\ncan\\tMD\\t(VP*\\tO\\ndo\\tVB\\t(VP*\\tO\\nthe\\tDT\\t(NP*\\tO\\njob\\tNN\\t*)\\tO\\nsafely\\tRB\\t(ADVP*)\\tO\\nif\\tIN\\t(SBAR*\\tO\\nit\\tPRP\\t(S(NP*)\\tO\\ncan\\tMD\\t(VP*\\tO\\nsecure\\tVB\\t(VP*\\tO\\nthe\\tDT\\t(NP*\\tO\\nfunding\\tNN\\t*))))))))))\\tO\\n.\\t.\\t*))\\tO',\n",
       " \"The\\tDT\\t(TOP(S(NP(NP*\\tO\\nBBC\\tNNP\\t*\\tB-ORG\\n's\\tPOS\\t*)\\tO\\nJames\\tNNP\\t*\\tB-PERSON\\nRogers\\tNNP\\t*)\\tI-PERSON\\nwas\\tVBD\\t(VP*\\tO\\nin\\tIN\\t(PP*\\tO\\nBrussels\\tNNP\\t(NP*))\\tB-GPE\\nfor\\tIN\\t(PP*\\tO\\ntoday\\tNN\\t(NP(NP*\\tB-DATE\\n's\\tPOS\\t*)\\tO\\nannouncement\\tNN\\t*)))\\tO\\n.\\t.\\t*))\\tO\",\n",
       " 'He\\tPRP\\t(TOP(S(NP*)\\tO\\nsays\\tVBZ\\t(VP*\\tO\\nthere\\tEX\\t(SBAR(S(NP*)\\tO\\nare\\tVBP\\t(VP*\\tO\\ntwo\\tCD\\t(NP(NP*\\tB-CARDINAL\\nmain\\tJJ\\t*\\tO\\nreasons\\tNNS\\t*)\\tO\\nfor\\tIN\\t(PP*\\tO\\nraising\\tVBG\\t(S(VP*\\tO\\nthe\\tDT\\t(NP*\\tO\\nKursk\\tNNP\\t*)))))))))\\tB-PRODUCT\\n.\\t.\\t*))\\tO',\n",
       " 'Obviously\\tRB\\t(TOP(S(ADVP*)\\tO\\nthe\\tDT\\t(NP*\\tO\\nfirst\\tJJ\\t*\\tB-ORDINAL\\none\\tNN\\t*)\\tO\\nis\\tVBZ\\t(VP*\\tO\\nto\\tTO\\t(S(VP*\\tO\\nrecover\\tVB\\t(VP*\\tO\\nthe\\tDT\\t(NP(NP*\\tO\\nbodies\\tNNS\\t*)\\tO\\nthat\\tWDT\\t(SBAR(WHNP*)\\tO\\nremain\\tVBP\\t(S(VP*))))))))\\tO\\n.\\t.\\t*))\\tO',\n",
       " 'There\\tEX\\t(TOP(S(NP*)\\tO\\nare\\tVBP\\t(VP*\\tO\\nstill\\tRB\\t(ADVP*)\\tO\\nthe\\tDT\\t(NP(NP(NP*\\tO\\nbodies\\tNNS\\t*)\\tO\\nof\\tIN\\t(PP*\\tO\\nmore\\tJJR\\t(NP(QP*\\tB-CARDINAL\\nthan\\tIN\\t*\\tI-CARDINAL\\n100\\tCD\\t*)\\tI-CARDINAL\\nsailors\\tNNS\\t*)))\\tO\\ntrapped\\tVBN\\t(VP*\\tO\\nin\\tIN\\t(PP*\\tO\\nthe\\tDT\\t(NP*\\tO\\nvessel\\tNN\\t*))\\tO\\nsince\\tIN\\t(SBAR*\\tO\\nit\\tPRP\\t(S(NP*)\\tO\\nsank\\tVBD\\t(VP*\\tO\\nin\\tIN\\t(PP*\\tO\\nthe\\tDT\\t(NP*\\tB-LOC\\nBarents\\tNNP\\t*\\tI-LOC\\nSea\\tNNP\\t*))\\tI-LOC\\nin\\tIN\\t(PP*\\tO\\nAugust\\tNNP\\t(NP(NP*)\\tB-DATE\\nof\\tIN\\t(PP*\\tI-DATE\\nlast\\tJJ\\t(NP*\\tI-DATE\\nyear\\tNN\\t*))))))))))\\tI-DATE\\n.\\t.\\t*))\\tO',\n",
       " \"Secondly\\tRB\\t(TOP(S(ADVP*)\\tB-ORDINAL\\n,\\t,\\t*\\tO\\nthere\\tEX\\t(S(NP*)\\tO\\nis\\tVBZ\\t(VP*\\tO\\na\\tDT\\t(NP*\\tO\\nlonger\\tJJR\\t(NML*\\tO\\n-\\tHYPH\\t*\\tO\\nterm\\tNN\\t*)\\tO\\nthreat\\tNN\\t*)))\\tO\\nand\\tCC\\t*\\tO\\nthat\\tDT\\t(S(NP*)\\tO\\n's\\tVBZ\\t(VP*\\tO\\nan\\tDT\\t(NP*\\tO\\nenvironmental\\tJJ\\t*\\tO\\nthreat\\tNN\\t*)))\\tO\\n.\\t.\\t*))\\tO\",\n",
       " 'The\\tDT\\t(TOP(S(NP*\\tB-ORG\\nKursk\\tNNP\\t*\\tI-ORG\\nFoundation\\tNNP\\t*)\\tI-ORG\\nsays\\tVBZ\\t(VP*\\tO\\nthat\\tIN\\t(SBAR(SBAR*\\tO\\nthe\\tDT\\t(S(NP(NP*\\tO\\nnuclear\\tJJ\\t*\\tO\\nreactors\\tNNS\\t*)\\tO\\n,\\t,\\t*\\tO\\nthere\\tEX\\t(PRN(S(NP*)\\tO\\nare\\tVBP\\t(VP*\\tO\\ntwo\\tCD\\t(NP(NP*)\\tB-CARDINAL\\non\\tIN\\t(PP*\\tO\\nboard\\tNN\\t(NP*)))))))\\tO\\n,\\t,\\t*\\tO\\nare\\tVBP\\t(VP*\\tO\\nsafe\\tJJ\\t(ADJP*\\tO\\nfor\\tIN\\t(PP*\\tO\\nthe\\tDT\\t(NP*\\tO\\ntime\\tNN\\t*\\tO\\nbeing\\tNN\\t*))))))\\tO\\nbut\\tCC\\t*\\tO\\nthat\\tIN\\t(SBAR*\\tO\\nthe\\tDT\\t(S(NP(NP*\\tO\\ncorrosive\\tJJ\\t*\\tO\\neffects\\tNNS\\t*)\\tO\\nof\\tIN\\t(PP*\\tO\\nseawater\\tNN\\t(NP*)))\\tO\\ncould\\tMD\\t(VP*\\tO\\nin\\tIN\\t(PP*\\tO\\ntime\\tNN\\t(NP*))\\tO\\nlead\\tVB\\t(VP*\\tO\\nto\\tIN\\t(PP*\\tO\\nradioactive\\tJJ\\t(NP(NP(NP*\\tO\\nleaks\\tNNS\\t*)\\tO\\ninto\\tIN\\t(PP*\\tO\\nthe\\tDT\\t(NP*\\tO\\nocean\\tNN\\t*)))\\tO\\n,\\t,\\t*\\tO\\nwhich\\tWDT\\t(SBAR(WHNP*)\\tO\\nobviously\\tRB\\t(S(ADVP*)\\tO\\ncould\\tMD\\t(VP*\\tO\\nhave\\tVB\\t(VP*\\tO\\ndevastating\\tJJ\\t(NP(NP*\\tO\\nconsequences\\tNNS\\t*)\\tO\\non\\tIN\\t(PP*\\tO\\nthe\\tDT\\t(NP(NP*\\tO\\nfishery\\tNN\\t*)\\tO\\nand\\tCC\\t*\\tO\\nthe\\tDT\\t(NP(NP*\\tO\\nenvironment\\tNN\\t*)\\tO\\nin\\tIN\\t(PP*\\tO\\ngeneral\\tJJ\\t(ADJP*))))))))))))))))))\\tO\\n.\\t.\\t*))\\tO']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame([x.split('\\t') for x in text[1].split('\\n')], columns=[\"Token\",\"Pos\",\"Pos_special\",\"Entity_label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Pos_special</th>\n",
       "      <th>Entity_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I</td>\n",
       "      <td>PRP</td>\n",
       "      <td>(TOP(S(NP*)</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>am</td>\n",
       "      <td>VBP</td>\n",
       "      <td>(VP*</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lisa</td>\n",
       "      <td>NNP</td>\n",
       "      <td>(NP*</td>\n",
       "      <td>B-PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mullins</td>\n",
       "      <td>NNP</td>\n",
       "      <td>*))</td>\n",
       "      <td>I-PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>*))</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Token  Pos  Pos_special Entity_label\n",
       "0        I  PRP  (TOP(S(NP*)            O\n",
       "1       am  VBP         (VP*            O\n",
       "2     Lisa  NNP         (NP*     B-PERSON\n",
       "3  Mullins  NNP          *))     I-PERSON\n",
       "4        .    .          *))            O"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10487"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the training data\n",
    "conll_lines = \"-DOCSTART- -X- -X- -O-\\n\\n\"\n",
    "for t in range(len(text)):    \n",
    "    df = pd.DataFrame([x.split('\\t') for x in text[t].split('\\n') if len(x.split('\\t')) == 4], columns=[\"Token\",\"Pos\",\"Pos_special\",\"Entity_label\"])\n",
    "    tokens = df.Token.tolist()\n",
    "    pos_labels = df.Pos.tolist()\n",
    "    entity_labels = df.Entity_label.tolist()\n",
    "    for token, pos, label in zip(tokens,pos_labels,entity_labels):\n",
    "        conll_lines += \"{} {} {} {}\\n\".format(token, pos, pos, label)\n",
    "    conll_lines += \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding other news files\n",
    "with open(\"/Users/ramybal/Downloads/bio/train/onto.mz.ner\") as fp:\n",
    "    text = fp.readlines()\n",
    "text = \"\".join(text[1:]).split(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7321"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(len(text)):    \n",
    "    df = pd.DataFrame([x.split('\\t') for x in text[t].split('\\n') if len(x.split('\\t')) == 4], columns=[\"Token\",\"Pos\",\"Pos_special\",\"Entity_label\"])\n",
    "    tokens = df.Token.tolist()\n",
    "    pos_labels = df.Pos.tolist()\n",
    "    entity_labels = df.Entity_label.tolist()\n",
    "    for token, pos, label in zip(tokens,pos_labels,entity_labels):\n",
    "        conll_lines += \"{} {} {} {}\\n\".format(token, pos, pos, label)\n",
    "    conll_lines += \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding other news files\n",
    "with open(\"/Users/ramybal/Downloads/bio/train/onto.nw.ner\") as fp:\n",
    "    text = fp.readlines()\n",
    "text = \"\".join(text[1:]).split(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16034"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(len(text)):    \n",
    "    df = pd.DataFrame([x.split('\\t') for x in text[t].split('\\n') if len(x.split('\\t')) == 4], columns=[\"Token\",\"Pos\",\"Pos_special\",\"Entity_label\"])\n",
    "    tokens = df.Token.tolist()\n",
    "    pos_labels = df.Pos.tolist()\n",
    "    entity_labels = df.Entity_label.tolist()\n",
    "    for token, pos, label in zip(tokens,pos_labels,entity_labels):\n",
    "        conll_lines += \"{} {} {} {}\\n\".format(token, pos, pos, label)\n",
    "    conll_lines += \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding broadcasting file\n",
    "with open(\"/Users/ramybal/Downloads/bio/train/onto.bc.ner\") as fp:\n",
    "    text = fp.readlines()\n",
    "text = \"\".join(text[1:]).split(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10713"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(len(text)):    \n",
    "    df = pd.DataFrame([x.split('\\t') for x in text[t].split('\\n') if len(x.split('\\t')) == 4], columns=[\"Token\",\"Pos\",\"Pos_special\",\"Entity_label\"])\n",
    "    tokens = df.Token.tolist()\n",
    "    pos_labels = df.Pos.tolist()\n",
    "    entity_labels = df.Entity_label.tolist()\n",
    "    for token, pos, label in zip(tokens,pos_labels,entity_labels):\n",
    "        conll_lines += \"{} {} {} {}\\n\".format(token, pos, pos, label)\n",
    "    conll_lines += \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding telephonic conversation files\n",
    "with open(\"/Users/ramybal/Downloads/bio/train/onto.tc.ner\") as fp:\n",
    "    text = fp.readlines()\n",
    "text = \"\".join(text[1:]).split(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11273"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(len(text)):    \n",
    "    df = pd.DataFrame([x.split('\\t') for x in text[t].split('\\n') if len(x.split('\\t')) == 4], columns=[\"Token\",\"Pos\",\"Pos_special\",\"Entity_label\"])\n",
    "    tokens = df.Token.tolist()\n",
    "    pos_labels = df.Pos.tolist()\n",
    "    entity_labels = df.Entity_label.tolist()\n",
    "    for token, pos, label in zip(tokens,pos_labels,entity_labels):\n",
    "        conll_lines += \"{} {} {} {}\\n\".format(token, pos, pos, label)\n",
    "    conll_lines += \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding web log file\n",
    "with open(\"/Users/ramybal/Downloads/bio/train/onto.wb.ner\") as fp:\n",
    "    text = fp.readlines()\n",
    "text = \"\".join(text[1:]).split(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6585"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(len(text)):    \n",
    "    df = pd.DataFrame([x.split('\\t') for x in text[t].split('\\n') if len(x.split('\\t')) == 4], columns=[\"Token\",\"Pos\",\"Pos_special\",\"Entity_label\"])\n",
    "    tokens = df.Token.tolist()\n",
    "    pos_labels = df.Pos.tolist()\n",
    "    entity_labels = df.Entity_label.tolist()\n",
    "    for token, pos, label in zip(tokens,pos_labels,entity_labels):\n",
    "        conll_lines += \"{} {} {} {}\\n\".format(token, pos, pos, label)\n",
    "    conll_lines += \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/ramybal/Downloads/bio/train/sample.train\",\"w\") as fp:\n",
    "    for line in conll_lines:\n",
    "        fp.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import data in CONLL format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|            document|            sentence|               token|                 pos|               label|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|This is The World...|[[document, 0, 88...|[[document, 0, 88...|[[token, 0, 3, Th...|[[pos, 0, 3, DT, ...|[[named_entity, 0...|\n",
      "| I am Lisa Mullins .|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 0, I,...|[[pos, 0, 0, PRP,...|[[named_entity, 0...|\n",
      "|A plan was announ...|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 0, A,...|[[pos, 0, 0, DT, ...|[[named_entity, 0...|\n",
      "|The Kursk Foundat...|[[document, 0, 16...|[[document, 0, 16...|[[token, 0, 2, Th...|[[pos, 0, 2, DT, ...|[[named_entity, 0...|\n",
      "|The BBC 's James ...|[[document, 0, 66...|[[document, 0, 66...|[[token, 0, 2, Th...|[[pos, 0, 2, DT, ...|[[named_entity, 0...|\n",
      "|He says there are...|[[document, 0, 57...|[[document, 0, 57...|[[token, 0, 1, He...|[[pos, 0, 1, PRP,...|[[named_entity, 0...|\n",
      "|Obviously the fir...|[[document, 0, 61...|[[document, 0, 61...|[[token, 0, 8, Ob...|[[pos, 0, 8, RB, ...|[[named_entity, 0...|\n",
      "|There are still t...|[[document, 0, 13...|[[document, 0, 13...|[[token, 0, 4, Th...|[[pos, 0, 4, EX, ...|[[named_entity, 0...|\n",
      "|Secondly , there ...|[[document, 0, 79...|[[document, 0, 79...|[[token, 0, 7, Se...|[[pos, 0, 7, RB, ...|[[named_entity, 0...|\n",
      "|The Kursk Foundat...|[[document, 0, 30...|[[document, 0, 30...|[[token, 0, 2, Th...|[[pos, 0, 2, DT, ...|[[named_entity, 0...|\n",
      "|That 's the dange...|[[document, 0, 44...|[[document, 0, 44...|[[token, 0, 3, Th...|[[pos, 0, 3, DT, ...|[[named_entity, 0...|\n",
      "|I would think the...|[[document, 0, 56...|[[document, 0, 56...|[[token, 0, 0, I,...|[[pos, 0, 0, PRP,...|[[named_entity, 0...|\n",
      "|I mean this is a ...|[[document, 0, 32...|[[document, 0, 32...|[[token, 0, 0, I,...|[[pos, 0, 0, PRP,...|[[named_entity, 0...|\n",
      "|     That 's right .|[[document, 0, 14...|[[document, 0, 14...|[[token, 0, 3, Th...|[[pos, 0, 3, DT, ...|[[named_entity, 0...|\n",
      "|The size of these...|[[document, 0, 51...|[[document, 0, 51...|[[token, 0, 2, Th...|[[pos, 0, 2, DT, ...|[[named_entity, 0...|\n",
      "|In fact one of th...|[[document, 0, 10...|[[document, 0, 10...|[[token, 0, 1, In...|[[pos, 0, 1, IN, ...|[[named_entity, 0...|\n",
      "|Now , it 's lying...|[[document, 0, 15...|[[document, 0, 15...|[[token, 0, 2, No...|[[pos, 0, 2, UH, ...|[[named_entity, 0...|\n",
      "|It is a huge subm...|[[document, 0, 11...|[[document, 0, 11...|[[token, 0, 1, It...|[[pos, 0, 1, PRP,...|[[named_entity, 0...|\n",
      "|There are any num...|[[document, 0, 19...|[[document, 0, 19...|[[token, 0, 4, Th...|[[pos, 0, 4, EX, ...|[[named_entity, 0...|\n",
      "|Second problem , ...|[[document, 0, 77...|[[document, 0, 77...|[[token, 0, 5, Se...|[[pos, 0, 5, JJ, ...|[[named_entity, 0...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sparknlp.training import CoNLL\n",
    "\n",
    "training_data = CoNLL().readDataset(spark, '/Users/ramybal/Downloads/bio/train/sample.train')\n",
    "training_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model - 2 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_base_cased download started this may take some time.\n",
      "Approximate size to download 389.1 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "# initialize embeddings\n",
    "bert = BertEmbeddings.pretrained('bert_base_cased', 'en').setInputCols([\"sentence\",'token']).setOutputCol(\"bert\").setCaseSensitive(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming the training data into embeddings and saving it as parquet files\n",
    "readyTrainingData = bert.transform(training_data)\n",
    "\n",
    "readyTrainingData.write.mode(\"Overwrite\").parquet(\"/tmp/conll2003/bert_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "readyTrainingData = spark.read.parquet(\"/tmp/conll2003/bert_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize NER tagger\n",
    "nerTagger = NerDLApproach()\\\n",
    ".setInputCols([\"sentence\", \"token\", \"bert\"])\\\n",
    ".setLabelColumn(\"label\")\\\n",
    ".setOutputCol(\"ner\")\\\n",
    ".setMaxEpochs(2)\\\n",
    ".setBatchSize(2)\\\n",
    ".setEnableMemoryOptimizer(True)\\\n",
    ".setRandomSeed(0)\\\n",
    ".setVerbose(1)\\\n",
    ".setValidationSplit(0.2)\\\n",
    ".setEvaluationLogExtended(True)\\\n",
    ".setEnableOutputLogs(True)\\\n",
    ".setIncludeConfidence(True)\\\n",
    ".setTestDataset(\"test_withEmbeds.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first use-case with test data as news\n",
    "test = CoNLL().readDataset(spark, \"/Users/ramybal/Downloads/bio/test/sample.train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = bert.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.write.parquet(\"test_withEmbeds.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 335 ms, sys: 250 ms, total: 585 ms\n",
      "Wall time: 1h 14min 10s\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "%time myNerModel = nerTagger.fit(readyTrainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.41 s, sys: 1.93 s, total: 4.35 s\n",
      "Wall time: 4min 57s\n"
     ]
    }
   ],
   "source": [
    "# infer from the trained model\n",
    "%time results = myNerModel.transform(test).select(\"sentence\",\"token\",\"label\",\"ner\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to find exceptions where no. of labels does not match no. of ners detected\n",
    "count = 0\n",
    "indices = []\n",
    "for i,row in enumerate(results):\n",
    "    if len(row['label']) != len(row['ner']):\n",
    "        count += 1\n",
    "        indices.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3584, 3772]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclusion_list = [results[3584],results[3772]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [results[i] for i in range(len(results)) if i not in [3584, 3772]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "labels = []\n",
    "ners = []\n",
    "\n",
    "for row in results:\n",
    "    tokens.append([t['result'] for t in row['token']])\n",
    "    labels.append([t['result'] for t in row['label']])\n",
    "    ners.append([t['result'] for t in row['ner']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9577009353150293\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import accuracy_score, f1_score, classification_report\n",
    "print(accuracy_score(labels,ners))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7584643848288621\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(labels,ners))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    CARDINAL       0.79      0.81      0.80       935\n",
      "        DATE       0.81      0.75      0.78      1600\n",
      "       EVENT       0.50      0.25      0.34        63\n",
      "         FAC       0.69      0.18      0.28       135\n",
      "         GPE       0.80      0.86      0.83      2240\n",
      "    LANGUAGE       1.00      0.23      0.37        22\n",
      "         LAW       1.00      0.00      0.00        40\n",
      "         LOC       0.63      0.30      0.40       179\n",
      "       MONEY       0.87      0.84      0.86       314\n",
      "        NORP       0.79      0.79      0.79       841\n",
      "     ORDINAL       0.71      0.90      0.79       195\n",
      "         ORG       0.76      0.54      0.63      1791\n",
      "     PERCENT       0.85      0.86      0.86       346\n",
      "      PERSON       0.84      0.83      0.83      1988\n",
      "     PRODUCT       0.60      0.37      0.46        76\n",
      "    QUANTITY       0.55      0.57      0.56       105\n",
      "        TIME       0.53      0.45      0.49       212\n",
      " WORK_OF_ART       0.45      0.11      0.17       166\n",
      "\n",
      "   micro avg       0.79      0.73      0.76     11248\n",
      "   macro avg       0.73      0.54      0.57     11248\n",
      "weighted avg       0.78      0.73      0.75     11248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(labels,ners, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model - 3 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming the training data into embeddings and saving it as parquet files\n",
    "readyTrainingData = bert.transform(training_data)\n",
    "\n",
    "readyTrainingData.write.mode(\"Overwrite\").parquet(\"/tmp/conll2003/bert_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "readyTrainingData = spark.read.parquet(\"/tmp/conll2003/bert_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize NER tagger\n",
    "nerTagger = NerDLApproach()\\\n",
    ".setInputCols([\"sentence\", \"token\", \"bert\"])\\\n",
    ".setLabelColumn(\"label\")\\\n",
    ".setOutputCol(\"ner\")\\\n",
    ".setMaxEpochs(3)\\\n",
    ".setBatchSize(2)\\\n",
    ".setEnableMemoryOptimizer(True)\\\n",
    ".setRandomSeed(0)\\\n",
    ".setVerbose(1)\\\n",
    ".setValidationSplit(0.2)\\\n",
    ".setEvaluationLogExtended(True)\\\n",
    ".setEnableOutputLogs(True)\\\n",
    ".setIncludeConfidence(True)\\\n",
    ".setTestDataset(\"test_withEmbeds.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first use-case with test data as news\n",
    "test = CoNLL().readDataset(spark, \"/Users/ramybal/Downloads/bio/test/sample.train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = bert.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.write.parquet(\"test_withEmbeds.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 503 ms, sys: 371 ms, total: 874 ms\n",
      "Wall time: 1h 57min 38s\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "%time myNerModel = nerTagger.fit(readyTrainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.79 s, sys: 471 ms, total: 3.26 s\n",
      "Wall time: 5min 40s\n"
     ]
    }
   ],
   "source": [
    "# infer from the trained model\n",
    "%time results = myNerModel.transform(test).select(\"sentence\",\"token\",\"label\",\"ner\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to find exceptions where no. of labels does not match no. of ners detected\n",
    "count = 0\n",
    "indices = []\n",
    "for i,row in enumerate(results):\n",
    "    if len(row['label']) != len(row['ner']):\n",
    "        count += 1\n",
    "        indices.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[3584, 3772]\n"
     ]
    }
   ],
   "source": [
    "print(count)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclusion_list = [results[t] for t in indices]\n",
    "results = [results[i] for i in range(len(results)) if i not in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "labels = []\n",
    "ners = []\n",
    "\n",
    "for row in results:\n",
    "    tokens.append([t['result'] for t in row['token']])\n",
    "    labels.append([t['result'] for t in row['label']])\n",
    "    ners.append([t['result'] for t in row['ner']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9602327137253873\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import accuracy_score, f1_score, classification_report\n",
    "print(accuracy_score(labels,ners))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7764214729772657\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(labels,ners))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    CARDINAL       0.80      0.83      0.82       935\n",
      "        DATE       0.79      0.80      0.80      1600\n",
      "       EVENT       0.59      0.27      0.37        63\n",
      "         FAC       0.67      0.25      0.37       135\n",
      "         GPE       0.83      0.88      0.85      2240\n",
      "    LANGUAGE       1.00      0.18      0.31        22\n",
      "         LAW       1.00      0.00      0.00        40\n",
      "         LOC       0.66      0.41      0.50       179\n",
      "       MONEY       0.84      0.82      0.83       314\n",
      "        NORP       0.78      0.82      0.80       841\n",
      "     ORDINAL       0.73      0.89      0.80       195\n",
      "         ORG       0.73      0.62      0.67      1791\n",
      "     PERCENT       0.84      0.86      0.85       346\n",
      "      PERSON       0.85      0.82      0.84      1988\n",
      "     PRODUCT       0.65      0.32      0.42        76\n",
      "    QUANTITY       0.65      0.67      0.66       105\n",
      "        TIME       0.56      0.50      0.53       212\n",
      " WORK_OF_ART       0.35      0.04      0.08       166\n",
      "\n",
      "   micro avg       0.79      0.76      0.78     11248\n",
      "   macro avg       0.74      0.56      0.58     11248\n",
      "weighted avg       0.78      0.76      0.76     11248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(labels,ners, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onto_bert_base_cased download started this may take some time.\n",
      "Approximate size to download 15.5 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "ner_onto = NerDLModel.pretrained('onto_bert_base_cased', lang='en') \\\n",
    "        .setInputCols([\"sentence\", \"token\", \"bert\"])\\\n",
    "        .setOutputCol(\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the model\n",
    "myNerModel = ner_onto.transform(readyTrainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tabulate the results\n",
    "from sklearn.metrics import classification_report\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "results = myNerModel.select(\"sentence\",\"token\",\"label\",\"ner\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8262"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to find exceptions where no. of labels does not match no. of ners detected\n",
    "count = 0\n",
    "indices = []\n",
    "for i,row in enumerate(results):\n",
    "    if len(row['label']) != len(row['ner']):\n",
    "        count += 1\n",
    "        indices.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1519, 1707]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151\n",
      "115\n"
     ]
    }
   ],
   "source": [
    "print(len(results[1519]['label']))\n",
    "print(len(results[1519]['ner']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115\n",
      "107\n"
     ]
    }
   ],
   "source": [
    "print(len(results[1707]['label']))\n",
    "print(len(results[1707]['ner']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclusion_list = [results[1519],results[1707]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [results[i] for i in range(len(results)) if i not in [1519,1707]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "indices = []\n",
    "for i,row in enumerate(results):\n",
    "    if len(row['label']) != len(row['ner']):\n",
    "        count += 1\n",
    "        indices.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My\n",
      "brother\n",
      "Qais\n",
      ",\n",
      "the\n",
      "Son\n",
      "of\n",
      "his\n",
      "Father\n",
      ",\n",
      "I\n",
      "thank\n",
      "you\n",
      "for\n",
      "your\n",
      "post\n",
      "and\n",
      "the\n",
      "addition\n",
      ",\n",
      "may\n",
      "God\n",
      "take\n",
      "care\n",
      "of\n",
      "you\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for t in results[1]['token']:\n",
    "    print(t['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O\n",
      "O\n",
      "B-PERSON\n",
      "I-PERSON\n",
      "I-PERSON\n",
      "I-PERSON\n",
      "I-PERSON\n",
      "I-PERSON\n",
      "I-PERSON\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n"
     ]
    }
   ],
   "source": [
    "for t in results[1]['label']:\n",
    "    print(t['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O\n",
      "O\n",
      "B-PERSON\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n"
     ]
    }
   ],
   "source": [
    "for t in results[1]['ner']:\n",
    "    print(t['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "labels = []\n",
    "ners = []\n",
    "\n",
    "for row in results:\n",
    "    tokens.append([t['result'] for t in row['token']])\n",
    "    labels.append([t['result'] for t in row['label']])\n",
    "    ners.append([t['result'] for t in row['ner']])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9132833099395259\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import accuracy_score, f1_score, classification_report\n",
    "print(accuracy_score(labels,ners))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48666707161513695\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(labels,ners))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    CARDINAL       0.79      0.88      0.83       935\n",
      "        DATE       0.83      0.68      0.75      1600\n",
      "       EVENT       0.50      0.05      0.09        63\n",
      "         FAC       0.17      0.01      0.01       135\n",
      "         GPE       0.81      0.14      0.24      2240\n",
      "    LANGUAGE       1.00      0.00      0.00        22\n",
      "         LAW       1.00      0.03      0.05        40\n",
      "         LOC       0.48      0.08      0.13       179\n",
      "       MONEY       0.85      0.86      0.85       314\n",
      "        NORP       0.63      0.23      0.34       841\n",
      "     ORDINAL       0.65      0.90      0.76       195\n",
      "         ORG       0.53      0.12      0.19      1791\n",
      "     PERCENT       0.90      0.88      0.89       346\n",
      "      PERSON       0.85      0.19      0.31      1988\n",
      "     PRODUCT       0.57      0.05      0.10        76\n",
      "    QUANTITY       0.77      0.82      0.80       105\n",
      "        TIME       0.59      0.61      0.60       212\n",
      " WORK_OF_ART       0.77      0.06      0.11       166\n",
      "\n",
      "   micro avg       0.77      0.36      0.49     11248\n",
      "   macro avg       0.70      0.37      0.39     11248\n",
      "weighted avg       0.74      0.36      0.42     11248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(labels,ners, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use pre-trained model with pipeline (bert and NER model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_pipeline = Pipeline(stages=[bert,ner_onto])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 166 µs, sys: 198 µs, total: 364 µs\n",
      "Wall time: 359 µs\n"
     ]
    }
   ],
   "source": [
    "%time myNerModel = nlp_pipeline.fit(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.5 s, sys: 235 ms, total: 2.74 s\n",
      "Wall time: 4min 34s\n"
     ]
    }
   ],
   "source": [
    "%time results = myNerModel.transform(training_data).select(\"sentence\",\"token\",\"label\",\"ner\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to find exceptions where no. of labels does not match no. of ners detected\n",
    "count = 0\n",
    "indices = []\n",
    "for i,row in enumerate(results):\n",
    "    if len(row['label']) != len(row['ner']):\n",
    "        count += 1\n",
    "        indices.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3584, 3772]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8262"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclusion_list = [results[3584],results[3772]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [results[i] for i in range(len(results)) if i not in [3584,3772]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "labels = []\n",
    "ners = []\n",
    "\n",
    "for row in results:\n",
    "    tokens.append([t['result'] for t in row['token']])\n",
    "    labels.append([t['result'] for t in row['label']])\n",
    "    ners.append([t['result'] for t in row['ner']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9132833099395259\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import accuracy_score, f1_score, classification_report\n",
    "print(accuracy_score(labels,ners))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48666707161513695\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(labels,ners))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    CARDINAL       0.79      0.88      0.83       935\n",
      "        DATE       0.83      0.68      0.75      1600\n",
      "       EVENT       0.50      0.05      0.09        63\n",
      "         FAC       0.17      0.01      0.01       135\n",
      "         GPE       0.81      0.14      0.24      2240\n",
      "    LANGUAGE       1.00      0.00      0.00        22\n",
      "         LAW       1.00      0.03      0.05        40\n",
      "         LOC       0.48      0.08      0.13       179\n",
      "       MONEY       0.85      0.86      0.85       314\n",
      "        NORP       0.63      0.23      0.34       841\n",
      "     ORDINAL       0.65      0.90      0.76       195\n",
      "         ORG       0.53      0.12      0.19      1791\n",
      "     PERCENT       0.90      0.88      0.89       346\n",
      "      PERSON       0.85      0.19      0.31      1988\n",
      "     PRODUCT       0.57      0.05      0.10        76\n",
      "    QUANTITY       0.77      0.82      0.80       105\n",
      "        TIME       0.59      0.61      0.60       212\n",
      " WORK_OF_ART       0.77      0.06      0.11       166\n",
      "\n",
      "   micro avg       0.77      0.36      0.49     11248\n",
      "   macro avg       0.70      0.37      0.39     11248\n",
      "weighted avg       0.74      0.36      0.42     11248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(classification_report(labels,ners, zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-LANGUAGE', 'I-ORDINAL'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([l for label in labels for l in label]) - set([n for ner in ners for n in ner])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use pre-trained Small BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onto_small_bert_L4_512 download started this may take some time.\n",
      "Approximate size to download 14.8 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "ner_onto = NerDLModel.pretrained('onto_small_bert_L4_512', lang='en') \\\n",
    "        .setInputCols([\"sentence\", \"token\", \"bert\"])\\\n",
    "        .setOutputCol(\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small_bert_L4_512 download started this may take some time.\n",
      "Approximate size to download 104 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "# use small bert embeddings\n",
    "bert = BertEmbeddings.pretrained('small_bert_L4_512', 'en').setInputCols([\"sentence\",'token']).setOutputCol(\"bert\").setCaseSensitive(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_pipeline = Pipeline(stages=[bert,ner_onto])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 156 µs, sys: 81 µs, total: 237 µs\n",
      "Wall time: 211 µs\n"
     ]
    }
   ],
   "source": [
    "%time myNerModel = nlp_pipeline.fit(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.54 s, sys: 1.2 s, total: 4.74 s\n",
      "Wall time: 1min 31s\n"
     ]
    }
   ],
   "source": [
    "%time results = myNerModel.transform(test).select(\"sentence\",\"token\",\"label\",\"ner\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to find exceptions where no. of labels does not match no. of ners detected\n",
    "count = 0\n",
    "indices = []\n",
    "for i,row in enumerate(results):\n",
    "    if len(row['label']) != len(row['ner']):\n",
    "        count += 1\n",
    "        indices.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[3584, 3772]\n"
     ]
    }
   ],
   "source": [
    "print(count)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclusion_list = [results[t] for t in indices]\n",
    "results = [results[i] for i in range(len(results)) if i not in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "labels = []\n",
    "ners = []\n",
    "\n",
    "for row in results:\n",
    "    tokens.append([t['result'] for t in row['token']])\n",
    "    labels.append([t['result'] for t in row['label']])\n",
    "    ners.append([t['result'] for t in row['ner']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9709960514751217\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import accuracy_score, f1_score, classification_report\n",
    "print(accuracy_score(labels,ners))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8455879074330048\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(labels,ners))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    CARDINAL       0.84      0.86      0.85       935\n",
      "        DATE       0.81      0.87      0.84      1600\n",
      "       EVENT       0.45      0.33      0.38        63\n",
      "         FAC       0.65      0.57      0.61       135\n",
      "         GPE       0.94      0.92      0.93      2240\n",
      "    LANGUAGE       0.91      0.45      0.61        22\n",
      "         LAW       0.65      0.28      0.39        40\n",
      "         LOC       0.68      0.64      0.66       179\n",
      "       MONEY       0.85      0.86      0.86       314\n",
      "        NORP       0.89      0.91      0.90       841\n",
      "     ORDINAL       0.77      0.89      0.83       195\n",
      "         ORG       0.81      0.76      0.79      1791\n",
      "     PERCENT       0.90      0.90      0.90       346\n",
      "      PERSON       0.89      0.91      0.90      1988\n",
      "     PRODUCT       0.62      0.42      0.50        76\n",
      "    QUANTITY       0.76      0.76      0.76       105\n",
      "        TIME       0.56      0.56      0.56       212\n",
      " WORK_OF_ART       0.56      0.35      0.43       166\n",
      "\n",
      "   micro avg       0.85      0.84      0.85     11248\n",
      "   macro avg       0.75      0.68      0.70     11248\n",
      "weighted avg       0.85      0.84      0.84     11248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(classification_report(labels,ners, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use pre-trained Electra model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onto_electra_large_uncased download started this may take some time.\n",
      "Approximate size to download 16.2 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "ner_onto = NerDLModel.pretrained('onto_electra_large_uncased', lang='en') \\\n",
    "        .setInputCols([\"sentence\", \"token\", \"bert\"])\\\n",
    "        .setOutputCol(\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "electra_large_uncased download started this may take some time.\n",
      "Approximate size to download 1.2 GB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "# use elctra embeddings\n",
    "electra = BertEmbeddings.pretrained('electra_large_uncased', 'en').setInputCols([\"sentence\",'token']).setOutputCol(\"bert\").setCaseSensitive(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_pipeline = Pipeline(stages=[electra,ner_onto])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 293 µs, sys: 941 µs, total: 1.23 ms\n",
      "Wall time: 1.47 ms\n"
     ]
    }
   ],
   "source": [
    "%time myNerModel = nlp_pipeline.fit(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.97 s, sys: 1.2 s, total: 4.17 s\n",
      "Wall time: 22min 58s\n"
     ]
    }
   ],
   "source": [
    "%time results = myNerModel.transform(test).select(\"sentence\",\"token\",\"label\",\"ner\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to find exceptions where no. of labels does not match no. of ners detected\n",
    "count = 0\n",
    "indices = []\n",
    "for i,row in enumerate(results):\n",
    "    if len(row['label']) != len(row['ner']):\n",
    "        count += 1\n",
    "        indices.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[3584, 3772]\n"
     ]
    }
   ],
   "source": [
    "print(count)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclusion_list = [results[t] for t in indices]\n",
    "results = [results[i] for i in range(len(results)) if i not in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "labels = []\n",
    "ners = []\n",
    "\n",
    "for row in results:\n",
    "    tokens.append([t['result'] for t in row['token']])\n",
    "    labels.append([t['result'] for t in row['label']])\n",
    "    ners.append([t['result'] for t in row['ner']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9760530492844118\n",
      "0.8774337268879482\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(labels,ners))\n",
    "print(f1_score(labels,ners))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    CARDINAL       0.84      0.84      0.84       935\n",
      "        DATE       0.85      0.87      0.86      1600\n",
      "       EVENT       0.71      0.46      0.56        63\n",
      "         FAC       0.63      0.53      0.58       135\n",
      "         GPE       0.95      0.95      0.95      2240\n",
      "    LANGUAGE       1.00      0.36      0.53        22\n",
      "         LAW       0.62      0.50      0.56        40\n",
      "         LOC       0.61      0.69      0.65       179\n",
      "       MONEY       0.89      0.91      0.90       314\n",
      "        NORP       0.87      0.95      0.91       841\n",
      "     ORDINAL       0.81      0.91      0.86       195\n",
      "         ORG       0.89      0.84      0.86      1791\n",
      "     PERCENT       0.90      0.88      0.89       346\n",
      "      PERSON       0.93      0.94      0.94      1988\n",
      "     PRODUCT       0.77      0.63      0.70        76\n",
      "    QUANTITY       0.77      0.81      0.79       105\n",
      "        TIME       0.68      0.61      0.65       212\n",
      " WORK_OF_ART       0.64      0.46      0.54       166\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     11248\n",
      "   macro avg       0.80      0.73      0.75     11248\n",
      "weighted avg       0.88      0.88      0.88     11248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(labels,ners, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use pre-trained transformer model with BERT, this time casesensitive is True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onto_bert_base_cased download started this may take some time.\n",
      "Approximate size to download 15.5 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "ner_onto = NerDLModel.pretrained('onto_bert_base_cased', lang='en') \\\n",
    "        .setInputCols([\"sentence\", \"token\", \"bert\"])\\\n",
    "        .setOutputCol(\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_base_cased download started this may take some time.\n",
      "Approximate size to download 389.1 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "# use bert embeddings\n",
    "bert = BertEmbeddings.pretrained('bert_base_cased', 'en').setInputCols([\"sentence\",'token']).setOutputCol(\"bert\").setCaseSensitive(True)#.setMaxSentenceLength(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_pipeline = Pipeline(stages=[bert,ner_onto])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 743 µs, sys: 453 µs, total: 1.2 ms\n",
      "Wall time: 849 µs\n"
     ]
    }
   ],
   "source": [
    "%time myNerModel = nlp_pipeline.fit(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.65 s, sys: 839 ms, total: 3.49 s\n",
      "Wall time: 4min 48s\n"
     ]
    }
   ],
   "source": [
    "%time results = myNerModel.transform(test).select(\"sentence\",\"token\",\"label\",\"ner\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to find exceptions where no. of labels does not match no. of ners detected\n",
    "count = 0\n",
    "indices = []\n",
    "for i,row in enumerate(results):\n",
    "    if len(row['label']) != len(row['ner']):\n",
    "        count += 1\n",
    "        indices.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(count)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclusion_list = [results[t] for t in indices]\n",
    "results = [results[i] for i in range(len(results)) if i not in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "labels = []\n",
    "ners = []\n",
    "\n",
    "for row in results:\n",
    "    tokens.append([t['result'] for t in row['token']])\n",
    "    labels.append([t['result'] for t in row['label']])\n",
    "    ners.append([t['result'] for t in row['ner']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.979728667958724\n",
      "0.8860354556360244\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(labels,ners))\n",
    "print(f1_score(labels,ners))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    CARDINAL   0.832827  0.879144  0.855359       935\n",
      "        DATE   0.865262  0.845818  0.855429      1602\n",
      "       EVENT   0.540984  0.523810  0.532258        63\n",
      "         FAC   0.780488  0.711111  0.744186       135\n",
      "         GPE   0.969266  0.943304  0.956109      2240\n",
      "    LANGUAGE   0.909091  0.454545  0.606061        22\n",
      "         LAW   0.785714  0.550000  0.647059        40\n",
      "         LOC   0.796610  0.787709  0.792135       179\n",
      "       MONEY   0.862500  0.878981  0.870662       314\n",
      "        NORP   0.942217  0.950059  0.946122       841\n",
      "     ORDINAL   0.815668  0.907692  0.859223       195\n",
      "         ORG   0.865071  0.885794  0.875310      1795\n",
      "     PERCENT   0.889535  0.876791  0.883117       349\n",
      "      PERSON   0.934617  0.927565  0.931078      1988\n",
      "     PRODUCT   0.710526  0.710526  0.710526        76\n",
      "    QUANTITY   0.813084  0.828571  0.820755       105\n",
      "        TIME   0.663551  0.669811  0.666667       212\n",
      " WORK_OF_ART   0.577778  0.626506  0.601156       166\n",
      "\n",
      "   micro avg   0.886311  0.885760  0.886035     11257\n",
      "   macro avg   0.808599  0.775430  0.786290     11257\n",
      "weighted avg   0.887357  0.885760  0.886128     11257\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(labels,ners, zero_division=1,digits=6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(classification_report(labels,ners, zero_division=1,digits=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n    CARDINAL   0.832827  0.879144  0.855359       935\\n        DATE   0.865262  0.845818  0.855429      1602\\n       EVENT   0.540984  0.523810  0.532258        63\\n         FAC   0.780488  0.711111  0.744186       135\\n         GPE   0.969266  0.943304  0.956109      2240\\n    LANGUAGE   0.909091  0.454545  0.606061        22\\n         LAW   0.785714  0.550000  0.647059        40\\n         LOC   0.796610  0.787709  0.792135       179\\n       MONEY   0.862500  0.878981  0.870662       314\\n        NORP   0.942217  0.950059  0.946122       841\\n     ORDINAL   0.815668  0.907692  0.859223       195\\n         ORG   0.865071  0.885794  0.875310      1795\\n     PERCENT   0.889535  0.876791  0.883117       349\\n      PERSON   0.934617  0.927565  0.931078      1988\\n     PRODUCT   0.710526  0.710526  0.710526        76\\n    QUANTITY   0.813084  0.828571  0.820755       105\\n        TIME   0.663551  0.669811  0.666667       212\\n WORK_OF_ART   0.577778  0.626506  0.601156       166\\n\\n   micro avg   0.886311  0.885760  0.886035     11257\\n   macro avg   0.808599  0.775430  0.786290     11257\\nweighted avg   0.887357  0.885760  0.886128     11257\\n'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(labels,ners, zero_division=1,digits=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = classification_report(labels,ners, zero_division=1,digits=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.split(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = []\n",
    "for t in text[0].strip().split(\"  \"):\n",
    "    if t == \"\":\n",
    "        continue\n",
    "    else:\n",
    "        columns.append(t.strip())\n",
    "columns = [\"entity-type\"] + columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['entity-type', 'precision', 'recall', 'f1-score', 'support']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rows = []\n",
    "for sent in text[1].strip().split(\"\\n\"):\n",
    "    temp = sent.split(\" \")\n",
    "    if \"\" in temp:\n",
    "        while \"\" in temp:\n",
    "            temp.remove(\"\")\n",
    "    new_rows.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_rows =[]\n",
    "for sent in text[2].strip().split(\"\\n\"):\n",
    "    temp = sent.split(\"  \")\n",
    "    if \"\" in temp:\n",
    "        while \"\" in temp:\n",
    "            temp.remove(\"\")\n",
    "    last_rows.append([t.strip() for t in temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['CARDINAL', '0.832827', '0.879144', '0.855359', '935'],\n",
       " ['DATE', '0.865262', '0.845818', '0.855429', '1602'],\n",
       " ['EVENT', '0.540984', '0.523810', '0.532258', '63'],\n",
       " ['FAC', '0.780488', '0.711111', '0.744186', '135'],\n",
       " ['GPE', '0.969266', '0.943304', '0.956109', '2240'],\n",
       " ['LANGUAGE', '0.909091', '0.454545', '0.606061', '22'],\n",
       " ['LAW', '0.785714', '0.550000', '0.647059', '40'],\n",
       " ['LOC', '0.796610', '0.787709', '0.792135', '179'],\n",
       " ['MONEY', '0.862500', '0.878981', '0.870662', '314'],\n",
       " ['NORP', '0.942217', '0.950059', '0.946122', '841'],\n",
       " ['ORDINAL', '0.815668', '0.907692', '0.859223', '195'],\n",
       " ['ORG', '0.865071', '0.885794', '0.875310', '1795'],\n",
       " ['PERCENT', '0.889535', '0.876791', '0.883117', '349'],\n",
       " ['PERSON', '0.934617', '0.927565', '0.931078', '1988'],\n",
       " ['PRODUCT', '0.710526', '0.710526', '0.710526', '76'],\n",
       " ['QUANTITY', '0.813084', '0.828571', '0.820755', '105'],\n",
       " ['TIME', '0.663551', '0.669811', '0.666667', '212'],\n",
       " ['WORK_OF_ART', '0.577778', '0.626506', '0.601156', '166']]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['micro avg', '0.886311', '0.885760', '0.886035', '11257'],\n",
       " ['macro avg', '0.808599', '0.775430', '0.786290', '11257'],\n",
       " ['weighted avg', '0.887357', '0.885760', '0.886128', '11257']]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(new_rows + last_rows, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity-type</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CARDINAL</td>\n",
       "      <td>0.832827</td>\n",
       "      <td>0.879144</td>\n",
       "      <td>0.855359</td>\n",
       "      <td>935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DATE</td>\n",
       "      <td>0.865262</td>\n",
       "      <td>0.845818</td>\n",
       "      <td>0.855429</td>\n",
       "      <td>1602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EVENT</td>\n",
       "      <td>0.540984</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.532258</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FAC</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.744186</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GPE</td>\n",
       "      <td>0.969266</td>\n",
       "      <td>0.943304</td>\n",
       "      <td>0.956109</td>\n",
       "      <td>2240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LANGUAGE</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LAW</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LOC</td>\n",
       "      <td>0.796610</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MONEY</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>0.878981</td>\n",
       "      <td>0.870662</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NORP</td>\n",
       "      <td>0.942217</td>\n",
       "      <td>0.950059</td>\n",
       "      <td>0.946122</td>\n",
       "      <td>841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ORDINAL</td>\n",
       "      <td>0.815668</td>\n",
       "      <td>0.907692</td>\n",
       "      <td>0.859223</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ORG</td>\n",
       "      <td>0.865071</td>\n",
       "      <td>0.885794</td>\n",
       "      <td>0.875310</td>\n",
       "      <td>1795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PERCENT</td>\n",
       "      <td>0.889535</td>\n",
       "      <td>0.876791</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PERSON</td>\n",
       "      <td>0.934617</td>\n",
       "      <td>0.927565</td>\n",
       "      <td>0.931078</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PRODUCT</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>QUANTITY</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.820755</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>TIME</td>\n",
       "      <td>0.663551</td>\n",
       "      <td>0.669811</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>WORK_OF_ART</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>0.626506</td>\n",
       "      <td>0.601156</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>micro avg</td>\n",
       "      <td>0.886311</td>\n",
       "      <td>0.885760</td>\n",
       "      <td>0.886035</td>\n",
       "      <td>11257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.808599</td>\n",
       "      <td>0.775430</td>\n",
       "      <td>0.786290</td>\n",
       "      <td>11257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>weighted avg</td>\n",
       "      <td>0.887357</td>\n",
       "      <td>0.885760</td>\n",
       "      <td>0.886128</td>\n",
       "      <td>11257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     entity-type precision    recall  f1-score support\n",
       "0       CARDINAL  0.832827  0.879144  0.855359     935\n",
       "1           DATE  0.865262  0.845818  0.855429    1602\n",
       "2          EVENT  0.540984  0.523810  0.532258      63\n",
       "3            FAC  0.780488  0.711111  0.744186     135\n",
       "4            GPE  0.969266  0.943304  0.956109    2240\n",
       "5       LANGUAGE  0.909091  0.454545  0.606061      22\n",
       "6            LAW  0.785714  0.550000  0.647059      40\n",
       "7            LOC  0.796610  0.787709  0.792135     179\n",
       "8          MONEY  0.862500  0.878981  0.870662     314\n",
       "9           NORP  0.942217  0.950059  0.946122     841\n",
       "10       ORDINAL  0.815668  0.907692  0.859223     195\n",
       "11           ORG  0.865071  0.885794  0.875310    1795\n",
       "12       PERCENT  0.889535  0.876791  0.883117     349\n",
       "13        PERSON  0.934617  0.927565  0.931078    1988\n",
       "14       PRODUCT  0.710526  0.710526  0.710526      76\n",
       "15      QUANTITY  0.813084  0.828571  0.820755     105\n",
       "16          TIME  0.663551  0.669811  0.666667     212\n",
       "17   WORK_OF_ART  0.577778  0.626506  0.601156     166\n",
       "18     micro avg  0.886311  0.885760  0.886035   11257\n",
       "19     macro avg  0.808599  0.775430  0.786290   11257\n",
       "20  weighted avg  0.887357  0.885760  0.886128   11257"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv(\"/Users/ramybal/Desktop/temp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
