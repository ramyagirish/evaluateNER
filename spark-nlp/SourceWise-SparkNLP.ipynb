{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP version:  3.1.2\n",
      "Apache Spark version:  3.1.2\n"
     ]
    }
   ],
   "source": [
    "# call relevant packages\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "import sparknlp\n",
    "\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.common import *\n",
    "from sparknlp.base import *\n",
    "from sparknlp.training import CoNLL\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# to use GPU \n",
    "spark = sparknlp.start()\n",
    "\n",
    "print(\"Spark NLP version: \", sparknlp.version())\n",
    "print(\"Apache Spark version: \", spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHANGE THESE APPROPRIATELY EACH TIME YOU WANT TO DO BLACKBOX TESTING OF A TEST SET\n",
    "inputdir = '/home/bangaru/Downloads/NERProject2021/conll-2012-share/bio/test/'\n",
    "outputdir = '/home/bangaru/Downloads/NERProject2021/spark-format-test'\n",
    "testfiles = ['onto.bn.ner', 'onto.bc.ner', 'onto.mz.ner', 'onto.nw.ner', 'onto.tc.ner', 'onto.wb.ner']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converts our regular CONLL files to SparkNLP's CONLL format\n",
    "def convert_format(inputpath, outputpath):\n",
    "    # create the training file\n",
    "    with open(inputpath) as fp:\n",
    "        text = fp.readlines()\n",
    "    text = \"\".join(text[1:]).split(\"\\n\\n\") \n",
    "    df = pd.DataFrame([x.split('\\t') for x in text[1].split('\\n')], \n",
    "                      columns=[\"Token\",\"Pos\",\"Pos_special\",\"Entity_label\"])\n",
    "    \n",
    "    # creating the training data\n",
    "    conll_lines = \"-DOCSTART- -X- -X- -O-\\n\\n\"\n",
    "    for t in range(len(text)):    \n",
    "        df = pd.DataFrame([x.split('\\t') for x in text[t].split('\\n') if len(x.split('\\t')) == 4], columns=[\"Token\",\"Pos\",\"Pos_special\",\"Entity_label\"])\n",
    "        tokens = df.Token.tolist()\n",
    "        pos_labels = df.Pos.tolist()\n",
    "        entity_labels = df.Entity_label.tolist()\n",
    "        for token, pos, label in zip(tokens,pos_labels,entity_labels):\n",
    "            conll_lines += \"{} {} {} {}\\n\".format(token, pos, pos, label)\n",
    "        conll_lines += \"\\n\"\n",
    "        \n",
    "    with open(outputpath,\"w\") as fp:\n",
    "        for line in conll_lines:\n",
    "            fp.write(line)\n",
    "    \n",
    "    print(\"Done\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#Convert all test files into SparkNLP's expected CONLL format.\n",
    "for testfile in testfiles:\n",
    "    convert_format(os.path.join(base_path,testfile), os.path.join(outputdir,testfile))#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_base_cased download started this may take some time.\n",
      "Approximate size to download 389.1 MB\n",
      "[OK!]\n",
      "onto_bert_base_cased download started this may take some time.\n",
      "Approximate size to download 15.5 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "#Set up the NER model\n",
    "bert = BertEmbeddings.pretrained('bert_base_cased', 'en').setInputCols([\"sentence\",'token']).setOutputCol(\"bert\").setCaseSensitive(True).setMaxSentenceLength(512)\n",
    "ner_onto = NerDLModel.pretrained('onto_bert_base_cased', lang='en') \\\n",
    "        .setInputCols([\"sentence\", \"token\", \"bert\"])\\\n",
    "        .setOutputCol(\"ner\")\n",
    "\n",
    "nlp_pipeline = Pipeline(stages=[bert,ner_onto])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(testfile):\n",
    "    test_data = CoNLL().readDataset(spark, testfile)\n",
    "    myNerModel = nlp_pipeline.fit(test_data)\n",
    "    results = myNerModel.transform(test_data).select(\"sentence\",\"token\",\"label\",\"ner\").collect()\n",
    "    \n",
    "    #test_data.show()\n",
    "    \n",
    "    # to find exceptions where no. of labels does not match no. of ners detected\n",
    "    count = 0\n",
    "    indices = []\n",
    "    for i,row in enumerate(results):\n",
    "        if len(row['label']) != len(row['ner']):\n",
    "            count += 1\n",
    "            indices.append(i)\n",
    "\n",
    "    print(count)\n",
    "    print(indices)\n",
    "\n",
    "    exclusion_list = [results[t] for t in indices]\n",
    "    results = [results[i] for i in range(len(results)) if i not in indices]\n",
    "    \n",
    "    tokens = []\n",
    "    labels = []\n",
    "    ners = []\n",
    "\n",
    "    for row in results:\n",
    "        tokens.append([t['result'] for t in row['token']])\n",
    "        labels.append([t['result'] for t in row['label']])\n",
    "        ners.append([t['result'] for t in row['ner']])\n",
    "\n",
    "    from seqeval.metrics import accuracy_score, f1_score, classification_report\n",
    "    #print(accuracy_score(labels,ners))\n",
    "    #print(f1_score(labels,ners))\n",
    "\n",
    "    print(classification_report(labels,ners, zero_division=1,digits=6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bangaru/Downloads/NERProject2021/spark-format-test/onto.bn.ner\n",
      "0\n",
      "[]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    CARDINAL   0.841176  0.905063  0.871951       158\n",
      "        DATE   0.885417  0.864407  0.874786       295\n",
      "       EVENT   0.777778  0.466667  0.583333        15\n",
      "         FAC   0.772727  0.586207  0.666667        29\n",
      "         GPE   0.980263  0.967532  0.973856       462\n",
      "    LANGUAGE   1.000000  0.600000  0.750000         5\n",
      "         LAW   1.000000  1.000000  1.000000         4\n",
      "         LOC   0.850000  0.871795  0.860759        39\n",
      "       MONEY   0.894737  0.850000  0.871795        20\n",
      "        NORP   0.964539  0.974910  0.969697       279\n",
      "     ORDINAL   0.791667  0.883721  0.835165        43\n",
      "         ORG   0.858268  0.882591  0.870259       247\n",
      "     PERCENT   0.833333  0.833333  0.833333         6\n",
      "      PERSON   0.964444  0.977477  0.970917       444\n",
      "     PRODUCT   0.755556  0.790698  0.772727        43\n",
      "    QUANTITY   0.875000  0.636364  0.736842        11\n",
      "        TIME   0.586207  0.693878  0.635514        49\n",
      " WORK_OF_ART   0.625000  0.714286  0.666667        35\n",
      "\n",
      "   micro avg   0.905540  0.913004  0.909257      2184\n",
      "   macro avg   0.847562  0.805496  0.819126      2184\n",
      "weighted avg   0.907588  0.913004  0.909293      2184\n",
      "\n",
      "**************\n",
      "/home/bangaru/Downloads/NERProject2021/spark-format-test/onto.bc.ner\n",
      "0\n",
      "[]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    CARDINAL   0.767677  0.835165  0.800000       182\n",
      "        DATE   0.819209  0.725000  0.769231       200\n",
      "       EVENT   0.416667  0.357143  0.384615        14\n",
      "         FAC   0.956522  0.916667  0.936170        48\n",
      "         GPE   0.971264  0.957507  0.964337       353\n",
      "         LAW   1.000000  0.333333  0.500000         3\n",
      "         LOC   0.760000  0.730769  0.745098        26\n",
      "       MONEY   0.750000  1.000000  0.857143         3\n",
      "        NORP   0.936620  0.963768  0.950000       138\n",
      "     ORDINAL   0.903846  0.940000  0.921569        50\n",
      "         ORG   0.817568  0.790850  0.803987       153\n",
      "     PERCENT   1.000000  1.000000  1.000000        14\n",
      "      PERSON   0.940874  0.958115  0.949416       382\n",
      "    QUANTITY   0.925000  0.925000  0.925000        40\n",
      "        TIME   0.737705  0.714286  0.725806        63\n",
      " WORK_OF_ART   0.410256  0.571429  0.477612        28\n",
      "\n",
      "   micro avg   0.876179  0.875663  0.875921      1697\n",
      "   macro avg   0.819575  0.794939  0.794374      1697\n",
      "weighted avg   0.878658  0.875663  0.876008      1697\n",
      "\n",
      "**************\n",
      "/home/bangaru/Downloads/NERProject2021/spark-format-test/onto.mz.ner\n",
      "0\n",
      "[]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    CARDINAL   0.810606  0.862903  0.835938       124\n",
      "        DATE   0.725191  0.879630  0.794979       108\n",
      "       EVENT   0.555556  0.625000  0.588235         8\n",
      "         FAC   0.571429  0.615385  0.592593        13\n",
      "         GPE   0.982143  0.914127  0.946915       361\n",
      "    LANGUAGE   0.500000  1.000000  0.666667         1\n",
      "         LAW   0.000000  0.000000  0.000000         1\n",
      "         LOC   0.888889  0.727273  0.800000        33\n",
      "       MONEY   0.631579  0.666667  0.648649        18\n",
      "        NORP   0.950617  0.974684  0.962500        79\n",
      "     ORDINAL   0.884615  0.958333  0.920000        24\n",
      "         ORG   0.837209  0.872727  0.854599       165\n",
      "     PERCENT   0.833333  0.833333  0.833333        12\n",
      "      PERSON   0.919786  0.955556  0.937330       180\n",
      "     PRODUCT   0.000000  1.000000  0.000000         0\n",
      "    QUANTITY   0.800000  0.750000  0.774194        16\n",
      "        TIME   0.600000  0.818182  0.692308        11\n",
      " WORK_OF_ART   0.500000  0.111111  0.181818         9\n",
      "\n",
      "   micro avg   0.869198  0.885641  0.877342      1163\n",
      "   macro avg   0.666164  0.753606  0.668336      1163\n",
      "weighted avg   0.877381  0.885641  0.878751      1163\n",
      "\n",
      "**************\n",
      "/home/bangaru/Downloads/NERProject2021/spark-format-test/onto.nw.ner\n",
      "0\n",
      "[]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    CARDINAL   0.887640  0.946108  0.915942       334\n",
      "        DATE   0.913939  0.886016  0.899761       851\n",
      "       EVENT   0.529412  0.642857  0.580645        14\n",
      "         FAC   0.625000  0.625000  0.625000        24\n",
      "         GPE   0.965812  0.940547  0.953012       841\n",
      "    LANGUAGE   1.000000  0.250000  0.400000         4\n",
      "         LAW   0.800000  0.516129  0.627451        31\n",
      "         LOC   0.776316  0.819444  0.797297        72\n",
      "       MONEY   0.905738  0.917012  0.911340       241\n",
      "        NORP   0.967593  0.945701  0.956522       221\n",
      "     ORDINAL   0.727273  0.941176  0.820513        51\n",
      "         ORG   0.904332  0.922652  0.913400      1086\n",
      "     PERCENT   0.930403  0.913669  0.921960       278\n",
      "      PERSON   0.931106  0.938947  0.935010       475\n",
      "     PRODUCT   0.730769  0.678571  0.703704        28\n",
      "    QUANTITY   0.805556  0.906250  0.852941        32\n",
      "        TIME   0.739130  0.739130  0.739130        46\n",
      " WORK_OF_ART   0.770492  0.701493  0.734375        67\n",
      "\n",
      "   micro avg   0.909866  0.909284  0.909575      4696\n",
      "   macro avg   0.828362  0.790595  0.793778      4696\n",
      "weighted avg   0.910923  0.909284  0.909316      4696\n",
      "\n",
      "**************\n",
      "/home/bangaru/Downloads/NERProject2021/spark-format-test/onto.tc.ner\n",
      "0\n",
      "[]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    CARDINAL   0.696429  0.750000  0.722222        52\n",
      "        DATE   0.819672  0.675676  0.740741        74\n",
      "       EVENT   0.000000  1.000000  0.000000         0\n",
      "         FAC   0.000000  0.000000  0.000000         3\n",
      "         GPE   0.940000  0.940000  0.940000        50\n",
      "    LANGUAGE   1.000000  0.500000  0.666667         8\n",
      "         LOC   0.000000  1.000000  0.000000         0\n",
      "       MONEY   0.600000  0.428571  0.500000         7\n",
      "        NORP   0.772727  1.000000  0.871795        17\n",
      "     ORDINAL   0.888889  0.888889  0.888889         9\n",
      "         ORG   0.764706  0.481481  0.590909        27\n",
      "     PERCENT   0.666667  0.666667  0.666667         6\n",
      "      PERSON   0.898148  0.970000  0.932692       100\n",
      "     PRODUCT   1.000000  0.250000  0.400000         4\n",
      "    QUANTITY   0.000000  1.000000  0.000000         0\n",
      "        TIME   0.666667  0.260870  0.375000        23\n",
      " WORK_OF_ART   0.000000  1.000000  0.000000         0\n",
      "\n",
      "   micro avg   0.802778  0.760526  0.781081       380\n",
      "   macro avg   0.571406  0.694833  0.487975       380\n",
      "weighted avg   0.818425  0.760526  0.774929       380\n",
      "\n",
      "**************\n",
      "/home/bangaru/Downloads/NERProject2021/spark-format-test/onto.wb.ner\n",
      "0\n",
      "[]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    CARDINAL   0.866667  0.764706  0.812500        85\n",
      "        DATE   0.654762  0.743243  0.696203        74\n",
      "       EVENT   0.600000  0.500000  0.545455        12\n",
      "         FAC   0.705882  0.666667  0.685714        18\n",
      "         GPE   0.930233  0.924855  0.927536       173\n",
      "    LANGUAGE   1.000000  0.250000  0.400000         4\n",
      "         LAW   1.000000  1.000000  1.000000         1\n",
      "         LOC   0.625000  0.555556  0.588235         9\n",
      "       MONEY   0.689655  0.800000  0.740741        25\n",
      "        NORP   0.875000  0.850467  0.862559       107\n",
      "     ORDINAL   0.812500  0.722222  0.764706        18\n",
      "         ORG   0.673913  0.794872  0.729412       117\n",
      "     PERCENT   0.575758  0.575758  0.575758        33\n",
      "      PERSON   0.911602  0.810811  0.858257       407\n",
      "     PRODUCT   0.000000  0.000000  0.000000         1\n",
      "    QUANTITY   0.333333  0.333333  0.333333         6\n",
      "        TIME   0.560000  0.700000  0.622222        20\n",
      " WORK_OF_ART   0.454545  0.555556  0.500000        27\n",
      "\n",
      "   micro avg   0.808969  0.793316  0.801066      1137\n",
      "   macro avg   0.681603  0.641558  0.646813      1137\n",
      "weighted avg   0.820945  0.793316  0.803871      1137\n",
      "\n",
      "**************\n"
     ]
    }
   ],
   "source": [
    "for testfile in testfiles:\n",
    "    filepath = os.path.join(outputdir,testfile)\n",
    "    print(filepath)\n",
    "    get_results(filepath)\n",
    "    print(\"**************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
