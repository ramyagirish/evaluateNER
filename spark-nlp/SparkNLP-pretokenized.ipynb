{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "frozen-treasurer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Spark NLP\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "import sparknlp\n",
    "\n",
    "# Start Spark Session with Spark NLP\n",
    "# start() functions has two parameters: gpu and spark23\n",
    "# sparknlp.start(gpu=True) will start the session with GPU support\n",
    "# sparknlp.start(spark23=True) is when you have Apache Spark 2.3.x installed\n",
    "spark = sparknlp.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "automotive-newman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP version 2.7.3\n",
      "Apache Spark version: 2.4.4\n"
     ]
    }
   ],
   "source": [
    "print(\"Spark NLP version\", sparknlp.version())\n",
    "print(\"Apache Spark version:\", spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "defined-volunteer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_onto_nw_ner.csv\n",
      "test_onto_bc_ner.csv\n",
      "test_onto_wb_ner.csv\n",
      "test_onto_mz_ner.csv\n",
      "test_onto_pt_ner.csv\n",
      "test_onto_bn_ner.csv\n",
      "test_onto_tc_ner.csv\n"
     ]
    }
   ],
   "source": [
    "import pathlib \n",
    "path = pathlib.Path(\"/Users/ramybal/Downloads/bio/spark/test\")\n",
    "flist = [str(f) for f in path.rglob(\"*.*\")]\n",
    "# create destination text file\n",
    "for f in flist:\n",
    "    filename = \"test_\" + pathlib.Path(f).name.split(\".\")[0] + \".csv\"\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cordless-factor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"/Users/ramybal/Downloads/bio/spark/test/onto_bc_ner.txt\",delimiter=\"\\t\", quoting=csv.QUOTE_NONE, encoding='utf-8',header=None,names=[\"Word\",\"POS\",\"DEREP\",\"TYPE\",\"SENT_NO\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "above-trailer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32488, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "technological-physics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Word', 'POS', 'DEREP', 'TYPE', 'SENT_NO'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "serial-tissue",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>DEREP</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>SENT_NO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--</td>\n",
       "      <td>:</td>\n",
       "      <td>(TOP(S*</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>basically</td>\n",
       "      <td>RB</td>\n",
       "      <td>(ADVP*)</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it</td>\n",
       "      <td>PRP</td>\n",
       "      <td>(NP*)</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>was</td>\n",
       "      <td>VBD</td>\n",
       "      <td>(VP*</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Word  POS    DEREP TYPE  SENT_NO\n",
       "0         --    :  (TOP(S*    O        1\n",
       "1  basically   RB  (ADVP*)    O        1\n",
       "2          ,    ,        *    O        1\n",
       "3         it  PRP    (NP*)    O        1\n",
       "4        was  VBD     (VP*    O        1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "prerequisite-winner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_base_cased download started this may take some time.\n",
      "Approximate size to download 389.1 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "embeddings = BertEmbeddings.pretrained(\"bert_base_cased\", \"en\") \\\n",
    "      .setInputCols(\"sentence\",\"token\") \\\n",
    "      .setOutputCol(\"embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "basic-evening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onto_bert_base_cased download started this may take some time.\n",
      "Approximate size to download 15.5 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "ner_onto = NerDLModel.pretrained(\"onto_bert_base_cased\", \"en\") \\\n",
    "        .setInputCols([\"document\", \"token\", \"embeddings\"]) \\\n",
    "        .setOutputCol(\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "devoted-official",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = ['basically',\n",
    " ',',\n",
    " 'it',\n",
    " 'was',\n",
    " 'unanimously',\n",
    " 'agreed',\n",
    " 'upon',\n",
    " 'by',\n",
    " 'the',\n",
    " 'various',\n",
    " 'relevant',\n",
    " 'parties',\n",
    " '.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "increased-warner",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \" \".join(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "agreed-bracelet",
   "metadata": {},
   "outputs": [],
   "source": [
    "documentAssembler = DocumentAssembler().setInputCol(\"text\")\\\n",
    "                     .setOutputCol(\"document\")\\\n",
    "                     .setCleanupMode(\"shrink\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "latin-settle",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = spark.createDataFrame(pd.DataFrame({'text':[sentence]}))\n",
    "doc_df = documentAssembler.transform(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "through-parks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                text|            document|\n",
      "+--------------------+--------------------+\n",
      "|basically , it wa...|[[document, 0, 75...|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "thirty-stations",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_detector = SentenceDetector().setInputCols([\"document\"])\\\n",
    "                                      .setOutputCol(\"sentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "executive-seafood",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_df = sentence_detector.transform(doc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "worthy-branch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|                text|            document|            sentence|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|basically , it wa...|[[document, 0, 75...|[[document, 0, 75...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sent_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "expected-announcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sent_df.select(\"text\",\"sentence\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "together-dylan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(text='basically , it was unanimously agreed upon by the various relevant parties .', sentence=[Row(annotatorType='document', begin=0, end=75, result='basically , it was unanimously agreed upon by the various relevant parties .', metadata={'sentence': '0'}, embeddings=[])])]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "straight-baker",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer().setInputCols([\"sentence\"])\\\n",
    "                          .setOutputCol(\"token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cellular-wonder",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_df = tokenizer.fit(sent_df).transform(sent_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "arbitrary-precipitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_df = embeddings.transform(token_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "southern-voltage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|            document|            sentence|               token|          embeddings|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|basically , it wa...|[[document, 0, 75...|[[document, 0, 75...|[[token, 0, 8, ba...|[[word_embeddings...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "embed_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "incomplete-suicide",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = embed_df.select(\"document\",\"token\",\"embeddings\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "selected-debate",
   "metadata": {},
   "outputs": [],
   "source": [
    "detoken = []\n",
    "for r in result[0].embeddings:\n",
    "    detoken.append(r.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "premium-curtis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['basically',\n",
       " ',',\n",
       " 'it',\n",
       " 'was',\n",
       " 'unanimously',\n",
       " 'agreed',\n",
       " 'upon',\n",
       " 'by',\n",
       " 'the',\n",
       " 'various',\n",
       " 'relevant',\n",
       " 'parties',\n",
       " '.']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "amber-lecture",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_assembler = DocumentAssembler().setInputCol(\"text\").setOutputCol(\"document\").setCleanupMode(\"shrink\")\n",
    "\n",
    "sentence_detector = SentenceDetector().setInputCols([\"document\"]).setOutputCol(\"sentence\")\n",
    "\n",
    "tokenizer = Tokenizer().setInputCols([\"sentence\"]).setOutputCol(\"token\")\n",
    "\n",
    "nlp_pipeline = Pipeline(stages=[document_assembler, sentence_detector, tokenizer, embeddings, ner_onto])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "stopped-carolina",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_model = nlp_pipeline.fit(spark.createDataFrame([['']]).toDF('text'))\n",
    "result1 = pipeline_model.transform(df1)\n",
    "                                                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "opening-electric",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result1.select(\"token\",\"ner\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "solved-decimal",
   "metadata": {},
   "outputs": [],
   "source": [
    "detoken = []\n",
    "for r in result[0].ner:\n",
    "    detoken.append(r.metadata[\"word\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "incorporated-reform",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['basically',\n",
       " ',',\n",
       " 'it',\n",
       " 'was',\n",
       " 'unanimously',\n",
       " 'agreed',\n",
       " 'upon',\n",
       " 'by',\n",
       " 'the',\n",
       " 'various',\n",
       " 'relevant',\n",
       " 'parties',\n",
       " '.']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "rocky-arnold",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing for /Users/ramybal/Downloads/bio/spark/test/onto_nw_ner.txt\n",
      "there are 1898 sentences\n",
      "Done for 1000 in 36.95173096656799 seconds\n",
      "Done processing in 336.0318179130554 seconds\n",
      "doing for /Users/ramybal/Downloads/bio/spark/test/onto_bc_ner.txt\n",
      "there are 2037 sentences\n",
      "Done for 1000 in 25.83370614051819 seconds\n",
      "Done for 2000 in 47.08746099472046 seconds\n",
      "Done processing in 317.4331738948822 seconds\n",
      "doing for /Users/ramybal/Downloads/bio/spark/test/onto_wb_ner.txt\n",
      "there are 929 sentences\n",
      "Done processing in 153.64200711250305 seconds\n",
      "doing for /Users/ramybal/Downloads/bio/spark/test/onto_mz_ner.txt\n",
      "there are 780 sentences\n",
      "Done processing in 129.082937002182 seconds\n",
      "doing for /Users/ramybal/Downloads/bio/spark/test/onto_pt_ner.txt\n",
      "there are 1217 sentences\n",
      "Done for 1000 in 19.892353057861328 seconds\n",
      "Done processing in 180.55652713775635 seconds\n",
      "doing for /Users/ramybal/Downloads/bio/spark/test/onto_bn_ner.txt\n",
      "there are 1252 sentences\n",
      "Done for 1000 in 28.17906093597412 seconds\n",
      "Done processing in 195.77146697044373 seconds\n",
      "doing for /Users/ramybal/Downloads/bio/spark/test/onto_tc_ner.txt\n",
      "there are 1366 sentences\n",
      "Done for 1000 in 12.035691976547241 seconds\n",
      "Done processing in 187.01007103919983 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "path = pathlib.Path(\"/Users/ramybal/Downloads/bio/spark/test\")\n",
    "flist = [str(f) for f in path.rglob(\"*.*\")]\n",
    "for f in flist:\n",
    "    print(\"doing for \" + f)\n",
    "    df = pd.read_csv(f,delimiter=\"\\t\", quoting=csv.QUOTE_NONE, encoding='utf-8',header=None,names=[\"Word\",\"POS\",\"DEREP\",\"TYPE\",\"SENT_NO\"])\n",
    "    sentences = []\n",
    "    entities = []\n",
    "    entities_type = []\n",
    "    print(\"there are {} sentences\".format(len(df.groupby(\"SENT_NO\").groups.items())))\n",
    "    count = 1\n",
    "    start = time.time()\n",
    "    for _,v in df.groupby(\"SENT_NO\").groups.items():\n",
    "        temp1 = []\n",
    "        temp2 = []\n",
    "        temp3 = []\n",
    "        if count%1000 == 0:\n",
    "            print(\"Done for {} in {} seconds\".format(count,time.time()-start))\n",
    "        for i,t in enumerate(df.iloc[v,:].Word.tolist()):\n",
    "            if i < (len(df.iloc[v,:].Word.tolist())-1):\n",
    "                if df.iloc[v,:].Word.tolist()[i][0].isalnum() and not(df.iloc[v,:].Word.tolist()[i+1][0].isalnum()):\n",
    "                    temp1.append(t + df.iloc[v,:].Word.tolist()[i+1])\n",
    "                    temp2.append(df.iloc[v,:].TYPE.tolist()[i])\n",
    "                    temp2.append(df.iloc[v,:].TYPE.tolist()[i+1])\n",
    "                    temp3.append(df.iloc[v,:].Word.tolist()[i])\n",
    "                    temp3.append(df.iloc[v,:].Word.tolist()[i+1])\n",
    "                elif not(df.iloc[v,:].Word.tolist()[i][0].isalnum()):\n",
    "                    continue\n",
    "                else:\n",
    "                    temp1.append(t)\n",
    "                    temp2.append(df.iloc[v,:].TYPE.tolist()[i])\n",
    "                    temp3.append(df.iloc[v,:].Word.tolist()[i])\n",
    "            elif i == (len(df.iloc[v,:].Word.tolist())-1):\n",
    "                if t[0].isalnum():\n",
    "                    temp1.append(t)\n",
    "                    temp2.append(df.iloc[v,:].TYPE.tolist()[i])\n",
    "                    temp3.append(df.iloc[v,:].Word.tolist()[i])\n",
    "        sentences.append(\" \".join(temp3))\n",
    "        entities_type.append(temp2)\n",
    "        entities.append(temp3)\n",
    "        count += 1\n",
    "    sentences =  [s for s in sentences if s != \"\"]\n",
    "    entities_type =  [s for s in entities_type if s != []]\n",
    "    entities =  [s for s in entities if s != []]\n",
    "    detected_sent = []\n",
    "    detected_ner = []\n",
    "    detected_ner_type = []\n",
    "    start = time.time()\n",
    "    for sent in sentences:\n",
    "        df = spark.createDataFrame(pd.DataFrame({'text':[sent]}))\n",
    "        result = pipeline_model.transform(df)    \n",
    "        df_result = result.select(\"sentence\",\"ner\").collect()\n",
    "    \n",
    "        detected_sent.append([df_result[0][0][0].result])\n",
    "        ners = []\n",
    "        ner_types = []\n",
    "        for d in df_result[0][1]:\n",
    "            ners.append(d.metadata[\"word\"])\n",
    "            ner_types.append(d.result)\n",
    "        detected_ner.append(ners)\n",
    "        detected_ner_type.append(ner_types)\n",
    "    print(\"Done processing in {} seconds\".format(time.time()-start))\n",
    "    pd.DataFrame({\"Detected_sentence\":detected_sent,\"Actual_ners\":entities,\"Detected_ners\":detected_ner,\"Actual_ner_types\":entities_type,\"Detected_ner_types\":detected_ner_type}).to_csv(\"detect_\" + pathlib.Path(f).name.split(\".\")[0] + \".csv\",index = False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "forward-shelter",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = pathlib.Path(\"/Users/ramybal/Downloads/bio/spark/test\")\n",
    "flist1 = [str(f) for f in path.rglob(\"*.*\")]\n",
    "path = pathlib.Path(\"/Users/ramybal/Desktop/untitled folder/neuroner/\")\n",
    "flist = [str(f) for f in path.rglob(\"detect*.csv\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "clear-arnold",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = flist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "united-actor",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "sunset-prerequisite",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Detected_sentence</th>\n",
       "      <th>Actual_ners</th>\n",
       "      <th>Detected_ners</th>\n",
       "      <th>Actual_ner_types</th>\n",
       "      <th>Detected_ner_types</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['Iraqi leader Saddam Hussein has given a defi...</td>\n",
       "      <td>['Iraqi', 'leader', 'Saddam', 'Hussein', 'has'...</td>\n",
       "      <td>['Iraqi', 'leader', 'Saddam', 'Hussein', 'has'...</td>\n",
       "      <td>['B-NORP', 'O', 'B-PERSON', 'I-PERSON', 'O', '...</td>\n",
       "      <td>['B-NORP', 'O', 'B-PERSON', 'I-PERSON', 'O', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['He says Iraq has triumphed over the evil of ...</td>\n",
       "      <td>['He', 'says', 'Iraq', 'has', 'triumphed', 'ov...</td>\n",
       "      <td>['He', 'says', 'Iraq', 'has', 'triumphed', 'ov...</td>\n",
       "      <td>['O', 'O', 'B-GPE', 'O', 'O', 'O', 'O', 'O', '...</td>\n",
       "      <td>['O', 'O', 'B-GPE', 'O', 'O', 'O', 'O', 'O', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['Barbara Plett reports from Baghdad .']</td>\n",
       "      <td>['Barbara', 'Plett', 'reports', 'from', 'Baghd...</td>\n",
       "      <td>['Barbara', 'Plett', 'reports', 'from', 'Baghd...</td>\n",
       "      <td>['B-PERSON', 'I-PERSON', 'O', 'O', 'B-GPE', 'O']</td>\n",
       "      <td>['B-PERSON', 'I-PERSON', 'O', 'O', 'B-GPE', 'O']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['Saddam Hussein addressed the nation in a spe...</td>\n",
       "      <td>['Saddam', 'Hussein', 'addressed', 'the', 'nat...</td>\n",
       "      <td>['Saddam', 'Hussein', 'addressed', 'the', 'nat...</td>\n",
       "      <td>['B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', '...</td>\n",
       "      <td>['B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['Iraq has triumphed over its enemies , he sai...</td>\n",
       "      <td>['Iraq', 'has', 'triumphed', 'over', 'its', 'e...</td>\n",
       "      <td>['Iraq', 'has', 'triumphed', 'over', 'its', 'e...</td>\n",
       "      <td>['B-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', '...</td>\n",
       "      <td>['B-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Detected_sentence  \\\n",
       "0  ['Iraqi leader Saddam Hussein has given a defi...   \n",
       "1  ['He says Iraq has triumphed over the evil of ...   \n",
       "2           ['Barbara Plett reports from Baghdad .']   \n",
       "3  ['Saddam Hussein addressed the nation in a spe...   \n",
       "4  ['Iraq has triumphed over its enemies , he sai...   \n",
       "\n",
       "                                         Actual_ners  \\\n",
       "0  ['Iraqi', 'leader', 'Saddam', 'Hussein', 'has'...   \n",
       "1  ['He', 'says', 'Iraq', 'has', 'triumphed', 'ov...   \n",
       "2  ['Barbara', 'Plett', 'reports', 'from', 'Baghd...   \n",
       "3  ['Saddam', 'Hussein', 'addressed', 'the', 'nat...   \n",
       "4  ['Iraq', 'has', 'triumphed', 'over', 'its', 'e...   \n",
       "\n",
       "                                       Detected_ners  \\\n",
       "0  ['Iraqi', 'leader', 'Saddam', 'Hussein', 'has'...   \n",
       "1  ['He', 'says', 'Iraq', 'has', 'triumphed', 'ov...   \n",
       "2  ['Barbara', 'Plett', 'reports', 'from', 'Baghd...   \n",
       "3  ['Saddam', 'Hussein', 'addressed', 'the', 'nat...   \n",
       "4  ['Iraq', 'has', 'triumphed', 'over', 'its', 'e...   \n",
       "\n",
       "                                    Actual_ner_types  \\\n",
       "0  ['B-NORP', 'O', 'B-PERSON', 'I-PERSON', 'O', '...   \n",
       "1  ['O', 'O', 'B-GPE', 'O', 'O', 'O', 'O', 'O', '...   \n",
       "2   ['B-PERSON', 'I-PERSON', 'O', 'O', 'B-GPE', 'O']   \n",
       "3  ['B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', '...   \n",
       "4  ['B-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', '...   \n",
       "\n",
       "                                  Detected_ner_types  \n",
       "0  ['B-NORP', 'O', 'B-PERSON', 'I-PERSON', 'O', '...  \n",
       "1  ['O', 'O', 'B-GPE', 'O', 'O', 'O', 'O', 'O', '...  \n",
       "2   ['B-PERSON', 'I-PERSON', 'O', 'O', 'B-GPE', 'O']  \n",
       "3  ['B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', '...  \n",
       "4  ['B-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', '...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "comparative-festival",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "df[['Detected_ners']] = df[['Detected_ners']].applymap(yaml.safe_load) \n",
    "df[['Detected_ner_types']] = df[['Detected_ner_types']].applymap(yaml.safe_load) \n",
    "df[['Actual_ners']] = df[['Actual_ners']].applymap(yaml.safe_load) \n",
    "df[['Actual_ner_types']] = df[['Actual_ner_types']].applymap(yaml.safe_load)\n",
    "  \n",
    "\n",
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "focused-shopper",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-PERSON',\n",
       " 'O',\n",
       " 'B-DATE',\n",
       " 'O',\n",
       " 'B-WORK_OF_ART',\n",
       " 'I-WORK_OF_ART',\n",
       " 'I-WORK_OF_ART',\n",
       " 'I-WORK_OF_ART',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-GPE',\n",
       " 'O']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[unequal[1],:].Actual_ner_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "silver-minutes",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gao',\n",
       " \"'s\",\n",
       " '1989',\n",
       " 'novel',\n",
       " '`',\n",
       " 'Soul',\n",
       " 'Mountain',\n",
       " \"'\",\n",
       " 'will',\n",
       " 'be',\n",
       " 'published',\n",
       " 'for',\n",
       " 'the',\n",
       " 'first',\n",
       " 'time',\n",
       " 'in',\n",
       " 'America',\n",
       " '.']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[unequal[1],:].Actual_ners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "blank-potential",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-PERSON',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-DATE',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-WORK_OF_ART',\n",
       " 'I-WORK_OF_ART',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ORDINAL',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-GPE',\n",
       " 'O']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[unequal[1],:].Detected_ner_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "exclusive-halloween",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gao',\n",
       " \"'\",\n",
       " 's',\n",
       " '1989',\n",
       " 'novel',\n",
       " '`',\n",
       " 'Soul',\n",
       " 'Mountain',\n",
       " \"'\",\n",
       " 'will',\n",
       " 'be',\n",
       " 'published',\n",
       " 'for',\n",
       " 'the',\n",
       " 'first',\n",
       " 'time',\n",
       " 'in',\n",
       " 'America',\n",
       " '.']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[unequal[1],:].Detected_ners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "incorrect-hampshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multicount(searchlist,target):\n",
    "    temp = []\n",
    "    count = 0\n",
    "    while(count<len(searchlist)):\n",
    "        if searchlist[count].lower() == target.lower():\n",
    "            temp.append(count)\n",
    "        count += 1\n",
    "    return temp\n",
    " \n",
    "detect_ner = []\n",
    "detect_type = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    detect_ner_temp = []\n",
    "    detect_type_temp = []\n",
    "    flag = 0\n",
    "    for j,d in enumerate(df.iloc[i,:].Detected_ners):\n",
    "        if (j < (len(df.iloc[i,:].Detected_ners) - 1) and df.iloc[i,:].Detected_ners[j+1] == \"s\" and d == \"'\"):\n",
    "            detect_ner_temp.append(\"'s\")\n",
    "            detect_type_temp.append(\"O\")\n",
    "            flag = 1\n",
    "        elif d == \"s\" and flag == 1:\n",
    "            flag = 0\n",
    "            continue\n",
    "        else:\n",
    "            detect_ner_temp.append(d)\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j])\n",
    "    detect_ner.append(detect_ner_temp)\n",
    "    detect_type.append(detect_type_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "premium-pantyhose",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1252"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(detect_ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "contained-elevation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1252"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(detect_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "compound-chase",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(detect_ner[unequal[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "heavy-niger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(detect_type[unequal[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "imported-municipality",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.iloc[unequal[0],:].Actual_ners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "interesting-concentration",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Detected_ners = detect_ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "registered-fever",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Detected_ner_types = detect_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "mental-platinum",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "usual-electric",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "accredited-ticket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Former', 'U.S.', 'representative', 'Sidney', 'Yates', 'has', 'died', '.']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[unequal[0],:].Actual_ners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "comic-table",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Former', 'U.S', '.', 'representative', 'Sidney', 'Yates', 'has', 'died', '.']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[unequal[0],:].Detected_ners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "instant-gospel",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_ner = []\n",
    "detect_type = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    detect_ner_temp = []\n",
    "    detect_type_temp = []\n",
    "    flag = 0\n",
    "    for j,d in enumerate(df.iloc[i,:].Detected_ners):\n",
    "        if (j < (len(df.iloc[i,:].Detected_ners) - 1) and df.iloc[i,:].Detected_ners[j+1] == \".\" and \".\" in d):\n",
    "            detect_ner_temp.append(d + \".\")\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j])\n",
    "            flag = 1\n",
    "        elif d == \".\" and flag == 1:\n",
    "            flag = 0\n",
    "            continue\n",
    "        else:\n",
    "            detect_ner_temp.append(d)\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j])\n",
    "    detect_ner.append(detect_ner_temp)\n",
    "    detect_type.append(detect_type_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "undefined-hartford",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Former', 'U.S.', 'representative', 'Sidney', 'Yates', 'has', 'died', '.']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_ner[unequal[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "agreed-darwin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-GPE', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_type[unequal[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "corporate-annex",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Detected_ners = detect_ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "lesser-tribute",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Detected_ner_types = detect_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "egyptian-monaco",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "concerned-pennsylvania",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "growing-republic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Well',\n",
       " ',',\n",
       " 'Mr.',\n",
       " 'Mubarak',\n",
       " 'has',\n",
       " 'been',\n",
       " ',',\n",
       " 'as',\n",
       " 'you',\n",
       " 'say',\n",
       " ',',\n",
       " 'a',\n",
       " 'voice',\n",
       " 'of',\n",
       " 'moderation',\n",
       " '.']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[unequal[0],:].Actual_ners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "invisible-delta",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Well',\n",
       " ',',\n",
       " 'Mr',\n",
       " '.',\n",
       " 'Mubarak',\n",
       " 'has',\n",
       " 'been',\n",
       " ',',\n",
       " 'as',\n",
       " 'you',\n",
       " 'say',\n",
       " ',',\n",
       " 'a',\n",
       " 'voice',\n",
       " 'of',\n",
       " 'moderation',\n",
       " '.']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[unequal[0],:].Detected_ners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "corporate-expression",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in unequal:\n",
    "    if \"'\" in df.iloc[i,:].Detected_ners[:-1]:\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "surgical-project",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "brazilian-egypt",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in unequal:\n",
    "    if \".\" in df.iloc[i,:].Detected_ners[:-1]:\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "czech-wellington",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "serious-inflation",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_ner = []\n",
    "detect_type = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    detect_ner_temp = []\n",
    "    detect_type_temp = []\n",
    "    flag = 0\n",
    "    for j,d in enumerate(df.iloc[i,:].Detected_ners):\n",
    "        if (j < (len(df.iloc[i,:].Detected_ners) - 2)) and df.iloc[i,:].Detected_ners[j+1] == \".\":\n",
    "            detect_ner_temp.append(d + \".\")\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j])\n",
    "            flag = 1\n",
    "        elif d == \".\" and flag == 1:\n",
    "            flag = 0\n",
    "            continue\n",
    "        else:\n",
    "            detect_ner_temp.append(d)\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j])\n",
    "    detect_ner.append(detect_ner_temp)\n",
    "    detect_type.append(detect_type_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "voluntary-vehicle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Iraqi',\n",
       " 'leader',\n",
       " 'Saddam',\n",
       " 'Hussein',\n",
       " 'has',\n",
       " 'given',\n",
       " 'a',\n",
       " 'defiant',\n",
       " 'speech',\n",
       " 'to',\n",
       " 'mark',\n",
       " 'the',\n",
       " 'tenth',\n",
       " 'anniversary',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Gulf',\n",
       " 'War',\n",
       " '.']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_ner[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "noted-stroke",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Detected_ners = detect_ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "herbal-swiss",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Detected_ner_types = detect_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "golden-development",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_ner = []\n",
    "detect_type = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    detect_ner_temp = []\n",
    "    detect_type_temp = []\n",
    "    flag = 0\n",
    "    for j,d in enumerate(df.iloc[i,:].Detected_ners):\n",
    "        if (j < (len(df.iloc[i,:].Detected_ners) - 1) and d == \"'\"):\n",
    "            detect_ner_temp.append(\"'\" + df.iloc[i,:].Detected_ners[j+1])\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j])\n",
    "            flag = 1\n",
    "        elif flag == 1:\n",
    "            flag = 0\n",
    "            continue\n",
    "        else:\n",
    "            detect_ner_temp.append(d)\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j])\n",
    "    detect_ner.append(detect_ner_temp)\n",
    "    detect_type.append(detect_type_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "bottom-option",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Detected_ners = detect_ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "printable-basement",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Detected_ner_types = detect_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "advanced-jimmy",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "voluntary-acrobat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "loose-reader",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'novel',\n",
       " '`',\n",
       " 'soul',\n",
       " 'mountain',\n",
       " \"'\",\n",
       " 'which',\n",
       " 'is',\n",
       " 'just',\n",
       " 'being',\n",
       " 'released',\n",
       " 'in',\n",
       " 'the',\n",
       " 'United',\n",
       " 'States',\n",
       " 'this',\n",
       " 'week',\n",
       " 'is',\n",
       " 'in',\n",
       " 'every',\n",
       " 'possible',\n",
       " 'way',\n",
       " 'a',\n",
       " 'celebration',\n",
       " 'of',\n",
       " 'what',\n",
       " 'freedom',\n",
       " 'means',\n",
       " '.']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[unequal[1],:].Actual_ners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "adapted-heather",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'novel',\n",
       " '`',\n",
       " 'soul',\n",
       " 'mountain',\n",
       " \"'which\",\n",
       " 'is',\n",
       " 'just',\n",
       " 'being',\n",
       " 'released',\n",
       " 'in',\n",
       " 'the',\n",
       " 'United',\n",
       " 'States',\n",
       " 'this',\n",
       " 'week',\n",
       " 'is',\n",
       " 'in',\n",
       " 'every',\n",
       " 'possible',\n",
       " 'way',\n",
       " 'a',\n",
       " 'celebration',\n",
       " 'of',\n",
       " 'what',\n",
       " 'freedom',\n",
       " 'means',\n",
       " '.']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[unequal[1],:].Detected_ners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "fiscal-watch",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_ner = []\n",
    "actual_type = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    actual_ner_temp = []\n",
    "    actual_type_temp = []\n",
    "    flag = 0\n",
    "    for j,d in enumerate(df.iloc[i,:].Actual_ners):\n",
    "        if (j < (len(df.iloc[i,:].Actual_ners) - 1) and d == \"'\"):\n",
    "            actual_ner_temp.append(\"'\" + df.iloc[i,:].Actual_ners[j+1])\n",
    "            actual_type_temp.append(df.iloc[i,:].Actual_ner_types[j])\n",
    "            flag = 1\n",
    "        elif flag == 1:\n",
    "            flag = 0\n",
    "            continue\n",
    "        else:\n",
    "            actual_ner_temp.append(d)\n",
    "            actual_type_temp.append(df.iloc[i,:].Actual_ner_types[j])\n",
    "    actual_ner.append(actual_ner_temp)\n",
    "    actual_type.append(actual_type_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "secure-sandwich",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Actual_ners = actual_ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "northern-edgar",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Actual_ner_types = actual_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "acoustic-explorer",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "different-briefing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "assigned-wildlife",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Just', 'go', 'to', 'our', 'Website', ',', 'cnn.com/wolf', '.']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[unequal[0],:].Actual_ners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "physical-patch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Just', 'go', 'to', 'our', 'Website', ',', 'cnn.com/wolf.']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[unequal[0],:].Detected_ners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "anonymous-shooting",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[unequal[0],:].Detected_ners = ['Just', 'go', 'to', 'our', 'Website', ',', 'cnn.com/wolf', '.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "specific-speaker",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'O', 'O', 'O', 'O', 'O', 'O']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[unequal[0],:].Detected_ner_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "coordinated-attraction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[unequal[0],:].Actual_ner_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "portuguese-bedroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[unequal[0],:].Detected_ner_types = df.iloc[unequal[0],:].Actual_ner_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "molecular-point",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Good', 'to', 'be', '-LRB-', 'bleep', '-RRB-', 'King', '.']"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[unequal[1],:].Actual_ners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "sudden-samuel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Good', 'to', 'be', '-', 'LRB', '-', 'bleep', '-', 'RRB', '-', 'King', '.']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[unequal[1],:].Detected_ners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "abandoned-costume",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[unequal[1],:].Actual_ner_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "sixth-laser",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[unequal[1],:].Detected_ner_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "complicated-lindsay",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[unequal[1],:].Detected_ners = df.iloc[unequal[1],:].Actual_ners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "invalid-tuition",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[unequal[1],:].Detected_ner_types = df.iloc[unequal[1],:].Actual_ner_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "authentic-alaska",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "collect-analyst",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unequal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "nuclear-unknown",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "demanding-liver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ramybal/Desktop/untitled folder/neuroner/detect_onto_bn_ner.csv\n",
      "accuracy score\n",
      "0.9795319112185854\n"
     ]
    }
   ],
   "source": [
    "print(f)\n",
    "print(\"accuracy score\")\n",
    "print(accuracy_score(df.Actual_ner_types.tolist(),df.Detected_ner_types.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "exposed-commons",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8935976304397356\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(df.Actual_ner_types.tolist(),df.Detected_ner_types.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "recovered-easter",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = flist[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "provincial-failing",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f)\n",
    "df[['Detected_ners']] = df[['Detected_ners']].applymap(yaml.safe_load) \n",
    "df[['Detected_ner_types']] = df[['Detected_ner_types']].applymap(yaml.safe_load) \n",
    "df[['Actual_ners']] = df[['Actual_ners']].applymap(yaml.safe_load) \n",
    "df[['Actual_ner_types']] = df[['Actual_ner_types']].applymap(yaml.safe_load)\n",
    "  \n",
    "\n",
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "contained-thursday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "340"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "virtual-folder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Detected_sentence        [\"That 's true .\"]\n",
       "Actual_ners             [That, 's, true, .]\n",
       "Detected_ners         [That, ', s, true, .]\n",
       "Actual_ner_types               [O, O, O, O]\n",
       "Detected_ner_types          [O, O, O, O, O]\n",
       "Name: 47, dtype: object"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[unequal[10],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "prospective-blank",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_ner = []\n",
    "detect_type = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    detect_ner_temp = []\n",
    "    detect_type_temp = []\n",
    "    flag = 0\n",
    "    for j,d in enumerate(df.iloc[i,:].Detected_ners):\n",
    "        if (j < (len(df.iloc[i,:].Detected_ners) - 1) and d == \"'\"):\n",
    "            detect_ner_temp.append(\"'\" + df.iloc[i,:].Detected_ners[j+1])\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j])\n",
    "            flag = 1\n",
    "        elif flag == 1:\n",
    "            flag = 0\n",
    "            continue\n",
    "        else:\n",
    "            detect_ner_temp.append(d)\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j])\n",
    "    detect_ner.append(detect_ner_temp)\n",
    "    detect_type.append(detect_type_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "sustained-content",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Detected_ners = detect_ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "seven-launch",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Detected_ner_types = detect_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "numeric-alaska",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "passing-baptist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "objective-cooking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Detected_sentence        [\"You know , I mean , we 're d- , you know ,\"]\n",
       "Actual_ners           [You, know, ,, I, mean, ,, we, 're, d-, ,, you...\n",
       "Detected_ners         [You, know, ,, I, mean, ,, we, 're, d, -, ,, y...\n",
       "Actual_ner_types                [O, O, O, O, O, O, O, O, O, O, O, O, O]\n",
       "Detected_ner_types           [O, O, O, O, O, O, O, O, O, O, O, O, O, O]\n",
       "Name: 107, dtype: object"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[unequal[3],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "former-baseball",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_ner = []\n",
    "detect_type = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    detect_ner_temp = []\n",
    "    detect_type_temp = []\n",
    "    flag = 0\n",
    "    for j,d in enumerate(df.iloc[i,:].Detected_ners):\n",
    "        if (j < (len(df.iloc[i,:].Detected_ners) - 1)) and df.iloc[i,:].Detected_ners[j+1] == \"-\":\n",
    "            detect_ner_temp.append(d + \"-\")\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j])\n",
    "            flag = 1\n",
    "        elif d == \"-\" and flag == 1:\n",
    "            flag = 0\n",
    "            continue\n",
    "        else:\n",
    "            detect_ner_temp.append(d)\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j])\n",
    "    detect_ner.append(detect_ner_temp)\n",
    "    detect_type.append(detect_type_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "raised-surgeon",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Detected_ners = detect_ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "foreign-metadata",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Detected_ner_types = detect_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "incident-tract",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_ner = []\n",
    "detect_type = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    detect_ner_temp = []\n",
    "    detect_type_temp = []\n",
    "    flag = 0\n",
    "    for j,d in enumerate(df.iloc[i,:].Detected_ners):\n",
    "        if (j < (len(df.iloc[i,:].Detected_ners) - 1)) and df.iloc[i,:].Detected_ners[j+1] == \":\":\n",
    "            detect_ner_temp.append(d + \":\")\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j])\n",
    "            flag = 1\n",
    "        elif d == \":\" and flag == 1:\n",
    "            flag = 0\n",
    "            continue\n",
    "        else:\n",
    "            detect_ner_temp.append(d)\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j])\n",
    "    detect_ner.append(detect_ner_temp)\n",
    "    detect_type.append(detect_type_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "adaptive-deployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Detected_ners = detect_ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "hybrid-database",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Detected_ner_types = detect_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "convinced-stupid",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "interstate-coordination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "brown-sacrifice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual\n",
      "['My', 'daughter', '-', 'in', '-', 'law', 'Barbara', 'got', 'on', 'her', 'case', 'real', 'serious', 'yesterday', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE', 'O']\n",
      "detected\n",
      "['My', 'daughter-', 'in-', 'law', 'Barbara', 'got', 'on', 'her', 'case', 'real', 'serious', 'yesterday', '.']\n",
      "['O', 'O', 'O', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['I', 'truly', 'believe', 'that', '**Salem**']\n",
      "['O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['I', 'truly', 'believe', 'that', '**', 'Salem', '**']\n",
      "['O', 'O', 'O', 'O', 'O', 'B-PERSON', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['because', 'my', 'daughter', '-', 'in', '-', 'law', 'is', 'pregnant', 'again', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['because', 'my', 'daughter-', 'in-', 'law', 'is', 'pregnant', 'again', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Was', 'this', 'last', 'crop', 'of', '**Tuftees**', 'good', '?']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['Was', 'this', 'last', 'crop', 'of', '**', 'Tuftees', '**', 'good', '?']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['it', 'has', 'an', 'off', 'board', 'power', 'supply', 'which', 'they', 'did', \"n't\", 'steal', ',', 'which', 'makes', 'the', 'thing', 'that', 'they', '**stoled**', 'absolutely', 'worthless', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['it', 'has', 'an', 'off', 'board', 'power', 'supply', 'which', 'they', 'did', \"n't\", 'steal', ',', 'which', 'makes', 'the', 'thing', 'that', 'they', '**', 'stoled', '**', 'absolutely', 'worthless', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['And', 'when', 'he', 'goes', 'to', 'work', 'he', 'brings', 'four', 'sandwiches', 'with', 'him', ',', 'uh-huh', '.', 'a', 'bag', 'of', 'potato', 'chips', 'uh-huh', '.', 'you', 'know', 'and', 'then', 'little', 'sweetie', 'things', 'chocolates', 'and', '**cakies**', 'and', 'stuff', 'like', 'that', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-CARDINAL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['And', 'when', 'he', 'goes', 'to', 'work', 'he', 'brings', 'four', 'sandwiches', 'with', 'him', ',', 'uh-huh', '.', 'a', 'bag', 'of', 'potato', 'chips', 'uh-huh', '.', 'you', 'know', 'and', 'then', 'little', 'sweetie', 'things', 'chocolates', 'and', '**', 'cakies', '**', 'and', 'stuff', 'like', 'that', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-CARDINAL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in unequal:\n",
    "    print(\"actual\")\n",
    "    print(df.iloc[i,:].Actual_ners)\n",
    "    print(df.iloc[i,:].Actual_ner_types)\n",
    "    print(\"detected\")\n",
    "    print(df.iloc[i,:].Detected_ners)\n",
    "    print(df.iloc[i,:].Detected_ner_types)\n",
    "    print(\"-----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "genetic-plaintiff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[unequal[0],:].Detected_ners = df.iloc[unequal[0],:].Actual_ners\n",
    "df.iloc[unequal[0],:].Detected_ner_types = df.iloc[unequal[0],:].Actual_ner_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "homeless-incident",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[unequal[1],:].Detected_ners = df.iloc[unequal[1],:].Actual_ners\n",
    "df.iloc[unequal[1],:].Detected_ner_types = ['O', 'O', 'O', 'O', 'B-PERSON']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "fitted-steam",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in unequal[2:]:\n",
    "    df.iloc[i,:].Detected_ners = df.iloc[i,:].Actual_ners\n",
    "    df.iloc[i,:].Detected_ner_types = df.iloc[i,:].Actual_ner_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "caring-repeat",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "handy-biotechnology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "centered-lafayette",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ramybal/Desktop/untitled folder/neuroner/detect_onto_tc_ner.csv\n",
      "accuracy score\n",
      "0.9811835544265688\n"
     ]
    }
   ],
   "source": [
    "print(f)\n",
    "print(\"accuracy score\")\n",
    "print(accuracy_score(df.Actual_ner_types.tolist(),df.Detected_ner_types.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "israeli-timeline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7783783783783784\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(df.Actual_ner_types.tolist(),df.Detected_ner_types.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "offshore-sudan",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = flist[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "subtle-marine",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f)\n",
    "df[['Detected_ners']] = df[['Detected_ners']].applymap(yaml.safe_load) \n",
    "df[['Detected_ner_types']] = df[['Detected_ner_types']].applymap(yaml.safe_load) \n",
    "df[['Actual_ners']] = df[['Actual_ners']].applymap(yaml.safe_load) \n",
    "df[['Actual_ner_types']] = df[['Actual_ner_types']].applymap(yaml.safe_load)\n",
    "  \n",
    "\n",
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "funky-prior",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "757"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "suited-timber",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual\n",
      "['With', 'economic', 'tension', 'between', 'the', 'U.S.', 'and', 'Japan', 'worsening', ',', 'many', 'Japanese', 'had', 'feared', 'last', 'week', \"'s\", 'visit', 'from', 'U.S.', 'Trade', 'Representative', 'Carla', 'Hills', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'B-GPE', 'O', 'B-GPE', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'B-DATE', 'I-DATE', 'I-DATE', 'O', 'O', 'B-GPE', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O']\n",
      "detected\n",
      "['With', 'economic', 'tension', 'between', 'the', 'U.S', '.', 'and', 'Japan', 'worsening', ',', 'many', 'Japanese', 'had', 'feared', 'last', 'week', \"'\", 's', 'visit', 'from', 'U.S', '.', 'Trade', 'Representative', 'Carla', 'Hills', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'B-GPE', 'I-GPE', 'O', 'B-GPE', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'B-DATE', 'I-DATE', 'I-DATE', 'O', 'O', 'O', 'B-GPE', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['They', 'expected', 'a', 'new', 'barrage', 'of', 'demands', 'that', 'Japan', 'do', 'something', 'quickly', 'to', 'reduce', 'its', 'trade', 'surplus', 'with', 'the', 'U.S.', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'O']\n",
      "detected\n",
      "['They', 'expected', 'a', 'new', 'barrage', 'of', 'demands', 'that', 'Japan', 'do', 'something', 'quickly', 'to', 'reduce', 'its', 'trade', 'surplus', 'with', 'the', 'U.S', '.', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'I-GPE', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Instead', ',', 'they', 'got', 'a', 'discussion', 'of', 'the', 'need', 'for', 'the', 'U.S.', 'and', 'Japan', 'to', 'work', 'together', 'and', 'of', 'the', 'importance', 'of', 'the', 'long', '-', 'term', 'view', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'O', 'B-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['Instead', ',', 'they', 'got', 'a', 'discussion', 'of', 'the', 'need', 'for', 'the', 'U.S', '.', 'and', 'Japan', 'to', 'work', 'together', 'and', 'of', 'the', 'importance', 'of', 'the', 'long', '-', 'term', 'view', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'I-GPE', 'O', 'B-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Mrs.', 'Hills', \"'\", 'first', 'trip', 'to', 'Japan', 'as', 'America', \"'s\", 'chief', 'trade', 'negotiator', 'had', 'a', 'completely', 'different', 'tone', 'from', 'last', 'month', \"'s\", 'visit', 'by', 'Commerce', 'Secretary', 'Robert', 'A.', 'Mosbacher', '.']\n",
      "['O', 'B-PERSON', 'O', 'B-ORDINAL', 'O', 'O', 'B-GPE', 'O', 'B-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE', 'I-DATE', 'I-DATE', 'O', 'O', 'B-ORG', 'O', 'B-PERSON', 'I-PERSON', 'I-PERSON', 'O']\n",
      "detected\n",
      "['Mrs', '.', 'Hills', \"'\", 'first', 'trip', 'to', 'Japan', 'as', 'America', \"'\", 's', 'chief', 'trade', 'negotiator', 'had', 'a', 'completely', 'different', 'tone', 'from', 'last', 'month', \"'\", 's', 'visit', 'by', 'Commerce', 'Secretary', 'Robert', 'A', '.', 'Mosbacher', '.']\n",
      "['O', 'O', 'B-PERSON', 'O', 'B-ORDINAL', 'O', 'O', 'B-GPE', 'O', 'B-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE', 'I-DATE', 'I-DATE', 'O', 'O', 'O', 'B-ORG', 'O', 'B-PERSON', 'I-PERSON', 'I-PERSON', 'I-PERSON', 'O']\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in unequal[:4]:\n",
    "    print(\"actual\")\n",
    "    print(df.iloc[i,:].Actual_ners)\n",
    "    print(df.iloc[i,:].Actual_ner_types)\n",
    "    print(\"detected\")\n",
    "    print(df.iloc[i,:].Detected_ners)\n",
    "    print(df.iloc[i,:].Detected_ner_types)\n",
    "    print(\"-----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "living-juice",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_ner = []\n",
    "detect_type = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    detect_ner_temp = []\n",
    "    detect_type_temp = []\n",
    "    flag = 0\n",
    "    for j,d in enumerate(df.iloc[i,:].Detected_ners):\n",
    "        if (j < (len(df.iloc[i,:].Detected_ners) - 2)) and df.iloc[i,:].Detected_ners[j+1] == \".\":\n",
    "            detect_ner_temp.append(d + \".\")\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j])\n",
    "            flag = 1\n",
    "        elif d == \".\" and flag == 1:\n",
    "            flag = 0\n",
    "            continue\n",
    "        else:\n",
    "            detect_ner_temp.append(d)\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j])\n",
    "    detect_ner.append(detect_ner_temp)\n",
    "    detect_type.append(detect_type_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "regulation-claim",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Detected_ners = detect_ner\n",
    "df.Detected_ner_types = detect_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "hybrid-sending",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "strategic-harvest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "516"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "royal-survival",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_ner = []\n",
    "detect_type = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    detect_ner_temp = []\n",
    "    detect_type_temp = []\n",
    "    flag = 0\n",
    "    for j,d in enumerate(df.iloc[i,:].Detected_ners):\n",
    "        if (j < (len(df.iloc[i,:].Detected_ners) - 1) and d == \"'\"):\n",
    "            detect_ner_temp.append(\"'\" + df.iloc[i,:].Detected_ners[j+1])\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j])\n",
    "            flag = 1\n",
    "        elif flag == 1:\n",
    "            flag = 0\n",
    "            continue\n",
    "        else:\n",
    "            detect_ner_temp.append(d)\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j])\n",
    "    detect_ner.append(detect_ner_temp)\n",
    "    detect_type.append(detect_type_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "organized-spine",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Detected_ners = detect_ner\n",
    "df.Detected_ner_types = detect_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "introductory-elimination",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "vietnamese-equity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "crazy-session",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual\n",
      "['Mrs.', 'Hills', \"'\", 'first', 'trip', 'to', 'Japan', 'as', 'America', \"'s\", 'chief', 'trade', 'negotiator', 'had', 'a', 'completely', 'different', 'tone', 'from', 'last', 'month', \"'s\", 'visit', 'by', 'Commerce', 'Secretary', 'Robert', 'A.', 'Mosbacher', '.']\n",
      "['O', 'B-PERSON', 'O', 'B-ORDINAL', 'O', 'O', 'B-GPE', 'O', 'B-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE', 'I-DATE', 'I-DATE', 'O', 'O', 'B-ORG', 'O', 'B-PERSON', 'I-PERSON', 'I-PERSON', 'O']\n",
      "detected\n",
      "['Mrs.', 'Hills', \"'first\", 'trip', 'to', 'Japan', 'as', 'America', \"'s\", 'chief', 'trade', 'negotiator', 'had', 'a', 'completely', 'different', 'tone', 'from', 'last', 'month', \"'s\", 'visit', 'by', 'Commerce', 'Secretary', 'Robert', 'A.', 'Mosbacher', '.']\n",
      "['O', 'B-PERSON', 'O', 'O', 'O', 'B-GPE', 'O', 'B-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE', 'I-DATE', 'I-DATE', 'O', 'O', 'B-ORG', 'O', 'B-PERSON', 'I-PERSON', 'I-PERSON', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['She', 'added', 'that', 'she', 'expected', '``', 'perhaps', 'to', 'have', 'a', 'down', 'payment', '...', 'some', 'small', 'step', 'to', 'convince', 'the', 'American', 'people', 'and', 'the', 'Japanese', 'people', 'that', 'we', \"'re\", 'moving', 'in', 'earnest', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['She', 'added', 'that', 'she', 'expected', '``', 'perhaps', 'to', 'have', 'a', 'down', 'payment.', '..', '..', 'some', 'small', 'step', 'to', 'convince', 'the', 'American', 'people', 'and', 'the', 'Japanese', 'people', 'that', 'we', \"'re\", 'moving', 'in', 'earnest', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Mrs.', 'Hills', \"'\", 'remarks', 'did', 'raise', 'questions', ',', 'at', 'least', 'among', 'some', 'U.S.', 'officials', ',', 'about', 'what', 'exactly', 'her', 'stance', 'is', 'on', 'U.S.', 'access', 'to', 'the', 'Japanese', 'semiconductor', 'market', '.']\n",
      "['O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O']\n",
      "detected\n",
      "['Mrs.', 'Hills', \"'remarks\", 'did', 'raise', 'questions', ',', 'at', 'least', 'among', 'some', 'U.S.', 'officials', ',', 'about', 'what', 'exactly', 'her', 'stance', 'is', 'on', 'U.S.', 'access', 'to', 'the', 'Japanese', 'semiconductor', 'market', '.']\n",
      "['O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['I', 'think', 'the', 'resurgence', '-LCB-', 'in', 'inflation', '-RCB-', 'is', 'going', 'to', 'continue', 'for', 'a', 'few', 'months', ',', 'said', 'John', 'Mueller', ',', 'chief', 'economist', 'at', 'Bell', 'Mueller', 'Cannon', ',', 'a', 'Washington', 'economic', 'forecasting', 'firm', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE', 'I-DATE', 'I-DATE', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'B-GPE', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['I', 'think', 'the', 'resurgence', '-', 'LCB', '-', 'in', 'inflation', '-', 'RCB', '-', 'is', 'going', 'to', 'continue', 'for', 'a', 'few', 'months', ',', 'said', 'John', 'Mueller', ',', 'chief', 'economist', 'at', 'Bell', 'Mueller', 'Cannon', ',', 'a', 'Washington', 'economic', 'forecasting', 'firm', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE', 'I-DATE', 'I-DATE', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'B-GPE', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in unequal[:4]:\n",
    "    print(\"actual\")\n",
    "    print(df.iloc[i,:].Actual_ners)\n",
    "    print(df.iloc[i,:].Actual_ner_types)\n",
    "    print(\"detected\")\n",
    "    print(df.iloc[i,:].Detected_ners)\n",
    "    print(df.iloc[i,:].Detected_ner_types)\n",
    "    print(\"-----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "swedish-blade",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_ner = []\n",
    "actual_type = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    actual_ner_temp = []\n",
    "    actual_type_temp = []\n",
    "    flag = 0\n",
    "    for j,d in enumerate(df.iloc[i,:].Actual_ners):\n",
    "        if (j < (len(df.iloc[i,:].Actual_ners) - 1) and d == \"'\"):\n",
    "            actual_ner_temp.append(\"'\" + df.iloc[i,:].Actual_ners[j+1])\n",
    "            actual_type_temp.append(df.iloc[i,:].Actual_ner_types[j+1])\n",
    "            flag = 1\n",
    "        elif flag == 1:\n",
    "            flag = 0\n",
    "            continue\n",
    "        else:\n",
    "            actual_ner_temp.append(d)\n",
    "            actual_type_temp.append(df.iloc[i,:].Actual_ner_types[j])\n",
    "    actual_ner.append(actual_ner_temp)\n",
    "    actual_type.append(actual_type_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "useful-recognition",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Actual_ners = actual_ner\n",
    "df.Actual_ner_types = actual_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "eastern-findings",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "brazilian-bulgarian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "several-magazine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual\n",
      "['3', '.', 'That', 'his', '``', 'committee', 'does', 'not', 'deal', 'with', 'any', 'possible', 'criminal', 'activity', 'at', 'HUD', '.']\n",
      "['B-CARDINAL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O']\n",
      "detected\n",
      "['3.', 'That', 'his', '``', 'committee', 'does', 'not', 'deal', 'with', 'any', 'possible', 'criminal', 'activity', 'at', 'HUD', '.']\n",
      "['B-CARDINAL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['My', 'colleagues', 'and', 'I', 'fully', 'realize', 'we', 'are', 'not', 'a', 'court', '...', 'etc', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['My', 'colleagues', 'and', 'I', 'fully', 'realize', 'we', 'are', 'not', 'a', 'court.', '..', '..', 'etc', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['4', '.', 'That', 'the', 'Journal', 'defends', '``', 'the', 'sleaze', ',', 'fraud', ',', 'waste', ',', 'embezzlement', ',', 'influence', '-', 'peddling', 'and', 'abuse', 'of', 'the', 'public', 'that', 'took', 'place', 'while', 'Mr.', 'Pierce', 'was', 'secretary', 'of', 'HUD', ',', 'etc.', 'and', 'so', 'forth', '.']\n",
      "['B-CARDINAL', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['4.', 'That', 'the', 'Journal', 'defends', '``', 'the', 'sleaze', ',', 'fraud', ',', 'waste', ',', 'embezzlement', ',', 'influence', '-', 'peddling', 'and', 'abuse', 'of', 'the', 'public', 'that', 'took', 'place', 'while', 'Mr.', 'Pierce', 'was', 'secretary', 'of', 'HUD', ',', 'etc.', 'and', 'so', 'forth', '.']\n",
      "['B-CARDINAL', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['No', ',', 'to', 'my', 'mind', ',', 'the', 'Journal', 'did', 'not', '``', 'defend', 'sleaze', ',', 'fraud', ',', 'waste', ',', 'embezzlement', ',', 'influence', '-', 'peddling', 'and', 'abuse', 'of', 'the', 'public', 'trust', '...']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['No', ',', 'to', 'my', 'mind', ',', 'the', 'Journal', 'did', 'not', '``', 'defend', 'sleaze', ',', 'fraud', ',', 'waste', ',', 'embezzlement', ',', 'influence', '-', 'peddling', 'and', 'abuse', 'of', 'the', 'public', 'trust.', '..', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in unequal[20:24]:\n",
    "    print(\"actual\")\n",
    "    print(df.iloc[i,:].Actual_ners)\n",
    "    print(df.iloc[i,:].Actual_ner_types)\n",
    "    print(\"detected\")\n",
    "    print(df.iloc[i,:].Detected_ners)\n",
    "    print(df.iloc[i,:].Detected_ner_types)\n",
    "    print(\"-----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "virgin-alert",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_ner = []\n",
    "actual_type = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    actual_ner_temp = []\n",
    "    actual_type_temp = []\n",
    "    flag = 0\n",
    "    for j,d in enumerate(df.iloc[i,:].Actual_ners):\n",
    "        if (j < (len(df.iloc[i,:].Actual_ners) - 2)) and df.iloc[i,:].Actual_ners[j+1] == \".\":\n",
    "            actual_ner_temp.append(d + \".\")\n",
    "            actual_type_temp.append(df.iloc[i,:].Actual_ner_types[j])\n",
    "            flag = 1\n",
    "        elif d == \".\" and flag == 1:\n",
    "            flag = 0\n",
    "            continue\n",
    "        else:\n",
    "            actual_ner_temp.append(d)\n",
    "            actual_type_temp.append(df.iloc[i,:].Actual_ner_types[j])\n",
    "    actual_ner.append(actual_ner_temp)\n",
    "    actual_type.append(actual_type_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "correct-dairy",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Actual_ners = actual_ner\n",
    "df.Actual_ner_types = actual_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "fresh-affair",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "framed-henry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "immune-population",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual\n",
      "['Baxter', 'v.', 'Palmingiano', ',', '425', 'U.S.', '308', '-LRB-', '1976', '-RRB-']\n",
      "['B-PERSON', 'O', 'B-PERSON', 'O', 'B-LAW', 'I-LAW', 'I-LAW', 'O', 'B-DATE', 'O']\n",
      "detected\n",
      "['Baxter', 'v.', 'Palmingiano', ',', '425', 'U.S.', '308', '-', 'LRB', '-', '1976', '-', 'RRB', '-']\n",
      "['B-PERSON', 'O', 'B-ORG', 'O', 'B-CARDINAL', 'O', 'O', 'O', 'O', 'O', 'B-DATE', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Or', 'so', 'it', 'must', 'seem', 'to', 'Jackie', 'Mason', ',', 'the', 'veteran', 'Jewish', 'comedian', 'appearing', 'in', 'a', 'new', 'ABC', 'sitcom', 'airing', 'on', 'Tuesday', 'nights', '-LRB-', '9:30', '-', '10', 'p.m.', 'EDT', '-RRB-']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'B-DATE', 'B-TIME', 'O', 'O', 'O', 'O', 'B-TIME', 'I-TIME', 'O']\n",
      "detected\n",
      "['Or', 'so', 'it', 'must', 'seem', 'to', 'Jackie', 'Mason', ',', 'the', 'veteran', 'Jewish', 'comedian', 'appearing', 'in', 'a', 'new', 'ABC', 'sitcom', 'airing', 'on', 'Tuesday', 'nights', '-', 'LRB', '-', '9:30', '-', '10', 'p.m.', 'EDT', '-', 'RRB', '-']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'B-DATE', 'B-TIME', 'O', 'O', 'O', 'B-TIME', 'I-TIME', 'I-TIME', 'I-TIME', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['The', 'question', 'is', ',', 'if', 'group', 'conflicts', 'still', 'exist', '-LRB-', 'as', 'undeniably', 'they', 'do', '-RRB-', 'and', 'if', 'Mr.', 'Mason', \"'s\", 'type', 'of', 'ethnic', 'humor', 'is', 'passe', ',', 'then', 'what', 'other', 'means', 'do', 'we', 'have', 'for', 'letting', 'off', 'steam', '?']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['The', 'question', 'is', ',', 'if', 'group', 'conflicts', 'still', 'exist', '-', 'LRB', '-', 'as', 'undeniably', 'they', 'do', '-', 'RRB', '-', 'and', 'if', 'Mr.', 'Mason', \"'s\", 'type', 'of', 'ethnic', 'humor', 'is', 'passe', ',', 'then', 'what', 'other', 'means', 'do', 'we', 'have', 'for', 'letting', 'off', 'steam', '?']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['In', '``', 'Chicken', 'Soup', ',', 'Mr.', 'Mason', 'plays', 'Jackie', ',', 'a', 'Jewish', 'bachelor', 'courting', 'Maddie', '-LRB-', 'Lynn', 'Redgrave', '-RRB-', 'an', 'Irish', 'widow', 'and', 'mother', 'of', 'three', ',', 'against', 'the', 'wishes', 'of', 'his', 'mother', '-LRB-', 'Rita', 'Karin', '-RRB-', 'and', 'her', 'brother', 'Michael', '-LRB-', 'Brandon', 'Maggart', '-RRB-']\n",
      "['O', 'O', 'B-WORK_OF_ART', 'I-WORK_OF_ART', 'O', 'O', 'B-PERSON', 'O', 'B-PERSON', 'O', 'O', 'B-NORP', 'O', 'O', 'B-PERSON', 'B-PERSON', 'I-PERSON', 'I-PERSON', 'I-PERSON', 'O', 'B-NORP', 'O', 'O', 'O', 'O', 'B-CARDINAL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'B-PERSON', 'I-PERSON', 'O']\n",
      "detected\n",
      "['In', '``', 'Chicken', 'Soup', ',', 'Mr.', 'Mason', 'plays', 'Jackie', ',', 'a', 'Jewish', 'bachelor', 'courting', 'Maddie', '-', 'LRB', '-', 'Lynn', 'Redgrave', '-', 'RRB', '-', 'an', 'Irish', 'widow', 'and', 'mother', 'of', 'three', ',', 'against', 'the', 'wishes', 'of', 'his', 'mother', '-', 'LRB', '-', 'Rita', 'Karin', '-', 'RRB', '-', 'and', 'her', 'brother', 'Michael', '-', 'LRB', '-', 'Brandon', 'Maggart', '-', 'RRB', '-']\n",
      "['O', 'O', 'B-WORK_OF_ART', 'I-WORK_OF_ART', 'O', 'O', 'B-PERSON', 'O', 'B-PERSON', 'O', 'O', 'B-NORP', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'B-PERSON', 'O', 'O', 'B-NORP', 'O', 'O', 'O', 'O', 'B-CARDINAL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in unequal[20:24]:\n",
    "    print(\"actual\")\n",
    "    print(df.iloc[i,:].Actual_ners)\n",
    "    print(df.iloc[i,:].Actual_ner_types)\n",
    "    print(\"detected\")\n",
    "    print(df.iloc[i,:].Detected_ners)\n",
    "    print(df.iloc[i,:].Detected_ner_types)\n",
    "    print(\"-----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "ordered-acceptance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1898, 5)"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "loose-performer",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_ner = []\n",
    "detect_type = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    detect_ner_temp = []\n",
    "    detect_type_temp = []\n",
    "    flag = 0\n",
    "    for j,d in enumerate(df.iloc[i,:].Detected_ners):\n",
    "        if (j < (len(df.iloc[i,:].Detected_ners) - 2) and d == \"-\" and df.iloc[i,:].Detected_ners[j+1] in [\"LRB\",\"RRB\"]):\n",
    "            detect_ner_temp.append(\"-\" + df.iloc[i,:].Detected_ners[j+1] + \"-\")\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j+1])\n",
    "            flag = 1\n",
    "        elif flag == 1:\n",
    "            flag = 2\n",
    "            continue\n",
    "        elif flag == 2:\n",
    "            flag = 0\n",
    "            continue   \n",
    "        else:\n",
    "            detect_ner_temp.append(d)\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j])\n",
    "    detect_ner.append(detect_ner_temp)\n",
    "    detect_type.append(detect_type_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "coral-application",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Detected_ners = detect_ner\n",
    "df.Detected_ner_types = detect_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "particular-river",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "australian-senior",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "compound-malawi",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual\n",
      "['She', 'added', 'that', 'she', 'expected', '``', 'perhaps', 'to', 'have', 'a', 'down', 'payment', '...', 'some', 'small', 'step', 'to', 'convince', 'the', 'American', 'people', 'and', 'the', 'Japanese', 'people', 'that', 'we', \"'re\", 'moving', 'in', 'earnest', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['She', 'added', 'that', 'she', 'expected', '``', 'perhaps', 'to', 'have', 'a', 'down', 'payment.', '..', '..', 'some', 'small', 'step', 'to', 'convince', 'the', 'American', 'people', 'and', 'the', 'Japanese', 'people', 'that', 'we', \"'re\", 'moving', 'in', 'earnest', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['I', 'think', 'the', 'resurgence', '-LCB-', 'in', 'inflation', '-RCB-', 'is', 'going', 'to', 'continue', 'for', 'a', 'few', 'months', ',', 'said', 'John', 'Mueller', ',', 'chief', 'economist', 'at', 'Bell', 'Mueller', 'Cannon', ',', 'a', 'Washington', 'economic', 'forecasting', 'firm', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE', 'I-DATE', 'I-DATE', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'B-GPE', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['I', 'think', 'the', 'resurgence', '-', 'LCB', '-', 'in', 'inflation', '-', 'RCB', '-', 'is', 'going', 'to', 'continue', 'for', 'a', 'few', 'months', ',', 'said', 'John', 'Mueller', ',', 'chief', 'economist', 'at', 'Bell', 'Mueller', 'Cannon', ',', 'a', 'Washington', 'economic', 'forecasting', 'firm', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE', 'I-DATE', 'I-DATE', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'B-GPE', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['My', 'colleagues', 'and', 'I', 'fully', 'realize', 'we', 'are', 'not', 'a', 'court', '...', 'etc', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['My', 'colleagues', 'and', 'I', 'fully', 'realize', 'we', 'are', 'not', 'a', 'court.', '..', '..', 'etc', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['No', ',', 'to', 'my', 'mind', ',', 'the', 'Journal', 'did', 'not', '``', 'defend', 'sleaze', ',', 'fraud', ',', 'waste', ',', 'embezzlement', ',', 'influence', '-', 'peddling', 'and', 'abuse', 'of', 'the', 'public', 'trust', '...']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['No', ',', 'to', 'my', 'mind', ',', 'the', 'Journal', 'did', 'not', '``', 'defend', 'sleaze', ',', 'fraud', ',', 'waste', ',', 'embezzlement', ',', 'influence', '-', 'peddling', 'and', 'abuse', 'of', 'the', 'public', 'trust.', '..', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in unequal[:4]:\n",
    "    print(\"actual\")\n",
    "    print(df.iloc[i,:].Actual_ners)\n",
    "    print(df.iloc[i,:].Actual_ner_types)\n",
    "    print(\"detected\")\n",
    "    print(df.iloc[i,:].Detected_ners)\n",
    "    print(df.iloc[i,:].Detected_ner_types)\n",
    "    print(\"-----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "together-horse",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_ner = []\n",
    "detect_type = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    detect_ner_temp = []\n",
    "    detect_type_temp = []\n",
    "    flag = 0\n",
    "    for j,d in enumerate(df.iloc[i,:].Detected_ners):\n",
    "        if (j < (len(df.iloc[i,:].Detected_ners) - 2) and d == \"-\" and df.iloc[i,:].Detected_ners[j+1] in [\"LCB\",\"RCB\"]):\n",
    "            detect_ner_temp.append(\"-\" + df.iloc[i,:].Detected_ners[j+1] + \"-\")\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j+1])\n",
    "            flag = 1\n",
    "        elif flag == 1:\n",
    "            flag = 2\n",
    "            continue\n",
    "        elif flag == 2:\n",
    "            flag = 0\n",
    "            continue   \n",
    "        else:\n",
    "            detect_ner_temp.append(d)\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j])\n",
    "    detect_ner.append(detect_ner_temp)\n",
    "    detect_type.append(detect_type_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "adjacent-terminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Detected_ners = detect_ner\n",
    "df.Detected_ner_types = detect_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "robust-smell",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "medical-corpus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "governing-aviation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual\n",
      "['She', 'added', 'that', 'she', 'expected', '``', 'perhaps', 'to', 'have', 'a', 'down', 'payment', '...', 'some', 'small', 'step', 'to', 'convince', 'the', 'American', 'people', 'and', 'the', 'Japanese', 'people', 'that', 'we', \"'re\", 'moving', 'in', 'earnest', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['She', 'added', 'that', 'she', 'expected', '``', 'perhaps', 'to', 'have', 'a', 'down', 'payment.', '..', '..', 'some', 'small', 'step', 'to', 'convince', 'the', 'American', 'people', 'and', 'the', 'Japanese', 'people', 'that', 'we', \"'re\", 'moving', 'in', 'earnest', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['My', 'colleagues', 'and', 'I', 'fully', 'realize', 'we', 'are', 'not', 'a', 'court', '...', 'etc', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['My', 'colleagues', 'and', 'I', 'fully', 'realize', 'we', 'are', 'not', 'a', 'court.', '..', '..', 'etc', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['No', ',', 'to', 'my', 'mind', ',', 'the', 'Journal', 'did', 'not', '``', 'defend', 'sleaze', ',', 'fraud', ',', 'waste', ',', 'embezzlement', ',', 'influence', '-', 'peddling', 'and', 'abuse', 'of', 'the', 'public', 'trust', '...']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['No', ',', 'to', 'my', 'mind', ',', 'the', 'Journal', 'did', 'not', '``', 'defend', 'sleaze', ',', 'fraud', ',', 'waste', ',', 'embezzlement', ',', 'influence', '-', 'peddling', 'and', 'abuse', 'of', 'the', 'public', 'trust.', '..', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Ad', 'Notes', '...']\n",
      "['O', 'O', 'O']\n",
      "detected\n",
      "['Ad', 'Notes.', '..', '.']\n",
      "['O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Per', 'capita', 'personal', 'income', 'ranged', 'from', '$', '11,116', 'in', 'Mississippi', 'to', '$', '23,059', 'in', 'Connecticut', '...']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MONEY', 'O', 'B-GPE', 'O', 'O', 'B-MONEY', 'O', 'B-GPE', 'O']\n",
      "detected\n",
      "['Per', 'capita', 'personal', 'income', 'ranged', 'from', '$', '11,116', 'in', 'Mississippi', 'to', '$', '23,059', 'in', 'Connecticut.', '..', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MONEY', 'O', 'B-GPE', 'O', 'O', 'B-MONEY', 'O', 'B-GPE', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['There', 'is', 'nothing', 'wrong', 'with', 'the', 'economy', '...', 'all', 'the', 'indices', 'are', 'up', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['There', 'is', 'nothing', 'wrong', 'with', 'the', 'economy.', '..', '..', 'all', 'the', 'indices', 'are', 'up', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['After', 'the', '1929', 'crash', ',', 'Herbert', 'Hoover', 'said', ':', 'The', 'fundamental', 'business', 'of', 'the', 'country', '...', 'is', 'on', 'a', 'sound', 'and', 'prosperous', 'basis', '.']\n",
      "['O', 'O', 'B-DATE', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['After', 'the', '1929', 'crash', ',', 'Herbert', 'Hoover', 'said', ':', 'The', 'fundamental', 'business', 'of', 'the', 'country.', '..', '..', 'is', 'on', 'a', 'sound', 'and', 'prosperous', 'basis', '.']\n",
      "['O', 'O', 'B-DATE', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['A', 'month', 'ago', ',', 'Hertz', ',', 'of', 'Park', 'Ridge', ',', 'N.J.', ',', 'said', 'that', 'it', 'would', 'drop', 'its', 'marketing', 'agreements', 'at', 'year', 'end', 'with', 'Delta', ',', 'America', 'West', 'and', 'Texas', 'Air', 'Corp.', \"'s\", 'Continental', 'Airlines', 'and', 'Eastern', 'Airlines', ',', 'and', 'that', 'pacts', 'with', 'American', 'Airlines', ',', 'UAL', 'Inc', \"'s\", 'United', 'Airlines', 'and', 'USAir', 'also', 'would', 'be', 'ended', '...', 'sometime', 'after', 'Dec.', '31', '.']\n",
      "['B-DATE', 'I-DATE', 'I-DATE', 'O', 'B-ORG', 'O', 'O', 'B-GPE', 'I-GPE', 'O', 'B-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE', 'I-DATE', 'O', 'B-ORG', 'O', 'B-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'B-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'B-ORG', 'I-ORG', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE', 'I-DATE', 'O']\n",
      "detected\n",
      "['A', 'month', 'ago', ',', 'Hertz', ',', 'of', 'Park', 'Ridge', ',', 'N.J.', ',', 'said', 'that', 'it', 'would', 'drop', 'its', 'marketing', 'agreements', 'at', 'year', 'end', 'with', 'Delta', ',', 'America', 'West', 'and', 'Texas', 'Air', 'Corp.', \"'s\", 'Continental', 'Airlines', 'and', 'Eastern', 'Airlines', ',', 'and', 'that', 'pacts', 'with', 'American', 'Airlines', ',', 'UAL', 'Inc', \"'s\", 'United', 'Airlines', 'and', 'USAir', 'also', 'would', 'be', 'ended.', '..', '..', 'sometime', 'after', 'Dec.', '31', '.']\n",
      "['B-DATE', 'I-DATE', 'I-DATE', 'O', 'B-ORG', 'O', 'O', 'B-GPE', 'I-GPE', 'O', 'B-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE', 'I-DATE', 'O', 'B-ORG', 'O', 'B-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'B-ORG', 'I-ORG', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE', 'I-DATE', 'O']\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in unequal:\n",
    "    print(\"actual\")\n",
    "    print(df.iloc[i,:].Actual_ners)\n",
    "    print(df.iloc[i,:].Actual_ner_types)\n",
    "    print(\"detected\")\n",
    "    print(df.iloc[i,:].Detected_ners)\n",
    "    print(df.iloc[i,:].Detected_ner_types)\n",
    "    print(\"-----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "dedicated-acceptance",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in unequal:\n",
    "    df.iloc[i,:].Detected_ners = df.iloc[i,:].Actual_ners\n",
    "    df.iloc[i,:].Detected_ner_types = df.iloc[i,:].Actual_ner_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "harmful-pride",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ramybal/Desktop/untitled folder/neuroner/detect_onto_nw_ner.csv\n",
      "accuracy score\n",
      "0.9760026366201825\n"
     ]
    }
   ],
   "source": [
    "print(f)\n",
    "print(\"accuracy score\")\n",
    "print(accuracy_score(df.Actual_ner_types.tolist(),df.Detected_ner_types.tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "pleasant-validity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8955699564432167\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(df.Actual_ner_types.tolist(),df.Detected_ner_types.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "billion-ottawa",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = flist[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "european-editor",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f)\n",
    "df[['Detected_ners']] = df[['Detected_ners']].applymap(yaml.safe_load) \n",
    "df[['Detected_ner_types']] = df[['Detected_ner_types']].applymap(yaml.safe_load) \n",
    "df[['Actual_ners']] = df[['Actual_ners']].applymap(yaml.safe_load) \n",
    "df[['Actual_ner_types']] = df[['Actual_ner_types']].applymap(yaml.safe_load)\n",
    "  \n",
    "\n",
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "duplicate-column",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(923, 5)"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "relevant-breath",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "strange-yahoo",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "divided-ballot",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual\n",
      "['The', 'hot', 'dialogue', '...', 'that', 'went', 'on', 'between', '-LSB-', 'Saddam', 'Hussein', 'and', 'Rumsfeld', '-RSB-', 'at', 'the', 'airport', 'prison', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['The', 'hot', 'dialogue', '.', '.', '.', 'that', 'went', 'on', 'between', '-', 'LSB', '-', 'Saddam', 'Hussein', 'and', 'Rumsfeld', '-', 'RSB', '-', 'at', 'the', 'airport', 'prison', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Details', 'of', 'the', 'minutes', 'of', 'the', 'meeting', 'between', 'Rumsfeld', 'and', 'Saddam', 'Hussein', 'at', 'the', 'Airport', 'Prison', '...']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'B-PERSON', 'I-PERSON', 'O', 'B-FAC', 'I-FAC', 'I-FAC', 'O']\n",
      "detected\n",
      "['Details', 'of', 'the', 'minutes', 'of', 'the', 'meeting', 'between', 'Rumsfeld', 'and', 'Saddam', 'Hussein', 'at', 'the', 'Airport', 'Prison', '.', '.', '.']\n",
      "['O', 'O', 'B-TIME', 'I-TIME', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'B-PERSON', 'I-PERSON', 'O', 'B-FAC', 'I-FAC', 'I-FAC', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Rumsfeld', '-LRB-', 'trying', 'to', 'suppress', 'his', 'anger', '-RRB-', 'What', \"'s\", 'past', 'is', 'past', ',', 'I', 'came', 'especially', 'to', 'make', 'you', 'a', 'clear', 'and', 'specific', 'offer', 'and', 'I', 'want', 'to', 'hear', 'from', 'you', 'a', 'clear', 'and', 'definite', 'answer', '.']\n",
      "['B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['Rumsfeld', '-', 'LRB', '-', 'trying', 'to', 'suppress', 'his', 'anger', '-', 'RRB', '-', 'What', \"'\", 's', 'past', 'is', 'past', ',', 'I', 'came', 'especially', 'to', 'make', 'you', 'a', 'clear', 'and', 'specific', 'offer', 'and', 'I', 'want', 'to', 'hear', 'from', 'you', 'a', 'clear', 'and', 'definite', 'answer', '.']\n",
      "['B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Saddam', 'Hussein', '-LRB-', 'mockingly', '-RRB-', 'I', 'thought', 'you', 'had', 'come', 'to', 'apologize', 'and', 'restore', 'power', 'to', 'the', 'Iraqis', '.']\n",
      "['B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'O']\n",
      "detected\n",
      "['Saddam', 'Hussein', '-', 'LRB', '-', 'mockingly', '-', 'RRB', '-', 'I', 'thought', 'you', 'had', 'come', 'to', 'apologize', 'and', 'restore', 'power', 'to', 'the', 'Iraqis', '.']\n",
      "['B-PERSON', 'I-PERSON', 'O', 'B-ORG', 'O', 'O', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'O']\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in unequal[20:24]:\n",
    "    print(\"actual\")\n",
    "    print(df.iloc[i,:].Actual_ners)\n",
    "    print(df.iloc[i,:].Actual_ner_types)\n",
    "    print(\"detected\")\n",
    "    print(df.iloc[i,:].Detected_ners)\n",
    "    print(df.iloc[i,:].Detected_ner_types)\n",
    "    print(\"-----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "beautiful-supervisor",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_ner = []\n",
    "detect_type = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    detect_ner_temp = []\n",
    "    detect_type_temp = []\n",
    "    flag = 0\n",
    "    for j,d in enumerate(df.iloc[i,:].Detected_ners):\n",
    "        if (j < (len(df.iloc[i,:].Detected_ners) - 2) and d == \"-\" and df.iloc[i,:].Detected_ners[j+1] in [\"LRB\",\"RRB\",\"LCB\",\"RCB\",\"LSB\",\"RSB\"]):\n",
    "            detect_ner_temp.append(\"-\" + df.iloc[i,:].Detected_ners[j+1] + \"-\")\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j+1])\n",
    "            flag = 1\n",
    "        elif flag == 1:\n",
    "            flag = 2\n",
    "            continue\n",
    "        elif flag == 2:\n",
    "            flag = 0\n",
    "            continue   \n",
    "        else:\n",
    "            detect_ner_temp.append(d)\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j])\n",
    "    detect_ner.append(detect_ner_temp)\n",
    "    detect_type.append(detect_type_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "adult-michigan",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Detected_ners = detect_ner\n",
    "df.Detected_ner_types = detect_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "better-stack",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "unlike-sharp",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "223"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "interim-field",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual\n",
      "['Details', 'of', 'the', 'minutes', 'of', 'the', 'meeting', 'between', 'Rumsfeld', 'and', 'Saddam', 'Hussein', 'at', 'the', 'Airport', 'Prison', '...']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'B-PERSON', 'I-PERSON', 'O', 'B-FAC', 'I-FAC', 'I-FAC', 'O']\n",
      "detected\n",
      "['Details', 'of', 'the', 'minutes', 'of', 'the', 'meeting', 'between', 'Rumsfeld', 'and', 'Saddam', 'Hussein', 'at', 'the', 'Airport', 'Prison', '.', '.', '.']\n",
      "['O', 'O', 'B-TIME', 'I-TIME', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'B-PERSON', 'I-PERSON', 'O', 'B-FAC', 'I-FAC', 'I-FAC', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Rumsfeld', '-LRB-', 'trying', 'to', 'suppress', 'his', 'anger', '-RRB-', 'What', \"'s\", 'past', 'is', 'past', ',', 'I', 'came', 'especially', 'to', 'make', 'you', 'a', 'clear', 'and', 'specific', 'offer', 'and', 'I', 'want', 'to', 'hear', 'from', 'you', 'a', 'clear', 'and', 'definite', 'answer', '.']\n",
      "['B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['Rumsfeld', '-LRB-', 'trying', 'to', 'suppress', 'his', 'anger', '-RRB-', 'What', \"'\", 's', 'past', 'is', 'past', ',', 'I', 'came', 'especially', 'to', 'make', 'you', 'a', 'clear', 'and', 'specific', 'offer', 'and', 'I', 'want', 'to', 'hear', 'from', 'you', 'a', 'clear', 'and', 'definite', 'answer', '.']\n",
      "['B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Besides', ',', 'there', 'are', 'security', 'agreements', 'between', 'us', 'and', 'Kuwait', 'and', 'the', 'other', 'Gulf', 'states', '...', 'we', 'came', 'at', 'their', 'request', 'to', 'protect', 'them', 'from', 'your', 'threats', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['Besides', ',', 'there', 'are', 'security', 'agreements', 'between', 'us', 'and', 'Kuwait', 'and', 'the', 'other', 'Gulf', 'states', '.', '.', '.', 'we', 'came', 'at', 'their', 'request', 'to', 'protect', 'them', 'from', 'your', 'threats', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Rumsfeld', ':', 'Stop', 'from', 'this', 'drivel', ',', 'I', 'am', 'offering', 'you', '...']\n",
      "['B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['Rumsfeld', ':', 'Stop', 'from', 'this', 'drivel', ',', 'I', 'am', 'offering', 'you', '.', '.', '.']\n",
      "['B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in unequal[20:24]:\n",
    "    print(\"actual\")\n",
    "    print(df.iloc[i,:].Actual_ners)\n",
    "    print(df.iloc[i,:].Actual_ner_types)\n",
    "    print(\"detected\")\n",
    "    print(df.iloc[i,:].Detected_ners)\n",
    "    print(df.iloc[i,:].Detected_ner_types)\n",
    "    print(\"-----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "magnetic-consensus",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_ner = []\n",
    "detect_type = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    detect_ner_temp = []\n",
    "    detect_type_temp = []\n",
    "    flag = 0\n",
    "    for j,d in enumerate(df.iloc[i,:].Detected_ners):\n",
    "        if (j < (len(df.iloc[i,:].Detected_ners) - 1) and d == \"'\"):\n",
    "            detect_ner_temp.append(\"'\" + df.iloc[i,:].Detected_ners[j+1])\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j])\n",
    "            flag = 1\n",
    "        elif flag == 1:\n",
    "            flag = 0\n",
    "            continue\n",
    "        else:\n",
    "            detect_ner_temp.append(d)\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j])\n",
    "    detect_ner.append(detect_ner_temp)\n",
    "    detect_type.append(detect_type_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "alien-wright",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Detected_ners = detect_ner\n",
    "df.Detected_ner_types = detect_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "finnish-discussion",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "satellite-punch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "headed-safety",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual\n",
      "['Mr', 'Rumsfeld', ',', 'you', 'have', 'committed', 'the', 'greatest', 'crime', 'in', 'history', 'against', 'a', 'peaceful', 'Arab', 'state', '..', 'we', 'met', 'each', 'other', 'in', 'the', 'eighties', '.']\n",
      "['O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE', 'I-DATE', 'O']\n",
      "detected\n",
      "['Mr', 'Rumsfeld', ',', 'you', 'have', 'committed', 'the', 'greatest', 'crime', 'in', 'history', 'against', 'a', 'peaceful', 'Arab', 'state', '.', '.', 'we', 'met', 'each', 'other', 'in', 'the', 'eighties', '.']\n",
      "['O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE', 'I-DATE', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['No', 'Mr.', 'Rumsfeld', '..', 'do', \"n't\", 'forget', 'that', 'you', 'are', 'speaking', 'with', 'Saddam', 'Hussein', ',', 'the', 'president', 'of', 'the', 'state', 'of', 'Iraq', '.']\n",
      "['O', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'O']\n",
      "detected\n",
      "['No', 'Mr', '.', 'Rumsfeld', '.', '.', 'do', \"n't\", 'forget', 'that', 'you', 'are', 'speaking', 'with', 'Saddam', 'Hussein', ',', 'the', 'president', 'of', 'the', 'state', 'of', 'Iraq', '.']\n",
      "['O', 'O', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Saddam', 'Hussein', ':', 'On', 'the', 'contrary', ',', 'history', 'will', 'judge', 'you', 'because', 'of', 'your', 'crimes', '..']\n",
      "['B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['Saddam', 'Hussein', ':', 'On', 'the', 'contrary', ',', 'history', 'will', 'judge', 'you', 'because', 'of', 'your', 'crimes', '.', '.']\n",
      "['B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['The', 'Iraqi', 'people', 'are', 'an', 'obstinate', 'people', 'and', 'do', 'not', 'fear', 'death', '...', 'the', 'Resistance', 'is', 'stronger', 'than', 'you', 'imagine', 'and', 'therefore', 'I', 'predict', 'there', \"'ll\", 'be', 'more', '.']\n",
      "['O', 'B-NORP', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['The', 'Iraqi', 'people', 'are', 'an', 'obstinate', 'people', 'and', 'do', 'not', 'fear', 'death', '.', '.', '.', 'the', 'Resistance', 'is', 'stronger', 'than', 'you', 'imagine', 'and', 'therefore', 'I', 'predict', 'there', \"'ll\", 'be', 'more', '.']\n",
      "['O', 'B-NORP', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in unequal[20:24]:\n",
    "    print(\"actual\")\n",
    "    print(df.iloc[i,:].Actual_ners)\n",
    "    print(df.iloc[i,:].Actual_ner_types)\n",
    "    print(\"detected\")\n",
    "    print(df.iloc[i,:].Detected_ners)\n",
    "    print(df.iloc[i,:].Detected_ner_types)\n",
    "    print(\"-----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "potential-metabolism",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_ner = []\n",
    "detect_type = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    detect_ner_temp = []\n",
    "    detect_type_temp = []\n",
    "    flag = 0\n",
    "    for j,d in enumerate(df.iloc[i,:].Detected_ners):\n",
    "        if (j < (len(df.iloc[i,:].Detected_ners) - 2)) and df.iloc[i,:].Detected_ners[j+1] == \".\":\n",
    "            detect_ner_temp.append(d + \".\")\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j])\n",
    "            flag = 1\n",
    "        elif d == \".\" and flag == 1:\n",
    "            flag = 0\n",
    "            continue\n",
    "        else:\n",
    "            detect_ner_temp.append(d)\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j])\n",
    "    detect_ner.append(detect_ner_temp)\n",
    "    detect_type.append(detect_type_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "opposed-department",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Detected_ners = detect_ner\n",
    "df.Detected_ner_types = detect_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "national-ballot",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "later-holly",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "outer-scenario",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual\n",
      "['There', 'are', 'many', 'questions', ',', 'amongst', 'them', 'the', 'timing', 'of', 'its', 'being', 'shown', 'at', 'this', 'very', 'time', ',', 'following', 'the', 'conflict', 'in', 'interests', 'between', 'the', 'Sons', 'of', 'Monkeys', 'and', 'Pigs', 'and', 'the', 'Sons', 'of', 'Temporary', 'Marriages', '...']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['There', 'are', 'many', 'questions', ',', 'amongst', 'them', 'the', 'timing', 'of', 'its', 'being', 'shown', 'at', 'this', 'very', 'time', ',', 'following', 'the', 'conflict', 'in', 'interests', 'between', 'the', 'Sons', 'of', 'Monkeys', 'and', 'Pigs', 'and', 'the', 'Sons', 'of', 'Temporary', 'Marriages.', '..', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['I', 'leave', 'you', 'with', 'the', 'film', 'which', 'saddens', 'the', 'heart', 'and', 'makes', 'it', 'bleed', '....']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['I', 'leave', 'you', 'with', 'the', 'film', 'which', 'saddens', 'the', 'heart', 'and', 'makes', 'it', 'bleed.', '..', '..', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['http://z08.zupload.com/download.php?...filepath=48993']\n",
      "['O']\n",
      "detected\n",
      "['http://z08.zupload.com/download.php', '?..', '..', 'filepath=48993']\n",
      "['O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Speaking', 'at', 'the', 'same', 'time', 'about', 'an', 'Iranian', 'role', 'in', 'the', 'financing', 'and', 'support', 'of', 'the', 'war', 'of', 'genocide', 'against', 'the', 'Sunnis', '.', 'Fadil', '\"', 'a', 'commander', 'in', 'the', 'Mahdi', 'Army', 'tells', 'how', 'he', 'had', 'followed', 'three', 'Arab', 'Sunni', 'men', 'for', 'a', 'period', 'of', 'some', 'weeks', 'and', 'detained', 'them', 'when', 'they', 'were', 'crossing', 'the', 'Karada', 'bridge', ',', 'after', 'having', 'informed', 'an', 'Iraqi', 'army', 'road', 'block', 'close', 'to', 'the', 'area', 'that', 'he', 'was', 'pursuing', '\"', 'terrorists', '\"', 'then', 'attacked', 'the', 'car', 'of', 'the', 'group', 'in', 'question', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'B-CARDINAL', 'B-NORP', 'B-NORP', 'O', 'O', 'O', 'O', 'O', 'B-DATE', 'I-DATE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FAC', 'I-FAC', 'I-FAC', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['Speaking', 'at', 'the', 'same', 'time', 'about', 'an', 'Iranian', 'role', 'in', 'the', 'financing', 'and', 'support', 'of', 'the', 'war', 'of', 'genocide', 'against', 'the', 'Sunnis.', 'Fadil', '\"', 'a', 'commander', 'in', 'the', 'Mahdi', 'Army', 'tells', 'how', 'he', 'had', 'followed', 'three', 'Arab', 'Sunni', 'men', 'for', 'a', 'period', 'of', 'some', 'weeks', 'and', 'detained', 'them', 'when', 'they', 'were', 'crossing', 'the', 'Karada', 'bridge', ',', 'after', 'having', 'informed', 'an', 'Iraqi', 'army', 'road', 'block', 'close', 'to', 'the', 'area', 'that', 'he', 'was', 'pursuing', '\"', 'terrorists', '\"', 'then', 'attacked', 'the', 'car', 'of', 'the', 'group', 'in', 'question', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'B-PERSON', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'B-CARDINAL', 'B-NORP', 'I-NORP', 'O', 'O', 'O', 'O', 'O', 'B-DATE', 'I-DATE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['The', 'newspaper', 'quoted', 'another', 'commander', 'in', 'the', 'Mahdi', 'Army', 'as', 'saying', ';', 'We', 'have', 'taken', '10', 'Sunnis', 'hostages', ',', 'we', 'will', 'get', 'a', 'ransom', 'for', 'five', 'of', 'them', ',', 'then', 'we', 'will', 'kill', 'them', 'all', '.', 'In', 'every', 'major', 'hostage', '-', 'taking', 'operation', 'we', 'get', '50', 'thousand', 'dollars', ',', 'and', 'he', 'considered', 'it', 'to', 'be', 'the', 'best', 'business', 'a', 'person', 'could', 'be', 'running', 'in', 'Baghdad', 'now', '!']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'B-CARDINAL', 'B-NORP', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-CARDINAL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MONEY', 'I-MONEY', 'I-MONEY', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'O', 'O']\n",
      "detected\n",
      "['The', 'newspaper', 'quoted', 'another', 'commander', 'in', 'the', 'Mahdi', 'Army', 'as', 'saying', ';', 'We', 'have', 'taken', '10', 'Sunnis', 'hostages', ',', 'we', 'will', 'get', 'a', 'ransom', 'for', 'five', 'of', 'them', ',', 'then', 'we', 'will', 'kill', 'them', 'all.', 'In', 'every', 'major', 'hostage', '-', 'taking', 'operation', 'we', 'get', '50', 'thousand', 'dollars', ',', 'and', 'he', 'considered', 'it', 'to', 'be', 'the', 'best', 'business', 'a', 'person', 'could', 'be', 'running', 'in', 'Baghdad', 'now', '!']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'B-CARDINAL', 'B-NORP', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-CARDINAL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MONEY', 'I-MONEY', 'I-MONEY', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['As', 'we', 'have', 'said', 'this', 'is', 'a', 'unique', 'precedent', 'for', 'it', '...']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['As', 'we', 'have', 'said', 'this', 'is', 'a', 'unique', 'precedent', 'for', 'it.', '..', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['The', 'last', 'of', 'these', 'tapes', 'or', 'news', 'is', 'Peres', \"'\", 'visit', 'to', 'Doha', 'and', 'the', 'warm', 'reception', 'which', 'he', 'and', 'his', 'delegation', 'enjoyed', '.']\n",
      "['O', 'B-ORDINAL', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'O', 'O', 'B-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['The', 'last', 'of', 'these', 'tapes', 'or', 'news', 'is', 'Peres', \"'visit\", 'to', 'Doha', 'and', 'the', 'warm', 'reception', 'which', 'he', 'and', 'his', 'delegation', 'enjoyed', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'O', 'B-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Try', 'again', 'perhaps', 'we', 'can', 'understand', 'what', 'you', 'wrote', '...']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['Try', 'again', 'perhaps', 'we', 'can', 'understand', 'what', 'you', 'wrote.', '..', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['The', 'Al', '-', 'Arabiya', 'started', 'as', 'a', 'rival', 'to', 'Al', '-', 'Jazeera', 'but', 'it', 'failed', 'and', 'the', 'reason', 'is', 'famously', 'unknown', '...', 'you', 'find', 'it', 'in', 'the', 'word', 'Hebrew']\n",
      "['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LANGUAGE']\n",
      "detected\n",
      "['The', 'Al', '-', 'Arabiya', 'started', 'as', 'a', 'rival', 'to', 'Al', '-', 'Jazeera', 'but', 'it', 'failed', 'and', 'the', 'reason', 'is', 'famously', 'unknown.', '..', '..', 'you', 'find', 'it', 'in', 'the', 'word', 'Hebrew']\n",
      "['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['The', 'hot', 'dialogue', '...', 'that', 'went', 'on', 'between', '-LSB-', 'Saddam', 'Hussein', 'and', 'Rumsfeld', '-RSB-', 'at', 'the', 'airport', 'prison', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['The', 'hot', 'dialogue.', '..', '..', 'that', 'went', 'on', 'between', '-LSB-', 'Saddam', 'Hussein', 'and', 'Rumsfeld', '-RSB-', 'at', 'the', 'airport', 'prison', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Details', 'of', 'the', 'minutes', 'of', 'the', 'meeting', 'between', 'Rumsfeld', 'and', 'Saddam', 'Hussein', 'at', 'the', 'Airport', 'Prison', '...']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'B-PERSON', 'I-PERSON', 'O', 'B-FAC', 'I-FAC', 'I-FAC', 'O']\n",
      "detected\n",
      "['Details', 'of', 'the', 'minutes', 'of', 'the', 'meeting', 'between', 'Rumsfeld', 'and', 'Saddam', 'Hussein', 'at', 'the', 'Airport', 'Prison.', '..', '.']\n",
      "['O', 'O', 'B-TIME', 'I-TIME', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'B-PERSON', 'I-PERSON', 'O', 'B-FAC', 'I-FAC', 'I-FAC', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Besides', ',', 'there', 'are', 'security', 'agreements', 'between', 'us', 'and', 'Kuwait', 'and', 'the', 'other', 'Gulf', 'states', '...', 'we', 'came', 'at', 'their', 'request', 'to', 'protect', 'them', 'from', 'your', 'threats', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['Besides', ',', 'there', 'are', 'security', 'agreements', 'between', 'us', 'and', 'Kuwait', 'and', 'the', 'other', 'Gulf', 'states.', '..', '..', 'we', 'came', 'at', 'their', 'request', 'to', 'protect', 'them', 'from', 'your', 'threats', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Rumsfeld', ':', 'Stop', 'from', 'this', 'drivel', ',', 'I', 'am', 'offering', 'you', '...']\n",
      "['B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['Rumsfeld', ':', 'Stop', 'from', 'this', 'drivel', ',', 'I', 'am', 'offering', 'you.', '..', '.']\n",
      "['B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['The', 'Iraqi', 'people', 'are', 'an', 'obstinate', 'people', 'and', 'do', 'not', 'fear', 'death', '...', 'the', 'Resistance', 'is', 'stronger', 'than', 'you', 'imagine', 'and', 'therefore', 'I', 'predict', 'there', \"'ll\", 'be', 'more', '.']\n",
      "['O', 'B-NORP', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['The', 'Iraqi', 'people', 'are', 'an', 'obstinate', 'people', 'and', 'do', 'not', 'fear', 'death.', '..', '..', 'the', 'Resistance', 'is', 'stronger', 'than', 'you', 'imagine', 'and', 'therefore', 'I', 'predict', 'there', \"'ll\", 'be', 'more', '.']\n",
      "['O', 'B-NORP', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['End', 'of', 'the', 'text', 'of', 'the', 'meeting', 'minutes', '...', 'the', 'source']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['End', 'of', 'the', 'text', 'of', 'the', 'meeting', 'minutes.', '..', '..', 'the', 'source']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['May', 'your', 'steps', 'in', 'doing', 'good', 'be', 'like', 'someone', 'walking', 'on', 'sand', '...', 'he', 'makes', 'no', 'sound', 'but', 'his', 'tracks', 'are', 'obvious', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['May', 'your', 'steps', 'in', 'doing', 'good', 'be', 'like', 'someone', 'walking', 'on', 'sand.', '..', '..', 'he', 'makes', 'no', 'sound', 'but', 'his', 'tracks', 'are', 'obvious', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['He', 'is', 'really', 'delusional', '...']\n",
      "['O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['He', 'is', 'really', 'delusional.', '..', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['I', 'have', 'reservations', 'about', 'what', 'appeared', 'in', 'these', 'minutes', '...', 'because', 'I', 'think', 'it', 'unlikely', 'that', 'what', 'happened', 'at', 'that', 'meeting', 'would', 'leak', 'out', 'this', 'easily', '...']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['I', 'have', 'reservations', 'about', 'what', 'appeared', 'in', 'these', 'minutes.', '..', '..', 'because', 'I', 'think', 'it', 'unlikely', 'that', 'what', 'happened', 'at', 'that', 'meeting', 'would', 'leak', 'out', 'this', 'easily.', '..', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-TIME', 'I-TIME', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['And', 'I', 'do', 'not', 'believe', 'that', 'Rumsfeld', 'would', 'meet', 'Saddam', 'unless', 'Saddam', 'himself', 'made', 'signs', '...', 'the', 'important', 'thing', 'is', 'that', 'the', 'expression', 'quoted', 'above', 'tells', 'of', 'a', 'reality', 'that', 'can', 'not', 'be', 'but', 'accepted', '...']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'O', 'B-PERSON', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['And', 'I', 'do', 'not', 'believe', 'that', 'Rumsfeld', 'would', 'meet', 'Saddam', 'unless', 'Saddam', 'himself', 'made', 'signs.', '..', '..', 'the', 'important', 'thing', 'is', 'that', 'the', 'expression', 'quoted', 'above', 'tells', 'of', 'a', 'reality', 'that', 'can', 'not', 'be', 'but', 'accepted.', '..', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'O', 'B-PERSON', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['My', 'brother', ',', 'Over', 'the', 'Sun', '.', 'I', 'apologize', 'for', 'repeating', 'the', 'article', ',', 'and', 'thank', 'you', 'for', 'participating', '.']\n",
      "['O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['My', 'brother', ',', 'Over', 'the', 'Sun.', 'I', 'apologize', 'for', 'repeating', 'the', 'article', ',', 'and', 'thank', 'you', 'for', 'participating', '.']\n",
      "['O', 'O', 'O', 'B-WORK_OF_ART', 'I-WORK_OF_ART', 'I-WORK_OF_ART', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in unequal[:20]:\n",
    "    print(\"actual\")\n",
    "    print(df.iloc[i,:].Actual_ners)\n",
    "    print(df.iloc[i,:].Actual_ner_types)\n",
    "    print(\"detected\")\n",
    "    print(df.iloc[i,:].Detected_ners)\n",
    "    print(df.iloc[i,:].Detected_ner_types)\n",
    "    print(\"-----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "southern-garden",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_ner = []\n",
    "actual_type = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    actual_ner_temp = []\n",
    "    actual_type_temp = []\n",
    "    flag = 0\n",
    "    for j,d in enumerate(df.iloc[i,:].Actual_ners):\n",
    "        if (j < (len(df.iloc[i,:].Actual_ners) - 2)) and df.iloc[i,:].Actual_ners[j+1] == \".\":\n",
    "            actual_ner_temp.append(d + \".\")\n",
    "            actual_type_temp.append(df.iloc[i,:].Actual_ner_types[j])\n",
    "            flag = 1\n",
    "        elif d == \".\" and flag == 1:\n",
    "            flag = 0\n",
    "            continue\n",
    "        else:\n",
    "            actual_ner_temp.append(d)\n",
    "            actual_type_temp.append(df.iloc[i,:].Actual_ner_types[j])\n",
    "    actual_ner.append(actual_ner_temp)\n",
    "    actual_type.append(actual_type_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "seasonal-attachment",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Actual_ners = actual_ner\n",
    "df.Actual_ner_types = actual_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "clear-hammer",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "pretty-killer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "lonely-paraguay",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual\n",
      "['There', 'are', 'many', 'questions', ',', 'amongst', 'them', 'the', 'timing', 'of', 'its', 'being', 'shown', 'at', 'this', 'very', 'time', ',', 'following', 'the', 'conflict', 'in', 'interests', 'between', 'the', 'Sons', 'of', 'Monkeys', 'and', 'Pigs', 'and', 'the', 'Sons', 'of', 'Temporary', 'Marriages', '...']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['There', 'are', 'many', 'questions', ',', 'amongst', 'them', 'the', 'timing', 'of', 'its', 'being', 'shown', 'at', 'this', 'very', 'time', ',', 'following', 'the', 'conflict', 'in', 'interests', 'between', 'the', 'Sons', 'of', 'Monkeys', 'and', 'Pigs', 'and', 'the', 'Sons', 'of', 'Temporary', 'Marriages.', '..', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['I', 'leave', 'you', 'with', 'the', 'film', 'which', 'saddens', 'the', 'heart', 'and', 'makes', 'it', 'bleed', '....']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['I', 'leave', 'you', 'with', 'the', 'film', 'which', 'saddens', 'the', 'heart', 'and', 'makes', 'it', 'bleed.', '..', '..', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['http://z08.zupload.com/download.php?...filepath=48993']\n",
      "['O']\n",
      "detected\n",
      "['http://z08.zupload.com/download.php', '?..', '..', 'filepath=48993']\n",
      "['O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['As', 'we', 'have', 'said', 'this', 'is', 'a', 'unique', 'precedent', 'for', 'it', '...']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['As', 'we', 'have', 'said', 'this', 'is', 'a', 'unique', 'precedent', 'for', 'it.', '..', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['My', 'brother', 'Source', 'of', 'the', 'Word.', 'The', 'truth', 'is', 'that', 'I', 'saw', 'the', 'film', 'and', 'it', 'was', 'really', 'terrifying', 'to', 'the', 'extent', 'that', 'I', 'thought', 'I', 'was', 'watching', 'a', 'fictional', 'film', '...', 'because', 'I', 'could', 'not', 'imagine', 'the', 'extent', 'of', 'the', 'Safavid', 'hatred', 'and', 'criminality', '.']\n",
      "['O', 'O', 'B-PERSON', 'I-PERSON', 'I-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['My', 'brother', 'Source', 'of', 'the', 'Word.', 'The', 'truth', 'is', 'that', 'I', 'saw', 'the', 'film', 'and', 'it', 'was', 'really', 'terrifying', 'to', 'the', 'extent', 'that', 'I', 'thought', 'I', 'was', 'watching', 'a', 'fictional', 'film.', '..', '..', 'because', 'I', 'could', 'not', 'imagine', 'the', 'extent', 'of', 'the', 'Safavid', 'hatred', 'and', 'criminality', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['The', 'last', 'of', 'these', 'tapes', 'or', 'news', 'is', 'Peres', \"'\", 'visit', 'to', 'Doha', 'and', 'the', 'warm', 'reception', 'which', 'he', 'and', 'his', 'delegation', 'enjoyed', '.']\n",
      "['O', 'B-ORDINAL', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'O', 'O', 'B-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['The', 'last', 'of', 'these', 'tapes', 'or', 'news', 'is', 'Peres', \"'visit\", 'to', 'Doha', 'and', 'the', 'warm', 'reception', 'which', 'he', 'and', 'his', 'delegation', 'enjoyed', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'O', 'B-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Try', 'again', 'perhaps', 'we', 'can', 'understand', 'what', 'you', 'wrote', '...']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['Try', 'again', 'perhaps', 'we', 'can', 'understand', 'what', 'you', 'wrote.', '..', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['The', 'Al', '-', 'Arabiya', 'started', 'as', 'a', 'rival', 'to', 'Al', '-', 'Jazeera', 'but', 'it', 'failed', 'and', 'the', 'reason', 'is', 'famously', 'unknown', '...', 'you', 'find', 'it', 'in', 'the', 'word', 'Hebrew']\n",
      "['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LANGUAGE']\n",
      "detected\n",
      "['The', 'Al', '-', 'Arabiya', 'started', 'as', 'a', 'rival', 'to', 'Al', '-', 'Jazeera', 'but', 'it', 'failed', 'and', 'the', 'reason', 'is', 'famously', 'unknown.', '..', '..', 'you', 'find', 'it', 'in', 'the', 'word', 'Hebrew']\n",
      "['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['The', 'hot', 'dialogue', '...', 'that', 'went', 'on', 'between', '-LSB-', 'Saddam', 'Hussein', 'and', 'Rumsfeld', '-RSB-', 'at', 'the', 'airport', 'prison', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['The', 'hot', 'dialogue.', '..', '..', 'that', 'went', 'on', 'between', '-LSB-', 'Saddam', 'Hussein', 'and', 'Rumsfeld', '-RSB-', 'at', 'the', 'airport', 'prison', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Details', 'of', 'the', 'minutes', 'of', 'the', 'meeting', 'between', 'Rumsfeld', 'and', 'Saddam', 'Hussein', 'at', 'the', 'Airport', 'Prison', '...']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'B-PERSON', 'I-PERSON', 'O', 'B-FAC', 'I-FAC', 'I-FAC', 'O']\n",
      "detected\n",
      "['Details', 'of', 'the', 'minutes', 'of', 'the', 'meeting', 'between', 'Rumsfeld', 'and', 'Saddam', 'Hussein', 'at', 'the', 'Airport', 'Prison.', '..', '.']\n",
      "['O', 'O', 'B-TIME', 'I-TIME', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'B-PERSON', 'I-PERSON', 'O', 'B-FAC', 'I-FAC', 'I-FAC', 'O', 'O']\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in unequal[:10]:\n",
    "    print(\"actual\")\n",
    "    print(df.iloc[i,:].Actual_ners)\n",
    "    print(df.iloc[i,:].Actual_ner_types)\n",
    "    print(\"detected\")\n",
    "    print(df.iloc[i,:].Detected_ners)\n",
    "    print(df.iloc[i,:].Detected_ner_types)\n",
    "    print(\"-----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "suburban-ownership",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_ner = []\n",
    "actual_type = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    actual_ner_temp = []\n",
    "    actual_type_temp = []\n",
    "    flag = 0\n",
    "    for j,d in enumerate(df.iloc[i,:].Actual_ners):\n",
    "        if (j < (len(df.iloc[i,:].Actual_ners) - 1) and d == \"'\"):\n",
    "            actual_ner_temp.append(\"'\" + df.iloc[i,:].Actual_ners[j+1])\n",
    "            actual_type_temp.append(df.iloc[i,:].Actual_ner_types[j+1])\n",
    "            flag = 1\n",
    "        elif flag == 1:\n",
    "            flag = 0\n",
    "            continue\n",
    "        else:\n",
    "            actual_ner_temp.append(d)\n",
    "            actual_type_temp.append(df.iloc[i,:].Actual_ner_types[j])\n",
    "    actual_ner.append(actual_ner_temp)\n",
    "    actual_type.append(actual_type_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "northern-aquarium",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Actual_ners = actual_ner\n",
    "df.Actual_ner_types = actual_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "lucky-trainer",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "moral-pharmacy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "fiscal-fleet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "re.findall(r'^[.][.]+',\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "cosmetic-fantasy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multicount_re(searchlist):\n",
    "    temp = []\n",
    "    for i,s in enumerate(searchlist):\n",
    "        if len(re.findall(r'^[.][.]+',s)):\n",
    "            temp.append(i)\n",
    "    return temp\n",
    "\n",
    "detect_ner = []\n",
    "detect_type = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    ref_list = multicount_re(df.iloc[i,:].Detected_ners)\n",
    "    detect_ner_temp = []\n",
    "    detect_type_temp = []\n",
    "    if len(ref_list) > 1:\n",
    "        counter = 0\n",
    "        while (counter<len(df.iloc[i,:].Detected_ners)):\n",
    "            flag = 0\n",
    "            while((counter<len(df.iloc[i,:].Detected_ners) - 1) and counter in ref_list):            \n",
    "                counter += 1\n",
    "                flag += 1\n",
    "            if flag > 0:\n",
    "                detect_ner_temp.append(\"...\")\n",
    "                detect_type_temp.append(\"O\")\n",
    "            while((counter<len(df.iloc[i,:].Detected_ners) - 1) and counter not in ref_list):\n",
    "                detect_ner_temp.append(df.iloc[i,:].Detected_ners[counter])\n",
    "                detect_type_temp.append(df.iloc[i,:].Detected_ner_types[counter])\n",
    "                if (counter<len(df.iloc[i,:].Detected_ners) - 1):\n",
    "                    counter += 1\n",
    "            if counter == (len(df.iloc[i,:].Detected_ners) - 1):\n",
    "                detect_ner_temp.append(df.iloc[i,:].Detected_ners[counter])\n",
    "                detect_type_temp.append(df.iloc[i,:].Detected_ner_types[counter])\n",
    "                detect_ner.append(detect_ner_temp)\n",
    "                detect_type.append(detect_type_temp)\n",
    "                break\n",
    "    else:\n",
    "        detect_ner.append(df.iloc[i,:].Detected_ners)\n",
    "        detect_type.append(df.iloc[i,:].Detected_ner_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "paperback-venue",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "923"
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(detect_ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "cosmetic-graduation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Detected_ners = detect_ner\n",
    "df.Detected_ner_types = detect_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "minus-devon",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "radical-reggae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "better-celebration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual\n",
      "['There', 'are', 'many', 'questions', ',', 'amongst', 'them', 'the', 'timing', 'of', 'its', 'being', 'shown', 'at', 'this', 'very', 'time', ',', 'following', 'the', 'conflict', 'in', 'interests', 'between', 'the', 'Sons', 'of', 'Monkeys', 'and', 'Pigs', 'and', 'the', 'Sons', 'of', 'Temporary', 'Marriages', '...']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['There', 'are', 'many', 'questions', ',', 'amongst', 'them', 'the', 'timing', 'of', 'its', 'being', 'shown', 'at', 'this', 'very', 'time', ',', 'following', 'the', 'conflict', 'in', 'interests', 'between', 'the', 'Sons', 'of', 'Monkeys', 'and', 'Pigs', 'and', 'the', 'Sons', 'of', 'Temporary', 'Marriages.', '..', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['I', 'leave', 'you', 'with', 'the', 'film', 'which', 'saddens', 'the', 'heart', 'and', 'makes', 'it', 'bleed', '....']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['I', 'leave', 'you', 'with', 'the', 'film', 'which', 'saddens', 'the', 'heart', 'and', 'makes', 'it', 'bleed.', '...', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['http://z08.zupload.com/download.php?...filepath=48993']\n",
      "['O']\n",
      "detected\n",
      "['http://z08.zupload.com/download.php', '?..', '..', 'filepath=48993']\n",
      "['O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['As', 'we', 'have', 'said', 'this', 'is', 'a', 'unique', 'precedent', 'for', 'it', '...']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['As', 'we', 'have', 'said', 'this', 'is', 'a', 'unique', 'precedent', 'for', 'it.', '..', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Try', 'again', 'perhaps', 'we', 'can', 'understand', 'what', 'you', 'wrote', '...']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['Try', 'again', 'perhaps', 'we', 'can', 'understand', 'what', 'you', 'wrote.', '..', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Details', 'of', 'the', 'minutes', 'of', 'the', 'meeting', 'between', 'Rumsfeld', 'and', 'Saddam', 'Hussein', 'at', 'the', 'Airport', 'Prison', '...']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'B-PERSON', 'I-PERSON', 'O', 'B-FAC', 'I-FAC', 'I-FAC', 'O']\n",
      "detected\n",
      "['Details', 'of', 'the', 'minutes', 'of', 'the', 'meeting', 'between', 'Rumsfeld', 'and', 'Saddam', 'Hussein', 'at', 'the', 'Airport', 'Prison.', '..', '.']\n",
      "['O', 'O', 'B-TIME', 'I-TIME', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'B-PERSON', 'I-PERSON', 'O', 'B-FAC', 'I-FAC', 'I-FAC', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Rumsfeld', ':', 'Stop', 'from', 'this', 'drivel', ',', 'I', 'am', 'offering', 'you', '...']\n",
      "['B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['Rumsfeld', ':', 'Stop', 'from', 'this', 'drivel', ',', 'I', 'am', 'offering', 'you.', '..', '.']\n",
      "['B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['He', 'is', 'really', 'delusional', '...']\n",
      "['O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['He', 'is', 'really', 'delusional.', '..', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['I', 'have', 'reservations', 'about', 'what', 'appeared', 'in', 'these', 'minutes', '...', 'because', 'I', 'think', 'it', 'unlikely', 'that', 'what', 'happened', 'at', 'that', 'meeting', 'would', 'leak', 'out', 'this', 'easily', '...']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['I', 'have', 'reservations', 'about', 'what', 'appeared', 'in', 'these', 'minutes.', '...', 'because', 'I', 'think', 'it', 'unlikely', 'that', 'what', 'happened', 'at', 'that', 'meeting', 'would', 'leak', 'out', 'this', 'easily.', '...', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-TIME', 'I-TIME', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['And', 'I', 'do', 'not', 'believe', 'that', 'Rumsfeld', 'would', 'meet', 'Saddam', 'unless', 'Saddam', 'himself', 'made', 'signs', '...', 'the', 'important', 'thing', 'is', 'that', 'the', 'expression', 'quoted', 'above', 'tells', 'of', 'a', 'reality', 'that', 'can', 'not', 'be', 'but', 'accepted', '...']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'O', 'B-PERSON', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['And', 'I', 'do', 'not', 'believe', 'that', 'Rumsfeld', 'would', 'meet', 'Saddam', 'unless', 'Saddam', 'himself', 'made', 'signs.', '...', 'the', 'important', 'thing', 'is', 'that', 'the', 'expression', 'quoted', 'above', 'tells', 'of', 'a', 'reality', 'that', 'can', 'not', 'be', 'but', 'accepted.', '...', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'O', 'B-PERSON', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in unequal[:10]:\n",
    "    print(\"actual\")\n",
    "    print(df.iloc[i,:].Actual_ners)\n",
    "    print(df.iloc[i,:].Actual_ner_types)\n",
    "    print(\"detected\")\n",
    "    print(df.iloc[i,:].Detected_ners)\n",
    "    print(df.iloc[i,:].Detected_ner_types)\n",
    "    print(\"-----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "restricted-metropolitan",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in unequal[:10]:\n",
    "    if i == unequal[2]:\n",
    "        df.iloc[i,:].Detected_ners = df.iloc[i,:].Actual_ners\n",
    "        df.iloc[i,:].Detected_ner_types = df.iloc[i,:].Actual_ner_types\n",
    "    else:\n",
    "        df.iloc[i,:].Detected_ners = df.iloc[i,:].Detected_ners[:-1]\n",
    "        df.iloc[i,:].Detected_ner_types = df.iloc[i,:].Detected_ner_types[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "expressed-insertion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual\n",
      "['For', 'the', 'people', 'working', 'at', 'Bahrain', \"'s\", 'malls', ',', 'the', 'person', 'covered', 'head', 'to', 'toe', 'in', 'a', 'black', 'veil', ',', 'gloves', 'and', 'glasses', 'appeared', 'to', 'be', 'a', 'rich', ',', 'doting', 'Saudi', 'mother', '....']\n",
      "['O', 'O', 'O', 'O', 'O', 'B-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'O', 'O']\n",
      "detected\n",
      "['For', 'the', 'people', 'working', 'at', 'Bahrain', \"'s\", 'malls', ',', 'the', 'person', 'covered', 'head', 'to', 'toe', 'in', 'a', 'black', 'veil', ',', 'gloves', 'and', 'glasses', 'appeared', 'to', 'be', 'a', 'rich', ',', 'doting', 'Saudi', 'mother.', '...', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'B-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['This', 'day', 'is', 'named', 'for', 'Saturn', '...']\n",
      "['O', 'O', 'O', 'O', 'O', 'B-PERSON', 'O']\n",
      "detected\n",
      "['This', 'day', 'is', 'named', 'for', 'Saturn.', '..', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['and', 'Saturn', 'devoured', 'all', 'of', 'his', 'children', 'when', 'they', 'were', 'born', 'to', 'prevent', 'this', '...']\n",
      "['O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['and', 'Saturn', 'devoured', 'all', 'of', 'his', 'children', 'when', 'they', 'were', 'born', 'to', 'prevent', 'this.', '..', '.']\n",
      "['O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['I', 'need', 'a', 'cup', 'of', 'coffee', '...']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['I', 'need', 'a', 'cup', 'of', 'coffee.', '..', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['I', 'looked', 'in', 'vain', 'for', 'the', 'Cheney', '``', 'A', 'hunting', 'we', 'will', 'go', \"''\", 'to', 'post', 'this', 'out', 'and', 'paste', 'but', '...']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['I', 'looked', 'in', 'vain', 'for', 'the', 'Cheney', '``', 'A', 'hunting', 'we', 'will', 'go', \"''\", 'to', 'post', 'this', 'out', 'and', 'paste', 'but.', '..', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Kuo', ',', 'a', 'former', 'CIA', 'employee', '...', 'had', 'been', 'Executive', 'Director', 'of', 'the', 'Center', 'for', 'Effective', 'Compassion', ',', 'founded', 'in', '1995', 'by', 'Arianna', 'Huffington', '...']\n",
      "['B-PERSON', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'B-DATE', 'O', 'B-PERSON', 'I-PERSON', 'O']\n",
      "detected\n",
      "['Kuo', ',', 'a', 'former', 'CIA', 'employee.', '...', 'had', 'been', 'Executive', 'Director', 'of', 'the', 'Center', 'for', 'Effective', 'Compassion', ',', 'founded', 'in', '1995', 'by', 'Arianna', 'Huffington.', '...', '.']\n",
      "['B-PERSON', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'B-DATE', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['There', \"'s\", 'also', 'some', 'curious', 'Neverland', '/', 'Disneyland', 'connections', 'to', 'the', '``', 'Mickey', 'Mouse', 'Club', \"''\", 'children', 'who', 'are', 'now', 'stars', ',', 'including', 'Justin', 'Timberlake', '-LRB-', 'remember', 'the', 'star', 'on', 'Janet', 'Jackson', \"'s\", 'breast', '?', 'and', 'Brittany', 'Spears', ',', 'Christina', 'Aguilera', '...']\n",
      "['O', 'O', 'O', 'O', 'O', 'B-FAC', 'O', 'B-FAC', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'I-PERSON', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'B-PERSON', 'I-PERSON', 'O']\n",
      "detected\n",
      "['There', \"'s\", 'also', 'some', 'curious', 'Neverland', '/', 'Disneyland', 'connections', 'to', 'the', '``', 'Mickey', 'Mouse', 'Club', \"''\", 'children', 'who', 'are', 'now', 'stars', ',', 'including', 'Justin', 'Timberlake', '-LRB-', 'remember', 'the', 'star', 'on', 'Janet', 'Jackson', \"'s\", 'breast', '?', 'and', 'Brittany', 'Spears', ',', 'Christina', 'Aguilera.', '..', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'I-PERSON', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['The', 'piper', 'walks', 'into', 'the', 'mountain', ',', 'still', 'followed', 'by', 'the', 'children', ',', 'and', 'the', 'cave', 'closes', 'again', '...']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['The', 'piper', 'walks', 'into', 'the', 'mountain', ',', 'still', 'followed', 'by', 'the', 'children', ',', 'and', 'the', 'cave', 'closes', 'again.', '..', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['but', 'i', 'thought', 'you', 'might', 'cover', 'chile', \"'s\", 'inauguration', 'of', 'its', 'first', 'woman', 'president', 'today', 'instead', '...']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['but', 'i', 'thought', 'you', 'might', 'cover', 'chile', \"'s\", 'inauguration', 'of', 'its', 'first', 'woman', 'president', 'today', 'instead.', '..', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORDINAL', 'O', 'O', 'B-DATE', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Jackson', 'had', 'already', 'undergone', 'a', 'blood', 'bath', '...']\n",
      "['B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['Jackson', 'had', 'already', 'undergone', 'a', 'blood', 'bath.', '..', '.']\n",
      "['B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in unequal[10:20]:\n",
    "    print(\"actual\")\n",
    "    print(df.iloc[i,:].Actual_ners)\n",
    "    print(df.iloc[i,:].Actual_ner_types)\n",
    "    print(\"detected\")\n",
    "    print(df.iloc[i,:].Detected_ners)\n",
    "    print(df.iloc[i,:].Detected_ner_types)\n",
    "    print(\"-----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "iraqi-committee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in unequal[10:20]:   \n",
    "    df.iloc[i,:].Detected_ners = df.iloc[i,:].Detected_ners[:-1]\n",
    "    df.iloc[i,:].Detected_ner_types = df.iloc[i,:].Detected_ner_types[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "healthy-tablet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual\n",
      "['The', 'pop', 'star', ',', 'who', 'is', 'said', 'to', 'be', '$', '240', 'million', 'in', 'debt', ',', 'had', 'paid', 'six', 'figures', 'for', 'a', 'ritual', 'cleansing', 'using', 'sheep', 'blood', 'to', 'another', 'voodoo', 'doctor', 'and', 'a', 'mysterious', 'Egyptian', 'woman', 'named', 'Samia', ',', 'who', 'came', 'to', 'him', 'with', 'a', 'letter', 'of', 'greeting', 'from', 'a', 'high', '-', 'ranking', 'Saudi', 'prince', ',', 'purportedly', 'Nawaf', 'Bin', 'Abdulaziz', 'Al', '-', 'Saud', ',', 'now', 'the', 'chief', 'of', 'intelligence', 'of', 'Saudi', 'Arabia', '...']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MONEY', 'I-MONEY', 'I-MONEY', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'I-PERSON', 'I-PERSON', 'I-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'I-GPE', 'O']\n",
      "detected\n",
      "['The', 'pop', 'star', ',', 'who', 'is', 'said', 'to', 'be', '$', '240', 'million', 'in', 'debt', ',', 'had', 'paid', 'six', 'figures', 'for', 'a', 'ritual', 'cleansing', 'using', 'sheep', 'blood', 'to', 'another', 'voodoo', 'doctor', 'and', 'a', 'mysterious', 'Egyptian', 'woman', 'named', 'Samia', ',', 'who', 'came', 'to', 'him', 'with', 'a', 'letter', 'of', 'greeting', 'from', 'a', 'high', '-', 'ranking', 'Saudi', 'prince', ',', 'purportedly', 'Nawaf', 'Bin', 'Abdulaziz', 'Al', '-', 'Saud', ',', 'now', 'the', 'chief', 'of', 'intelligence', 'of', 'Saudi', 'Arabia.', '..', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MONEY', 'I-MONEY', 'I-MONEY', 'O', 'O', 'O', 'O', 'O', 'B-CARDINAL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'I-PERSON', 'I-PERSON', 'I-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'I-GPE', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Anonymous', 'quoted', ',', 'Jackson', \"'s\", 'stay', 'at', 'the', 'Cedars', 'was', 'arranged', 'through', 'David', 'Kuo', '...']\n",
      "['O', 'O', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'B-FAC', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O']\n",
      "detected\n",
      "['Anonymous', 'quoted', ',', 'Jackson', \"'s\", 'stay', 'at', 'the', 'Cedars', 'was', 'arranged', 'through', 'David', 'Kuo.', '..', '.']\n",
      "['B-ORG', 'O', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'B-FAC', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['then', 'he', 'shoves', 'his', 'hand', 'hard', 'into', 'my', 'groin', '.....']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['then', 'he', 'shoves', 'his', 'hand', 'hard', 'into', 'my', 'groin.', '...', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['I', 'apologize', 'for', 'continuing', 'my', 'ramble', 'but', '...']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['I', 'apologize', 'for', 'continuing', 'my', 'ramble', 'but.', '..', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Bout', 'was', 'Liberian', 'dictator', 'Charles', 'Taylor', \"'s\", 'primary', 'arms', 'and', 'diamond', 'smuggler', '...']\n",
      "['O', 'O', 'B-NORP', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['Bout', 'was', 'Liberian', 'dictator', 'Charles', 'Taylor', \"'s\", 'primary', 'arms', 'and', 'diamond', 'smuggler.', '..', '.']\n",
      "['B-PERSON', 'O', 'B-NORP', 'O', 'B-PERSON', 'I-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['What', 'the', '...']\n",
      "['O', 'O', 'O']\n",
      "detected\n",
      "['What', 'the.', '..', '.']\n",
      "['O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['It', \"'s\", 'the', 'most', 'disappointingly', '*cheesy*', '1960s', 'sci', '-', 'fi', 'kind', 'of', 'name', 'for', 'an', 'astral', 'entity', 'to', 'use', ',', 'that', \"'s\", 'for', 'sure', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-DATE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['It', \"'s\", 'the', 'most', 'disappointingly', '*', 'cheesy', '*', '1960s', 'sci', '-', 'fi', 'kind', 'of', 'name', 'for', 'an', 'astral', 'entity', 'to', 'use', ',', 'that', \"'s\", 'for', 'sure', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['There', 'was', 'no', 'mention', 'made', 'of', 'this', 'in', 'either', 'the', 'main', 'post', 'or', 'comments', '....']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['There', 'was', 'no', 'mention', 'made', 'of', 'this', 'in', 'either', 'the', 'main', 'post', 'or', 'comments.', '...', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['It', 'would', 'seem', 'to', 'me', 'that', 'their', 'must', 'be', 'some', 'relationship', 'between', 'that', 'cult', 'organization', 'and', 'all', 'the', '``', 'high', 'weirdness', \"''\", 'going', 'on', '....']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['It', 'would', 'seem', 'to', 'me', 'that', 'their', 'must', 'be', 'some', 'relationship', 'between', 'that', 'cult', 'organization', 'and', 'all', 'the', '``', 'high', 'weirdness', \"''\", 'going', 'on.', '...', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['The', 'way', 'I', 'work', 'it', \"'s\", 'gon', 'na', 'keep', 'you', \"cumin'\"]\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['The', 'way', 'I', 'work', 'it', \"'s\", 'gon', 'na', 'keep', 'you', 'cumin', \"'\"]\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in unequal[20:30]:\n",
    "    print(\"actual\")\n",
    "    print(df.iloc[i,:].Actual_ners)\n",
    "    print(df.iloc[i,:].Actual_ner_types)\n",
    "    print(\"detected\")\n",
    "    print(df.iloc[i,:].Detected_ners)\n",
    "    print(df.iloc[i,:].Detected_ner_types)\n",
    "    print(\"-----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "extensive-evaluation",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in unequal[20:30]:\n",
    "    if i == unequal[26] or i == unequal[29]:\n",
    "        df.iloc[i,:].Detected_ners = df.iloc[i,:].Actual_ners\n",
    "        df.iloc[i,:].Detected_ner_types = df.iloc[i,:].Actual_ner_types\n",
    "    else:\n",
    "        df.iloc[i,:].Detected_ners = df.iloc[i,:].Detected_ners[:-1]\n",
    "        df.iloc[i,:].Detected_ner_types = df.iloc[i,:].Detected_ner_types[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "exotic-appointment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual\n",
      "['The', 'sentence', 'I', 'put', 'in', 'boldface', 'is', '*extremely*', 'interesting', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['The', 'sentence', 'I', 'put', 'in', 'boldface', 'is', '*', 'extremely', '*', 'interesting', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['hmmm', '...']\n",
      "['O', 'O']\n",
      "detected\n",
      "['hmmm.', '..', '.']\n",
      "['O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['in', 'March', '2003', 'Jackson', 'distraction', '-', 'o', '-', 'mania', 'was', 'part', 'of', 'the', 'media', 'smokescreen', 'that', 'led', 'up', 'the', 'Iraq', 'war', '...']\n",
      "['O', 'B-DATE', 'I-DATE', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-EVENT', 'I-EVENT', 'I-EVENT', 'O']\n",
      "detected\n",
      "['in', 'March', '2003', 'Jackson', 'distraction', '-', 'o', '-', 'mania', 'was', 'part', 'of', 'the', 'media', 'smokescreen', 'that', 'led', 'up', 'the', 'Iraq', 'war.', '..', '.']\n",
      "['O', 'B-DATE', 'I-DATE', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-EVENT', 'I-EVENT', 'I-EVENT', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['and', 'now', 'Fox', 'news', 'and', 'other', 'rabid', '-', 'right', 'media', 'outlets', 'have', 'once', 'again', 'taken', 'to', 'whipping', 'on', 'Jackson', '...']\n",
      "['O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'O']\n",
      "detected\n",
      "['and', 'now', 'Fox', 'news', 'and', 'other', 'rabid', '-', 'right', 'media', 'outlets', 'have', 'once', 'again', 'taken', 'to', 'whipping', 'on', 'Jackson.', '..', '.']\n",
      "['O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Which', 'is', 'why', 'I', 'decided', 'to', 'ask', '...']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['Which', 'is', 'why', 'I', 'decided', 'to', 'ask.', '..', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['And', 'then', 'something', 'happened', '...']\n",
      "['O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['And', 'then', 'something', 'happened.', '..', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['However', ',', 'there', 'is', 'more', 'to', 'this', 'matter', ',', 'the', 'whole', 'world', 'has', 'to', 'share', 'the', 'various', 'negative', 'effects', 'caused', 'by', 'the', 'US', 'excessive', 'energy', 'consumption', ':', 'global', 'warming', ',', 'and', 'wars', 'caused', 'by', 'oil', ',', 'etc.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['However', ',', 'there', 'is', 'more', 'to', 'this', 'matter', ',', 'the', 'whole', 'world', 'has', 'to', 'share', 'the', 'various', 'negative', 'effects', 'caused', 'by', 'the', 'US', 'excessive', 'energy', 'consumption', ':', 'global', 'warming', ',', 'and', 'wars', 'caused', 'by', 'oil', ',', 'etc', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['By', 'then', '17', '-', '18', 'hours', 'had', 'passed', 'since', 'I', \"'d\", 'gotten', 'up', 'at', '4:00', 'a.m.']\n",
      "['O', 'O', 'B-TIME', 'I-TIME', 'I-TIME', 'I-TIME', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-TIME', 'I-TIME']\n",
      "detected\n",
      "['By', 'then', '17', '-', '18', 'hours', 'had', 'passed', 'since', 'I', \"'d\", 'gotten', 'up', 'at', '4:00', 'a.m', '.']\n",
      "['O', 'O', 'B-TIME', 'I-TIME', 'I-TIME', 'I-TIME', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-TIME', 'I-TIME', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Then', 'I', 'went', 'straight', 'for', 'the', 'physical', ',', 'and', 'I', 'filled', 'out', 'the', 'application', 'form', ',', 'reference', 'list', ',', 'etc.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['Then', 'I', 'went', 'straight', 'for', 'the', 'physical', ',', 'and', 'I', 'filled', 'out', 'the', 'application', 'form', ',', 'reference', 'list', ',', 'etc', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['MSN', ':', 'p...@hotmail.com']\n",
      "['O', 'O', 'O']\n",
      "detected\n",
      "['MSN', ':', 'p', '...', '@hotmail.com']\n",
      "['B-ORG', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in unequal[30:40]:\n",
    "    print(\"actual\")\n",
    "    print(df.iloc[i,:].Actual_ners)\n",
    "    print(df.iloc[i,:].Actual_ner_types)\n",
    "    print(\"detected\")\n",
    "    print(df.iloc[i,:].Detected_ners)\n",
    "    print(df.iloc[i,:].Detected_ner_types)\n",
    "    print(\"-----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "willing-disposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in unequal[30:40]:\n",
    "    if i == unequal[30]:\n",
    "        df.iloc[i,:].Detected_ners = df.iloc[i,:].Actual_ners\n",
    "        df.iloc[i,:].Detected_ner_types = df.iloc[i,:].Actual_ner_types\n",
    "    elif i == unequal[39]:\n",
    "        df.iloc[i,:].Detected_ners = ['MSN', ':', 'p', '...', '@hotmail.com']\n",
    "        df.iloc[i,:].Detected_ner_types = ['B-ORG', 'O', 'O']\n",
    "    else:\n",
    "        df.iloc[i,:].Detected_ners = df.iloc[i,:].Detected_ners[:-1]\n",
    "        df.iloc[i,:].Detected_ner_types = df.iloc[i,:].Detected_ner_types[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "surgical-yorkshire",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual\n",
      "['email', ':', 'youyutianshi...@sina.com']\n",
      "['O', 'O', 'O']\n",
      "detected\n",
      "['email', ':', 'youyutianshi.', '...', '@sina.com']\n",
      "['O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "i = unequal[40]\n",
    "print(\"actual\")\n",
    "print(df.iloc[i,:].Actual_ners)\n",
    "print(df.iloc[i,:].Actual_ner_types)\n",
    "print(\"detected\")\n",
    "print(df.iloc[i,:].Detected_ners)\n",
    "print(df.iloc[i,:].Detected_ner_types)\n",
    "print(\"-----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "little-pearl",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[i,:].Detected_ners = ['email', ':', 'youyutianshi...@sina.com']\n",
    "df.iloc[i,:].Detected_ner_types = ['O', 'O', 'O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "different-scenario",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "sonic-motel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "utility-involvement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ramybal/Desktop/untitled folder/neuroner/detect_onto_wb_ner.csv\n",
      "accuracy score\n",
      "0.9695007758574563\n"
     ]
    }
   ],
   "source": [
    "print(f)\n",
    "print(\"accuracy score\")\n",
    "print(accuracy_score(df.Actual_ner_types.tolist(),df.Detected_ner_types.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "lesser-attendance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7908410391897842\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(df.Actual_ner_types.tolist(),df.Detected_ner_types.tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optimum-drill",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
