{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "congressional-shannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Spark NLP\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "import sparknlp\n",
    "\n",
    "# Start Spark Session with Spark NLP\n",
    "# start() functions has two parameters: gpu and spark23\n",
    "# sparknlp.start(gpu=True) will start the session with GPU support\n",
    "# sparknlp.start(spark23=True) is when you have Apache Spark 2.3.x installed\n",
    "spark = sparknlp.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "heard-tulsa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP version 2.7.3\n",
      "Apache Spark version: 2.4.4\n"
     ]
    }
   ],
   "source": [
    "print(\"Spark NLP version\", sparknlp.version())\n",
    "print(\"Apache Spark version:\", spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caroline-hampshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text files with the input\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"/Users/ramybal/Downloads/bio/spark/test/onto_bc_ner.txt\",delimiter=\"\\t\", quoting=csv.QUOTE_NONE, encoding='utf-8',header=None,names=[\"Word\",\"POS\",\"DEREP\",\"TYPE\",\"SENT_NO\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "hairy-beads",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>DEREP</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>SENT_NO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>But</td>\n",
       "      <td>CC</td>\n",
       "      <td>(TOP(S*</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>%um</td>\n",
       "      <td>UH</td>\n",
       "      <td>(INTJ*)</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>guessed</td>\n",
       "      <td>VBD</td>\n",
       "      <td>(VP*</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what</td>\n",
       "      <td>WP</td>\n",
       "      <td>(SBAR(WHNP*)</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Word  POS         DEREP TYPE  SENT_NO\n",
       "0      But   CC       (TOP(S*    O        1\n",
       "1      %um   UH       (INTJ*)    O        1\n",
       "2        ,    ,             *    O        1\n",
       "3  guessed  VBD          (VP*    O        1\n",
       "4     what   WP  (SBAR(WHNP*)    O        1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "included-angel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10976 entries, 0 to 10975\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Word     10976 non-null  object\n",
      " 1   POS      10976 non-null  object\n",
      " 2   DEREP    10976 non-null  object\n",
      " 3   TYPE     10976 non-null  object\n",
      " 4   SENT_NO  10976 non-null  int64 \n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 428.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "greenhouse-costume",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for i in range(df.shape[0]):\n",
    "    if df.iloc[i,:].TYPE == 'B-PERSON' or df.iloc[i,:].TYPE == 'I-PERSON':\n",
    "        words.append(\"Dodo\")\n",
    "    else:\n",
    "        words.append(df.iloc[i,:].Word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adjusted-middle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32488"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "foster-birthday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32488, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "naval-locator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "644"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.count(\"Dodo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "experienced-idaho",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'basically'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1,:].Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "literary-japan",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Word = words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "specialized-edward",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in df.groupby(\"SENT_NO\").groups.items():\n",
    "    temp = df.iloc[v,:]\n",
    "    temp.to_csv(\"/Users/ramybal/Downloads/bio/spark/test/onto_bc_ner_perturb2.txt\",mode='a',sep=\"\\t\",index=False,header=False)\n",
    "    with open(\"/Users/ramybal/Downloads/bio/spark/test/onto_bc_ner_perturb2.txt\",\"a\") as f:\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "portuguese-delay",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"/Users/ramybal/Downloads/bio/spark/test/onto_bc_ner_perturb1.txt\",sep=\"\\t\",index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "intense-squad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pathlib\n",
    "path = pathlib.Path(\"/Users/ramybal/Downloads/bio/spark/test\")\n",
    "flist = [str(f) for f in path.rglob(\"*.txt\") if str(f).endswith(\"_ner.txt\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "amateur-characterization",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/ramybal/Downloads/bio/spark/test/onto_nw_ner.txt',\n",
       " '/Users/ramybal/Downloads/bio/spark/test/onto_bc_ner.txt',\n",
       " '/Users/ramybal/Downloads/bio/spark/test/onto_wb_ner.txt',\n",
       " '/Users/ramybal/Downloads/bio/spark/test/onto_mz_ner.txt',\n",
       " '/Users/ramybal/Downloads/bio/spark/test/onto_pt_ner.txt',\n",
       " '/Users/ramybal/Downloads/bio/spark/test/onto_bn_ner.txt',\n",
       " '/Users/ramybal/Downloads/bio/spark/test/onto_tc_ner.txt']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "intended-entry",
   "metadata": {},
   "outputs": [],
   "source": [
    "flist.remove('/Users/ramybal/Downloads/bio/spark/test/onto_bc_ner.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "christian-calcium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ramybal/Downloads/bio/spark/test/onto_nw_ner.txt\n",
      "792\n",
      "49235\n",
      "49235\n",
      "/Users/ramybal/Downloads/bio/spark/test/onto_wb_ner.txt\n",
      "679\n",
      "18945\n",
      "18945\n",
      "/Users/ramybal/Downloads/bio/spark/test/onto_mz_ner.txt\n",
      "449\n",
      "17875\n",
      "17875\n",
      "/Users/ramybal/Downloads/bio/spark/test/onto_pt_ner.txt\n",
      "0\n",
      "16851\n",
      "16851\n",
      "/Users/ramybal/Downloads/bio/spark/test/onto_bn_ner.txt\n",
      "726\n",
      "23209\n",
      "23209\n",
      "/Users/ramybal/Downloads/bio/spark/test/onto_tc_ner.txt\n",
      "110\n",
      "10976\n",
      "10976\n"
     ]
    }
   ],
   "source": [
    "for f in flist:\n",
    "    print(f)\n",
    "    df = pd.read_csv(f,delimiter=\"\\t\", quoting=csv.QUOTE_NONE, encoding='utf-8',header=None,names=[\"Word\",\"POS\",\"DEREP\",\"TYPE\",\"SENT_NO\"])\n",
    "    words = []\n",
    "    for i in range(df.shape[0]):\n",
    "        if df.iloc[i,:].TYPE == 'B-PERSON' or df.iloc[i,:].TYPE == 'I-PERSON':\n",
    "            words.append(\"Dodo\")\n",
    "        else:\n",
    "            words.append(df.iloc[i,:].Word)\n",
    "    print(words.count(\"Dodo\"))\n",
    "    print(len(words))\n",
    "    print(df.shape[0])\n",
    "    df.Word = words\n",
    "    new_filename = f.replace(\".txt\",\"_perturb2.txt\")\n",
    "    for k, v in df.groupby(\"SENT_NO\").groups.items():\n",
    "        temp = df.iloc[v,:]\n",
    "        temp.to_csv(new_filename,mode='a',sep=\"\\t\",index=False,header=False)\n",
    "        with open(new_filename,\"a\") as f:\n",
    "            f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "acoustic-marking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['O', 'B-DATE', 'I-DATE', 'B-PERSON', 'B-GPE', 'I-GPE', 'B-TIME',\n",
       "       'B-CARDINAL', 'B-NORP', 'I-CARDINAL', 'I-TIME', 'B-ORDINAL',\n",
       "       'B-PRODUCT', 'B-ORG', 'B-PERCENT', 'I-PERCENT', 'B-LANGUAGE',\n",
       "       'I-PERSON', 'I-ORG', 'B-FAC', 'I-FAC', 'B-MONEY', 'I-MONEY',\n",
       "       'I-PRODUCT'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.TYPE.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fallen-technical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_base_cased download started this may take some time.\n",
      "Approximate size to download 389.1 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "embeddings = BertEmbeddings.pretrained(\"bert_base_cased\", \"en\") \\\n",
    "      .setInputCols(\"sentence\",\"token\") \\\n",
    "      .setOutputCol(\"embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "still-father",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onto_bert_base_cased download started this may take some time.\n",
      "Approximate size to download 15.5 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "ner_onto = NerDLModel.pretrained(\"onto_bert_base_cased\", \"en\") \\\n",
    "        .setInputCols([\"document\", \"token\", \"embeddings\"]) \\\n",
    "        .setOutputCol(\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "processed-reputation",
   "metadata": {},
   "outputs": [],
   "source": [
    "documentAssembler = DocumentAssembler().setInputCol(\"text\")\\\n",
    "                     .setOutputCol(\"document\")\\\n",
    "                     .setCleanupMode(\"shrink\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "acknowledged-desert",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer().setInputCols([\"sentence\"])\\\n",
    "                          .setOutputCol(\"token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "directed-arnold",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_assembler = DocumentAssembler().setInputCol(\"text\").setOutputCol(\"document\").setCleanupMode(\"shrink\")\n",
    "\n",
    "sentence_detector = SentenceDetector().setInputCols([\"document\"]).setOutputCol(\"sentence\")\n",
    "\n",
    "tokenizer = Tokenizer().setInputCols([\"sentence\"]).setOutputCol(\"token\")\n",
    "\n",
    "nlp_pipeline = Pipeline(stages=[document_assembler, sentence_detector, tokenizer, embeddings, ner_onto])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bronze-jones",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_model = nlp_pipeline.fit(spark.createDataFrame([['']]).toDF('text'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "balanced-pressure",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "path = pathlib.Path(\"/Users/ramybal/Downloads/bio/spark/test\")\n",
    "flist = [str(f) for f in path.rglob(\"*.*\") if \"perturb1\" in str(f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "large-struggle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/ramybal/Downloads/bio/spark/test/onto_bn_ner_perturb1.txt',\n",
       " '/Users/ramybal/Downloads/bio/spark/test/onto_nw_ner_perturb1.txt',\n",
       " '/Users/ramybal/Downloads/bio/spark/test/onto_wb_ner_perturb1.txt',\n",
       " '/Users/ramybal/Downloads/bio/spark/test/onto_tc_ner_perturb1.txt',\n",
       " '/Users/ramybal/Downloads/bio/spark/test/onto_mz_ner_perturb1.txt',\n",
       " '/Users/ramybal/Downloads/bio/spark/test/onto_pt_ner_perturb1.txt',\n",
       " '/Users/ramybal/Downloads/bio/spark/test/onto_bc_ner_perturb1.txt']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "alternative-handbook",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing for: /Users/ramybal/Downloads/bio/spark/test/onto_bn_ner_perturb1.txt\n",
      "there are 1252 sentences\n",
      "Done for 1000 in 28.919176816940308 seconds\n",
      "Done processing in 220.06137013435364 seconds\n",
      "doing for: /Users/ramybal/Downloads/bio/spark/test/onto_nw_ner_perturb1.txt\n",
      "there are 1898 sentences\n",
      "Done for 1000 in 35.327131032943726 seconds\n",
      "Done processing in 331.36916995048523 seconds\n",
      "doing for: /Users/ramybal/Downloads/bio/spark/test/onto_wb_ner_perturb1.txt\n",
      "there are 929 sentences\n",
      "Done processing in 166.31479001045227 seconds\n",
      "doing for: /Users/ramybal/Downloads/bio/spark/test/onto_tc_ner_perturb1.txt\n",
      "there are 1366 sentences\n",
      "Done for 1000 in 12.347544193267822 seconds\n",
      "Done processing in 200.78535294532776 seconds\n",
      "doing for: /Users/ramybal/Downloads/bio/spark/test/onto_mz_ner_perturb1.txt\n",
      "there are 780 sentences\n",
      "Done processing in 152.22356867790222 seconds\n",
      "doing for: /Users/ramybal/Downloads/bio/spark/test/onto_pt_ner_perturb1.txt\n",
      "there are 1217 sentences\n",
      "Done for 1000 in 20.625119924545288 seconds\n",
      "Done processing in 197.86945295333862 seconds\n",
      "doing for: /Users/ramybal/Downloads/bio/spark/test/onto_bc_ner_perturb1.txt\n",
      "there are 2037 sentences\n",
      "Done for 1000 in 26.687029123306274 seconds\n",
      "Done for 2000 in 48.50235295295715 seconds\n",
      "Done processing in 358.8815748691559 seconds\n"
     ]
    }
   ],
   "source": [
    "for f in flist:\n",
    "    print(\"doing for: \" + f)\n",
    "    df = pd.read_csv(f,delimiter=\"\\t\", quoting=csv.QUOTE_NONE,header=None,encoding='utf-8',names=[\"Word\",\"POS\",\"DEREP\",\"TYPE\",\"SENT_NO\"])\n",
    "    sentences = []\n",
    "    entities = []\n",
    "    entities_type = []\n",
    "    print(\"there are {} sentences\".format(len(df.groupby(\"SENT_NO\").groups.items())))\n",
    "    count = 1\n",
    "    start = time.time()\n",
    "    for _,v in df.groupby(\"SENT_NO\").groups.items():\n",
    "        temp1 = []\n",
    "        temp2 = []\n",
    "        temp3 = []\n",
    "        if count%1000 == 0:\n",
    "            print(\"Done for {} in {} seconds\".format(count,time.time()-start))\n",
    "        for i,t in enumerate(df.iloc[v,:].Word.tolist()):\n",
    "            if i < (len(df.iloc[v,:].Word.tolist())-1):\n",
    "                if df.iloc[v,:].Word.tolist()[i][0].isalnum() and not(df.iloc[v,:].Word.tolist()[i+1][0].isalnum()):\n",
    "                    temp1.append(t + df.iloc[v,:].Word.tolist()[i+1])\n",
    "                    temp2.append(df.iloc[v,:].TYPE.tolist()[i])\n",
    "                    temp2.append(df.iloc[v,:].TYPE.tolist()[i+1])\n",
    "                    temp3.append(df.iloc[v,:].Word.tolist()[i])\n",
    "                    temp3.append(df.iloc[v,:].Word.tolist()[i+1])\n",
    "                elif not(df.iloc[v,:].Word.tolist()[i][0].isalnum()):\n",
    "                    continue\n",
    "                else:\n",
    "                    temp1.append(t)\n",
    "                    temp2.append(df.iloc[v,:].TYPE.tolist()[i])\n",
    "                    temp3.append(df.iloc[v,:].Word.tolist()[i])\n",
    "            elif i == (len(df.iloc[v,:].Word.tolist())-1):\n",
    "                if t[0].isalnum():\n",
    "                    temp1.append(t)\n",
    "                    temp2.append(df.iloc[v,:].TYPE.tolist()[i])\n",
    "                    temp3.append(df.iloc[v,:].Word.tolist()[i])\n",
    "        sentences.append(\" \".join(temp3))\n",
    "        entities_type.append(temp2)\n",
    "        entities.append(temp3)\n",
    "        count += 1\n",
    "    sentences =  [s for s in sentences if s != \"\"]\n",
    "    entities_type =  [s for s in entities_type if s != []]\n",
    "    entities =  [s for s in entities if s != []]\n",
    "    detected_sent = []\n",
    "    detected_ner = []\n",
    "    detected_ner_type = []\n",
    "    start = time.time()\n",
    "    for sent in sentences:\n",
    "        df = spark.createDataFrame(pd.DataFrame({'text':[sent]}))\n",
    "        result = pipeline_model.transform(df)    \n",
    "        df_result = result.select(\"sentence\",\"ner\").collect()\n",
    "    \n",
    "        detected_sent.append([df_result[0][0][0].result])\n",
    "        ners = []\n",
    "        ner_types = []\n",
    "        for d in df_result[0][1]:\n",
    "            ners.append(d.metadata[\"word\"])\n",
    "            ner_types.append(d.result)\n",
    "        detected_ner.append(ners)\n",
    "        detected_ner_type.append(ner_types)\n",
    "    print(\"Done processing in {} seconds\".format(time.time()-start))\n",
    "    pd.DataFrame({\"Detected_sentence\":detected_sent,\"Actual_ners\":entities,\"Detected_ners\":detected_ner,\"Actual_ner_types\":entities_type,\"Detected_ner_types\":detected_ner_type}).to_csv(\"detect_\" + pathlib.Path(f).name.split(\".\")[0] + \"_perturb1.csv\",index = False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "equivalent-advantage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/ramybal/Downloads/bio/spark/test/onto_bn_ner_perturb1.txt',\n",
       " '/Users/ramybal/Downloads/bio/spark/test/onto_nw_ner_perturb1.txt',\n",
       " '/Users/ramybal/Downloads/bio/spark/test/onto_wb_ner_perturb1.txt',\n",
       " '/Users/ramybal/Downloads/bio/spark/test/onto_tc_ner_perturb1.txt',\n",
       " '/Users/ramybal/Downloads/bio/spark/test/onto_mz_ner_perturb1.txt',\n",
       " '/Users/ramybal/Downloads/bio/spark/test/onto_pt_ner_perturb1.txt',\n",
       " '/Users/ramybal/Downloads/bio/spark/test/onto_bc_ner_perturb1.txt']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "direct-looking",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = pathlib.Path(\"/Users/ramybal/Desktop/untitled folder/neuroner/\")\n",
    "flist = [str(f) for f in path.rglob(\"detect*_perturb1.csv\")]\n",
    "f = flist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "legal-hours",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ramybal/Desktop/untitled folder/neuroner/detect_onto_mz_ner_perturb1_perturb1.csv'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "impressed-updating",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "shared-watson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Detected_sentence</th>\n",
       "      <th>Actual_ners</th>\n",
       "      <th>Detected_ners</th>\n",
       "      <th>Actual_ner_types</th>\n",
       "      <th>Detected_ner_types</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['Genteel Journalis --']</td>\n",
       "      <td>['Genteel', 'Journalis', '--']</td>\n",
       "      <td>['Genteel', 'Journalis', '--']</td>\n",
       "      <td>['O', 'O', 'O']</td>\n",
       "      <td>['O', 'O', 'O']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['Dodo Dodo']</td>\n",
       "      <td>['Dodo', 'Dodo']</td>\n",
       "      <td>['Dodo', 'Dodo']</td>\n",
       "      <td>['B-PERSON', 'I-PERSON']</td>\n",
       "      <td>['O', 'O']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['Dodo Dodo / tr.']</td>\n",
       "      <td>['Dodo', 'Dodo', '/', 'tr.', 'by', 'Dodo', 'Do...</td>\n",
       "      <td>['Dodo', 'Dodo', '/', 'tr', '.', 'by', 'Dodo',...</td>\n",
       "      <td>['B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'B-PER...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['Dodo Dodo is the doyen of the Chinese news m...</td>\n",
       "      <td>['Dodo', 'Dodo', 'is', 'the', 'doyen', 'of', '...</td>\n",
       "      <td>['Dodo', 'Dodo', 'is', 'the', 'doyen', 'of', '...</td>\n",
       "      <td>['B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', '...</td>\n",
       "      <td>['B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['Still out on the journalistic front lines at...</td>\n",
       "      <td>['Still', 'out', 'on', 'the', 'journalistic', ...</td>\n",
       "      <td>['Still', 'out', 'on', 'the', 'journalistic', ...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DA...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Detected_sentence  \\\n",
       "0                           ['Genteel Journalis --']   \n",
       "1                                      ['Dodo Dodo']   \n",
       "2                                ['Dodo Dodo / tr.']   \n",
       "3  ['Dodo Dodo is the doyen of the Chinese news m...   \n",
       "4  ['Still out on the journalistic front lines at...   \n",
       "\n",
       "                                         Actual_ners  \\\n",
       "0                     ['Genteel', 'Journalis', '--']   \n",
       "1                                   ['Dodo', 'Dodo']   \n",
       "2  ['Dodo', 'Dodo', '/', 'tr.', 'by', 'Dodo', 'Do...   \n",
       "3  ['Dodo', 'Dodo', 'is', 'the', 'doyen', 'of', '...   \n",
       "4  ['Still', 'out', 'on', 'the', 'journalistic', ...   \n",
       "\n",
       "                                       Detected_ners  \\\n",
       "0                     ['Genteel', 'Journalis', '--']   \n",
       "1                                   ['Dodo', 'Dodo']   \n",
       "2  ['Dodo', 'Dodo', '/', 'tr', '.', 'by', 'Dodo',...   \n",
       "3  ['Dodo', 'Dodo', 'is', 'the', 'doyen', 'of', '...   \n",
       "4  ['Still', 'out', 'on', 'the', 'journalistic', ...   \n",
       "\n",
       "                                    Actual_ner_types  \\\n",
       "0                                    ['O', 'O', 'O']   \n",
       "1                           ['B-PERSON', 'I-PERSON']   \n",
       "2  ['B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'B-PER...   \n",
       "3  ['B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', '...   \n",
       "4  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DA...   \n",
       "\n",
       "                                  Detected_ner_types  \n",
       "0                                    ['O', 'O', 'O']  \n",
       "1                                         ['O', 'O']  \n",
       "2  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n",
       "3  ['B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'B...  \n",
       "4  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DA...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "million-lying",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "df[['Detected_ners']] = df[['Detected_ners']].applymap(yaml.safe_load) \n",
    "df[['Detected_ner_types']] = df[['Detected_ner_types']].applymap(yaml.safe_load) \n",
    "df[['Actual_ners']] = df[['Actual_ners']].applymap(yaml.safe_load) \n",
    "df[['Actual_ner_types']] = df[['Actual_ner_types']].applymap(yaml.safe_load)\n",
    "  \n",
    "\n",
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "industrial-vienna",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "institutional-leather",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multicount(searchlist,target):\n",
    "    temp = []\n",
    "    count = 0\n",
    "    while(count<len(searchlist)):\n",
    "        if searchlist[count].lower() == target.lower():\n",
    "            temp.append(count)\n",
    "        count += 1\n",
    "    return temp\n",
    " \n",
    "detect_ner = []\n",
    "detect_type = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    detect_ner_temp = []\n",
    "    detect_type_temp = []\n",
    "    flag = 0\n",
    "    for j,d in enumerate(df.iloc[i,:].Detected_ners):\n",
    "        if (j < (len(df.iloc[i,:].Detected_ners) - 1) and df.iloc[i,:].Detected_ners[j+1] == \"s\" and d == \"'\"):\n",
    "            detect_ner_temp.append(\"'s\")\n",
    "            detect_type_temp.append(\"O\")\n",
    "            flag = 1\n",
    "        elif d == \"s\" and flag == 1:\n",
    "            flag = 0\n",
    "            continue\n",
    "        else:\n",
    "            detect_ner_temp.append(d)\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j])\n",
    "    detect_ner.append(detect_ner_temp)\n",
    "    detect_type.append(detect_type_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "outdoor-station",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Detected_ners = detect_ner\n",
    "df.Detected_ner_types = detect_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "controlled-costs",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "hourly-alabama",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "excellent-fetish",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_ner = []\n",
    "detect_type = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    detect_ner_temp = []\n",
    "    detect_type_temp = []\n",
    "    flag = 0\n",
    "    for j,d in enumerate(df.iloc[i,:].Detected_ners):\n",
    "        if (j < (len(df.iloc[i,:].Detected_ners) - 1) and df.iloc[i,:].Detected_ners[j+1] == \".\" and \".\" in d):\n",
    "            detect_ner_temp.append(d + \".\")\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j])\n",
    "            flag = 1\n",
    "        elif d == \".\" and flag == 1:\n",
    "            flag = 0\n",
    "            continue\n",
    "        else:\n",
    "            detect_ner_temp.append(d)\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j])\n",
    "    detect_ner.append(detect_ner_temp)\n",
    "    detect_type.append(detect_type_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "intended-nothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Detected_ners = detect_ner\n",
    "df.Detected_ner_types = detect_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "charged-image",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "tribal-twelve",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "referenced-trust",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual\n",
      "['Dodo', 'Dodo', '/', 'tr.', 'by', 'Dodo', 'Dodo', '-RRB-']\n",
      "['B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O']\n",
      "detected\n",
      "['Dodo', 'Dodo', '/', 'tr', '.', 'by', 'Dodo', 'Dodo', '-', 'RRB', '-']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Now', 'that', 'I', \"'m\", 'in', 'my', '80s', ',', 'looking', 'back', 'I', 'think', 'I', 'can', 'say', 'I', \"'ve\", 'done', 'alright', 'in', 'both', 'respects', ',', 'and', 'I', \"'ve\", 'learnt', 'that', 'both', 'reporting', 'the', 'news', 'well', ',', 'and', 'finding', 'favor', 'with', 'women', ',', 'depend', 'on', 'your', 'character', 'and', 'conduct', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-DATE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['Now', 'that', 'I', \"'\", 'm', 'in', 'my', '80s', ',', 'looking', 'back', 'I', 'think', 'I', 'can', 'say', 'I', \"'\", 've', 'done', 'alright', 'in', 'both', 'respects', ',', 'and', 'I', \"'\", 've', 'learnt', 'that', 'both', 'reporting', 'the', 'news', 'well', ',', 'and', 'finding', 'favor', 'with', 'women', ',', 'depend', 'on', 'your', 'character', 'and', 'conduct', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-DATE', 'I-DATE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['I', 'have', 'always', 'remembered', 'the', 'encouragement', 'which', 'Mr.', 'Dodo', 'Dodo', 'gave', 'me', 'as', 'a', 'young', 'reporter', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['I', 'have', 'always', 'remembered', 'the', 'encouragement', 'which', 'Mr', '.', 'Dodo', 'Dodo', 'gave', 'me', 'as', 'a', 'young', 'reporter', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Looking', 'back', 'at', 'my', 'life', ',', 'I', \"'ve\", 'hardly', 'had', 'any', 'really', 'bad', 'experiences', 'in', 'my', 'relationships', 'with', 'women', ',', 'and', 'this', 'is', 'because', 'just', 'as', 'in', 'my', 'professional', 'life', ',', 'I', \"'ve\", 'always', 'maintained', 'a', 'self', '-', 'critical', 'attitude', 'towards', 'my', 'emotions', ',', 'and', 'always', 'tried', 'to', 'prevent', 'myself', 'acting', 'like', 'a', 'male', 'chauvinist', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['Looking', 'back', 'at', 'my', 'life', ',', 'I', \"'\", 've', 'hardly', 'had', 'any', 'really', 'bad', 'experiences', 'in', 'my', 'relationships', 'with', 'women', ',', 'and', 'this', 'is', 'because', 'just', 'as', 'in', 'my', 'professional', 'life', ',', 'I', \"'\", 've', 'always', 'maintained', 'a', 'self', '-', 'critical', 'attitude', 'towards', 'my', 'emotions', ',', 'and', 'always', 'tried', 'to', 'prevent', 'myself', 'acting', 'like', 'a', 'male', 'chauvinist', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in unequal[:4]:\n",
    "    print(\"actual\")\n",
    "    print(df.iloc[i,:].Actual_ners)\n",
    "    print(df.iloc[i,:].Actual_ner_types)\n",
    "    print(\"detected\")\n",
    "    print(df.iloc[i,:].Detected_ners)\n",
    "    print(df.iloc[i,:].Detected_ner_types)\n",
    "    print(\"-----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "mathematical-ranch",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_ner = []\n",
    "detect_type = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    detect_ner_temp = []\n",
    "    detect_type_temp = []\n",
    "    flag = 0\n",
    "    for j,d in enumerate(df.iloc[i,:].Detected_ners):\n",
    "        if (j < (len(df.iloc[i,:].Detected_ners) - 1) and d == \"'\"):\n",
    "            detect_ner_temp.append(\"'\" + df.iloc[i,:].Detected_ners[j+1])\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j])\n",
    "            flag = 1\n",
    "        elif flag == 1:\n",
    "            flag = 0\n",
    "            continue\n",
    "        else:\n",
    "            detect_ner_temp.append(d)\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j])\n",
    "    detect_ner.append(detect_ner_temp)\n",
    "    detect_type.append(detect_type_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "spectacular-wholesale",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Detected_ners = detect_ner\n",
    "df.Detected_ner_types = detect_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "secondary-examination",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "saved-masters",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "connected-sharing",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_ner = []\n",
    "actual_type = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    actual_ner_temp = []\n",
    "    actual_type_temp = []\n",
    "    flag = 0\n",
    "    for j,d in enumerate(df.iloc[i,:].Actual_ners):\n",
    "        if (j < (len(df.iloc[i,:].Actual_ners) - 1) and d == \"'\"):\n",
    "            actual_ner_temp.append(\"'\" + df.iloc[i,:].Actual_ners[j+1])\n",
    "            actual_type_temp.append(df.iloc[i,:].Actual_ner_types[j])\n",
    "            flag = 1\n",
    "        elif flag == 1:\n",
    "            flag = 0\n",
    "            continue\n",
    "        else:\n",
    "            actual_ner_temp.append(d)\n",
    "            actual_type_temp.append(df.iloc[i,:].Actual_ner_types[j])\n",
    "    actual_ner.append(actual_ner_temp)\n",
    "    actual_type.append(actual_type_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "unusual-hydrogen",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Actual_ners = actual_ner\n",
    "df.Actual_ner_types = actual_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "distributed-mouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "accepted-washington",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "responsible-check",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_ner = []\n",
    "detect_type = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    detect_ner_temp = []\n",
    "    detect_type_temp = []\n",
    "    flag = 0\n",
    "    for j,d in enumerate(df.iloc[i,:].Detected_ners):\n",
    "        if (j < (len(df.iloc[i,:].Detected_ners) - 2)) and df.iloc[i,:].Detected_ners[j+1] == \".\":\n",
    "            detect_ner_temp.append(d + \".\")\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j])\n",
    "            flag = 1\n",
    "        elif d == \".\" and flag == 1:\n",
    "            flag = 0\n",
    "            continue\n",
    "        else:\n",
    "            detect_ner_temp.append(d)\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j])\n",
    "    detect_ner.append(detect_ner_temp)\n",
    "    detect_type.append(detect_type_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "historic-chassis",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Detected_ners = detect_ner\n",
    "df.Detected_ner_types = detect_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "intellectual-influence",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "flying-history",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "phantom-broad",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_ner = []\n",
    "actual_type = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    actual_ner_temp = []\n",
    "    actual_type_temp = []\n",
    "    flag = 0\n",
    "    for j,d in enumerate(df.iloc[i,:].Actual_ners):\n",
    "        if (j < (len(df.iloc[i,:].Actual_ners) - 2)) and df.iloc[i,:].Actual_ners[j+1] == \".\":\n",
    "            actual_ner_temp.append(d + \".\")\n",
    "            actual_type_temp.append(df.iloc[i,:].Actual_ner_types[j])\n",
    "            flag = 1\n",
    "        elif d == \".\" and flag == 1:\n",
    "            flag = 0\n",
    "            continue\n",
    "        else:\n",
    "            actual_ner_temp.append(d)\n",
    "            actual_type_temp.append(df.iloc[i,:].Actual_ner_types[j])\n",
    "    actual_ner.append(actual_ner_temp)\n",
    "    actual_type.append(actual_type_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "leading-comment",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Actual_ners = actual_ner\n",
    "df.Actual_ner_types = actual_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fifteen-nursery",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "proper-sweden",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "split-williams",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual\n",
      "['Dodo', 'Dodo', '/', 'tr.', 'by', 'Dodo', 'Dodo', '-RRB-']\n",
      "['B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O']\n",
      "detected\n",
      "['Dodo', 'Dodo', '/', 'tr.', 'by', 'Dodo', 'Dodo', '-', 'RRB', '-']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['In', 'a', 'November', '28', 'press', 'release', ',', 'the', 'Mainland', 'Affairs', 'Council', '-LRB-', 'MAC', '-RRB-', 'the', 'government', 'body', 'in', 'charge', 'of', 'cross-strait', 'affairs', ',', 'diplomatically', 'stated', 'that', 'it', 'would', 'observe', 'and', 'implement', 'the', 'suggestions', 'of', 'the', 'Advisory', 'Group', 'if', 'and', 'when', 'they', 'become', 'official', 'government', 'policy', '.']\n",
      "['O', 'O', 'B-DATE', 'I-DATE', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['In', 'a', 'November', '28', 'press', 'release', ',', 'the', 'Mainland', 'Affairs', 'Council', '-', 'LRB', '-', 'MAC', '-', 'RRB', '-', 'the', 'government', 'body', 'in', 'charge', 'of', 'cross-strait', 'affairs', ',', 'diplomatically', 'stated', 'that', 'it', 'would', 'observe', 'and', 'implement', 'the', 'suggestions', 'of', 'the', 'Advisory', 'Group', 'if', 'and', 'when', 'they', 'become', 'official', 'government', 'policy', '.']\n",
      "['O', 'O', 'B-DATE', 'I-DATE', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Dodo', 'Dodo', 'Dodo', 'Dodo', '/', 'photos', 'by', 'Dodo', 'Dodo', '/', 'tr.', 'by', 'Dodo', 'Dodo', '-RRB-']\n",
      "['B-PERSON', 'I-PERSON', 'I-PERSON', 'I-PERSON', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O']\n",
      "detected\n",
      "['Dodo', 'Dodo', 'Dodo', 'Dodo', '/', 'photos', 'by', 'Dodo', 'Dodo', '/', 'tr.', 'by', 'Dodo', 'Dodo', '-', 'RRB', '-']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['But', 'others', 'say', 'it', 'comes', 'from', 'a', 'long', '-', 'gone', 'fishing', 'practice', ',', 'using', 'a', 'shi', 'hu', '-LRB-', 'stone', 'pool', '\"\"\"\"']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['But', 'others', 'say', 'it', 'comes', 'from', 'a', 'long', '-', 'gone', 'fishing', 'practice', ',', 'using', 'a', 'shi', 'hu', '-', 'LRB', '-', 'stone', 'pool', '\"\"\"\"']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Early', 'fishermen', 'used', 'stones', 'to', 'carve', 'a', 'long', ',', 'narrow', 'catchment', '-LRB-', 'the', 'so', '-', 'called', '\"\"\"\"', 'pool', '\"\"\"\"', 'in', 'the', 'sand', ',', 'waiting', 'for', 'the', 'tide', 'to', 'carry', 'in', 'fish', 'which', 'they', 'could', 'then', 'easily', 'scoop', 'up', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['Early', 'fishermen', 'used', 'stones', 'to', 'carve', 'a', 'long', ',', 'narrow', 'catchment', '-', 'LRB', '-', 'the', 'so', '-', 'called', '\"\"\"\"', 'pool', '\"\"\"\"', 'in', 'the', 'sand', ',', 'waiting', 'for', 'the', 'tide', 'to', 'carry', 'in', 'fish', 'which', 'they', 'could', 'then', 'easily', 'scoop', 'up', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Since', 'the', 'place', 'now', 'known', 'as', 'Tanshui', 'was', 'at', 'the', 'tail', 'end', '-LRB-', 'wei', '-RRB-', 'of', 'this', 'stone', 'pool', ',', 'it', 'came', 'to', 'be', 'called', 'Huwei', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'O']\n",
      "detected\n",
      "['Since', 'the', 'place', 'now', 'known', 'as', 'Tanshui', 'was', 'at', 'the', 'tail', 'end', '-', 'LRB', '-', 'wei', '-', 'RRB', '-', 'of', 'this', 'stone', 'pool', ',', 'it', 'came', 'to', 'be', 'called', 'Huwei', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Here', 'they', 'engaged', 'in', 'barter', 'trade', 'with', 'the', 'Pingpu', '-LRB-', 'meaning', '\"\"\"\"', 'plains', '\"\"\"\"', 'aborigines', ',', 'with', 'deer', 'skins', 'and', 'sulphur', 'being', 'the', 'most', 'coveted', 'products', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['Here', 'they', 'engaged', 'in', 'barter', 'trade', 'with', 'the', 'Pingpu', '-', 'LRB', '-', 'meaning', '\"\"\"\"', 'plains', '\"\"\"\"', 'aborigines', ',', 'with', 'deer', 'skins', 'and', 'sulphur', 'being', 'the', 'most', 'coveted', 'products', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['During', 'the', 'reign', 'of', 'the', 'Guangxu', 'emperor', 'of', 'the', 'Qing', 'dynasty', '-LRB-', 'which', 'began', 'in', '1875', '-RRB-', 'and', 'prior', 'to', 'the', 'beginning', 'of', 'the', 'Japanese', 'occupation', 'in', '1895', ',', 'Tanshui', 'produced', 'two', 'successful', 'candidates', 'in', 'the', 'highest', 'level', 'military', 'exam', ',', 'one', 'in', 'the', 'highest', 'level', 'civil', 'exam', ',', 'and', 'countless', 'successes', 'in', 'lower', '-', 'level', 'imperial', 'exams', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'B-GPE', 'O', 'O', 'B-DATE', 'I-DATE', 'I-DATE', 'O', 'O', 'O', 'O', 'B-DATE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'B-DATE', 'O', 'B-GPE', 'O', 'B-CARDINAL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-CARDINAL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['During', 'the', 'reign', 'of', 'the', 'Guangxu', 'emperor', 'of', 'the', 'Qing', 'dynasty', '-', 'LRB', '-', 'which', 'began', 'in', '1875', '-', 'RRB', '-', 'and', 'prior', 'to', 'the', 'beginning', 'of', 'the', 'Japanese', 'occupation', 'in', '1895', ',', 'Tanshui', 'produced', 'two', 'successful', 'candidates', 'in', 'the', 'highest', 'level', 'military', 'exam', ',', 'one', 'in', 'the', 'highest', 'level', 'civil', 'exam', ',', 'and', 'countless', 'successes', 'in', 'lower', '-', 'level', 'imperial', 'exams', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'B-DATE', 'I-DATE', 'I-DATE', 'O', 'B-EVENT', 'O', 'O', 'O', 'O', 'B-DATE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'B-DATE', 'O', 'B-GPE', 'O', 'B-CARDINAL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-CARDINAL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Owner', 'Dodo', 'Dodo', 'Dodo', 'Dodo', 'is', 'a', 'descendant', 'of', 'the', 'eminent', 'Dodo', 'family', 'of', 'Dodo', ',', 'which', 'produced', 'three', 'juren', '-LRB-', 'a', 'successful', 'candidate', 'in', 'provincial', '-', 'level', 'exams', ',', 'held', 'every', 'three', 'years', '-RRB-']\n",
      "['O', 'B-PERSON', 'I-PERSON', 'I-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'O', 'B-PERSON', 'O', 'O', 'O', 'B-CARDINAL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-CARDINAL', 'O', 'O']\n",
      "detected\n",
      "['Owner', 'Dodo', 'Dodo', 'Dodo', 'Dodo', 'is', 'a', 'descendant', 'of', 'the', 'eminent', 'Dodo', 'family', 'of', 'Dodo', ',', 'which', 'produced', 'three', 'juren', '-', 'LRB', '-', 'a', 'successful', 'candidate', 'in', 'provincial', '-', 'level', 'exams', ',', 'held', 'every', 'three', 'years', '-', 'RRB', '-']\n",
      "['O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'B-CARDINAL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE', 'I-DATE', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Dodo', 'Dodo', '-LRB-', 'whose', 'name', 'by', 'birth', 'is', 'Dodo', 'Dodo', '-RRB-', 'a', 'scholar', 'from', 'Beijing', 'University', 'currently', 'working', 'at', 'Chinese', 'Culture', 'University', 'on', 'an', 'exchange', 'program', ',', 'is', 'a', 'descendant', 'of', 'the', 'juren', 'Dodo', 'Dodo', ',', 'who', 'was', 'wounded', 'resisting', 'the', 'Japanese', 'occupation', 'and', 'fled', 'to', 'the', 'mainland', ',', 'where', 'he', 'settled', 'down', '.']\n",
      "['B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['Dodo', 'Dodo', '-', 'LRB', '-', 'whose', 'name', 'by', 'birth', 'is', 'Dodo', 'Dodo', '-', 'RRB', '-', 'a', 'scholar', 'from', 'Beijing', 'University', 'currently', 'working', 'at', 'Chinese', 'Culture', 'University', 'on', 'an', 'exchange', 'program', ',', 'is', 'a', 'descendant', 'of', 'the', 'juren', 'Dodo', 'Dodo', ',', 'who', 'was', 'wounded', 'resisting', 'the', 'Japanese', 'occupation', 'and', 'fled', 'to', 'the', 'mainland', ',', 'where', 'he', 'settled', 'down', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in unequal[:10]:\n",
    "    print(\"actual\")\n",
    "    print(df.iloc[i,:].Actual_ners)\n",
    "    print(df.iloc[i,:].Actual_ner_types)\n",
    "    print(\"detected\")\n",
    "    print(df.iloc[i,:].Detected_ners)\n",
    "    print(df.iloc[i,:].Detected_ner_types)\n",
    "    print(\"-----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "assumed-wholesale",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_ner = []\n",
    "detect_type = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    detect_ner_temp = []\n",
    "    detect_type_temp = []\n",
    "    flag = 0\n",
    "    for j,d in enumerate(df.iloc[i,:].Detected_ners):\n",
    "        if (j < (len(df.iloc[i,:].Detected_ners) - 2) and d == \"-\" and df.iloc[i,:].Detected_ners[j+1] in [\"LRB\",\"RRB\"]):\n",
    "            detect_ner_temp.append(\"-\" + df.iloc[i,:].Detected_ners[j+1] + \"-\")\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j+1])\n",
    "            flag = 1\n",
    "        elif flag == 1:\n",
    "            flag = 2\n",
    "            continue\n",
    "        elif flag == 2:\n",
    "            flag = 0\n",
    "            continue   \n",
    "        else:\n",
    "            detect_ner_temp.append(d)\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j])\n",
    "    detect_ner.append(detect_ner_temp)\n",
    "    detect_type.append(detect_type_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "tracked-illness",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Detected_ners = detect_ner\n",
    "df.Detected_ner_types = detect_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "competitive-george",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "boxed-ribbon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "above-sweden",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual\n",
      "['For', 'more', 'detailed', 'information', 'visit', 'http://www.tamsui.gov.tw/', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['For', 'more', 'detailed', 'information', 'visit', 'http://www.tamsui.gov.tw/.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "i = unequal[0]\n",
    "print(\"actual\")\n",
    "print(df.iloc[i,:].Actual_ners)\n",
    "print(df.iloc[i,:].Actual_ner_types)\n",
    "print(\"detected\")\n",
    "print(df.iloc[i,:].Detected_ners)\n",
    "print(df.iloc[i,:].Detected_ner_types)\n",
    "print(\"-----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "headed-recipe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in unequal:\n",
    "    df.iloc[i,:].Detected_ners = df.iloc[i,:].Actual_ners\n",
    "    df.iloc[i,:].Detected_ner_types = df.iloc[i,:].Actual_ner_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "contemporary-timeline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ramybal/Desktop/untitled folder/neuroner/detect_onto_mz_ner_perturb1_perturb1.csv\n",
      "accuracy score\n",
      "0.9678591709256105\n",
      "0.8338368580060423\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import accuracy_score, f1_score\n",
    "print(f)\n",
    "print(\"accuracy score\")\n",
    "print(accuracy_score(df.Actual_ner_types.tolist(),df.Detected_ner_types.tolist()))\n",
    "print(f1_score(df.Actual_ner_types.tolist(),df.Detected_ner_types.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "respiratory-convertible",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ramybal/Desktop/untitled folder/neuroner/detect_onto_tc_ner_perturb1_perturb1.csv\n"
     ]
    }
   ],
   "source": [
    "f = flist[1]\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "aging-heavy",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "secret-blood",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Detected_sentence</th>\n",
       "      <th>Actual_ners</th>\n",
       "      <th>Detected_ners</th>\n",
       "      <th>Actual_ner_types</th>\n",
       "      <th>Detected_ner_types</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['But %um guessed what happened .']</td>\n",
       "      <td>['But', '%um', 'guessed', 'what', 'happened', ...</td>\n",
       "      <td>['But', '%um', 'guessed', 'what', 'happened', ...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['What ?']</td>\n",
       "      <td>['What', '?']</td>\n",
       "      <td>['What', '?']</td>\n",
       "      <td>['O', 'O']</td>\n",
       "      <td>['O', 'O']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['The %um']</td>\n",
       "      <td>['The', '%um']</td>\n",
       "      <td>['The', '%um']</td>\n",
       "      <td>['O', 'O']</td>\n",
       "      <td>['O', 'O']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['Again ?']</td>\n",
       "      <td>['Again', '?']</td>\n",
       "      <td>['Again', '?']</td>\n",
       "      <td>['O', 'O']</td>\n",
       "      <td>['O', 'O']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[\"118.91_120.82_B: Let 's see ,\"]</td>\n",
       "      <td>['118.91_120.82_B:', 'Let', \"'s\", 'see', ',']</td>\n",
       "      <td>['118.91_120.82_B', ':', 'Let', \"'\", 's', 'see...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Detected_sentence  \\\n",
       "0  ['But %um guessed what happened .']   \n",
       "1                           ['What ?']   \n",
       "2                          ['The %um']   \n",
       "3                          ['Again ?']   \n",
       "4    [\"118.91_120.82_B: Let 's see ,\"]   \n",
       "\n",
       "                                         Actual_ners  \\\n",
       "0  ['But', '%um', 'guessed', 'what', 'happened', ...   \n",
       "1                                      ['What', '?']   \n",
       "2                                     ['The', '%um']   \n",
       "3                                     ['Again', '?']   \n",
       "4      ['118.91_120.82_B:', 'Let', \"'s\", 'see', ',']   \n",
       "\n",
       "                                       Detected_ners  \\\n",
       "0  ['But', '%um', 'guessed', 'what', 'happened', ...   \n",
       "1                                      ['What', '?']   \n",
       "2                                     ['The', '%um']   \n",
       "3                                     ['Again', '?']   \n",
       "4  ['118.91_120.82_B', ':', 'Let', \"'\", 's', 'see...   \n",
       "\n",
       "                 Actual_ner_types                   Detected_ner_types  \n",
       "0  ['O', 'O', 'O', 'O', 'O', 'O']       ['O', 'O', 'O', 'O', 'O', 'O']  \n",
       "1                      ['O', 'O']                           ['O', 'O']  \n",
       "2                      ['O', 'O']                           ['O', 'O']  \n",
       "3                      ['O', 'O']                           ['O', 'O']  \n",
       "4       ['O', 'O', 'O', 'O', 'O']  ['O', 'O', 'O', 'O', 'O', 'O', 'O']  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "humanitarian-coating",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Detected_ners']] = df[['Detected_ners']].applymap(yaml.safe_load) \n",
    "df[['Detected_ner_types']] = df[['Detected_ner_types']].applymap(yaml.safe_load) \n",
    "df[['Actual_ners']] = df[['Actual_ners']].applymap(yaml.safe_load) \n",
    "df[['Actual_ner_types']] = df[['Actual_ner_types']].applymap(yaml.safe_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "engaged-blair",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "spectacular-lecture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "338"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "necessary-daughter",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_ner = []\n",
    "detect_type = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    detect_ner_temp = []\n",
    "    detect_type_temp = []\n",
    "    flag = 0\n",
    "    for j,d in enumerate(df.iloc[i,:].Detected_ners):\n",
    "        if (j < (len(df.iloc[i,:].Detected_ners) - 2)) and df.iloc[i,:].Detected_ners[j+1] == \".\":\n",
    "            detect_ner_temp.append(d + \".\")\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j])\n",
    "            flag = 1\n",
    "        elif d == \".\" and flag == 1:\n",
    "            flag = 0\n",
    "            continue\n",
    "        else:\n",
    "            detect_ner_temp.append(d)\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j])\n",
    "    detect_ner.append(detect_ner_temp)\n",
    "    detect_type.append(detect_type_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "german-queens",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Detected_ners = detect_ner\n",
    "df.Detected_ner_types = detect_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "derived-school",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "homeless-outreach",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "364"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "tested-sewing",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_ner = []\n",
    "actual_type = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    actual_ner_temp = []\n",
    "    actual_type_temp = []\n",
    "    flag = 0\n",
    "    for j,d in enumerate(df.iloc[i,:].Actual_ners):\n",
    "        if (j < (len(df.iloc[i,:].Actual_ners) - 2)) and df.iloc[i,:].Actual_ners[j+1] == \".\":\n",
    "            actual_ner_temp.append(d + \".\")\n",
    "            actual_type_temp.append(df.iloc[i,:].Actual_ner_types[j])\n",
    "            flag = 1\n",
    "        elif d == \".\" and flag == 1:\n",
    "            flag = 0\n",
    "            continue\n",
    "        else:\n",
    "            actual_ner_temp.append(d)\n",
    "            actual_type_temp.append(df.iloc[i,:].Actual_ner_types[j])\n",
    "    actual_ner.append(actual_ner_temp)\n",
    "    actual_type.append(actual_type_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "guilty-greene",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Actual_ners = actual_ner\n",
    "df.Actual_ner_types = actual_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "personal-valuation",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "molecular-valuation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "338"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "coral-begin",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_ner = []\n",
    "detect_type = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    detect_ner_temp = []\n",
    "    detect_type_temp = []\n",
    "    flag = 0\n",
    "    for j,d in enumerate(df.iloc[i,:].Detected_ners):\n",
    "        if (j < (len(df.iloc[i,:].Detected_ners) - 1) and d == \"'\"):\n",
    "            detect_ner_temp.append(\"'\" + df.iloc[i,:].Detected_ners[j+1])\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j])\n",
    "            flag = 1\n",
    "        elif flag == 1:\n",
    "            flag = 0\n",
    "            continue\n",
    "        else:\n",
    "            detect_ner_temp.append(d)\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j])\n",
    "    detect_ner.append(detect_ner_temp)\n",
    "    detect_type.append(detect_type_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "located-click",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Detected_ners = detect_ner\n",
    "df.Detected_ner_types = detect_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "textile-hearts",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "immediate-music",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "funky-sarah",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_ner = []\n",
    "actual_type = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    actual_ner_temp = []\n",
    "    actual_type_temp = []\n",
    "    flag = 0\n",
    "    for j,d in enumerate(df.iloc[i,:].Actual_ners):\n",
    "        if (j < (len(df.iloc[i,:].Actual_ners) - 1) and d == \"'\"):\n",
    "            actual_ner_temp.append(\"'\" + df.iloc[i,:].Actual_ners[j+1])\n",
    "            actual_type_temp.append(df.iloc[i,:].Actual_ner_types[j])\n",
    "            flag = 1\n",
    "        elif flag == 1:\n",
    "            flag = 0\n",
    "            continue\n",
    "        else:\n",
    "            actual_ner_temp.append(d)\n",
    "            actual_type_temp.append(df.iloc[i,:].Actual_ner_types[j])\n",
    "    actual_ner.append(actual_ner_temp)\n",
    "    actual_type.append(actual_type_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "right-blowing",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Actual_ners = actual_ner\n",
    "df.Actual_ner_types = actual_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "surface-accountability",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "australian-atlanta",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "animated-humidity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual\n",
      "['118.91_120.82_B:', 'Let', \"'s\", 'see', ',']\n",
      "['O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['118.91_120.82_B', ':', 'Let', \"'s\", 'see', ',']\n",
      "['O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Very', 'ha-']\n",
      "['O', 'O']\n",
      "detected\n",
      "['Very', 'ha', '-']\n",
      "['O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['oh', '296.72_297.91_A:', 'oh', 'no', '.']\n",
      "['O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['oh', '296.72_297.91_A', ':', 'oh', 'no', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['You', 'know', ',', 'I', 'mean', ',', 'we', \"'re\", 'd-', ',', 'you', 'know', ',']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['You', 'know', ',', 'I', 'mean', ',', 'we', \"'re\", 'd', '-', ',', 'you', 'know', ',']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['but', 'I', 'think', 'he', \"'s\", 'at', 'a', 'point', 'now', 'where', 'he', \"'s\", 'reserved', 'us', 'of', 'that', '%um', 'you', 'know', 'that', 'she', 'may', 'end', 'up', 'going', '%um', 'to', '%uh', 't-']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['but', 'I', 'think', 'he', \"'s\", 'at', 'a', 'point', 'now', 'where', 'he', \"'s\", 'reserved', 'us', 'of', 'that', '%um', 'you', 'know', 'that', 'she', 'may', 'end', 'up', 'going', '%um', 'to', '%uh', 't', '-']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['I', 'truly', 'believe', 'that', '**Salem**']\n",
      "['O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['I', 'truly', 'believe', 'that', '**', 'Salem', '**']\n",
      "['O', 'O', 'O', 'O', 'O', 'B-PERSON', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['t-', ',']\n",
      "['O', 'O']\n",
      "detected\n",
      "['t', '-', ',']\n",
      "['O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['a-', ',']\n",
      "['O', 'O']\n",
      "detected\n",
      "['a', '-', ',']\n",
      "['O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Well', 'it', \"'s\", 'good', 'to', 'hear', 'from', 'Dodo', 'who', \"'s\", 'had', 'a', 'lot', 'of', 'child-']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['Well', 'it', \"'s\", 'good', 'to', 'hear', 'from', 'Dodo', 'who', \"'s\", 'had', 'a', 'lot', 'of', 'child', '-']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['j-', ',', 'j-', ',']\n",
      "['O', 'O', 'O', 'O']\n",
      "detected\n",
      "['j', '-', ',', 'j', '-', ',']\n",
      "['O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in unequal[:10]:\n",
    "    print(\"actual\")\n",
    "    print(df.iloc[i,:].Actual_ners)\n",
    "    print(df.iloc[i,:].Actual_ner_types)\n",
    "    print(\"detected\")\n",
    "    print(df.iloc[i,:].Detected_ners)\n",
    "    print(df.iloc[i,:].Detected_ner_types)\n",
    "    print(\"-----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "hourly-understanding",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in unequal[:10]:\n",
    "    df.iloc[i,:].Detected_ners = df.iloc[i,:].Actual_ners\n",
    "    df.iloc[i,:].Detected_ner_types = df.iloc[i,:].Actual_ner_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "authentic-command",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual\n",
      "['no', 'w-']\n",
      "['O', 'O']\n",
      "detected\n",
      "['no', 'w', '-']\n",
      "['O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['And', 'she', 'has', 't-', 'aw']\n",
      "['O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['And', 'she', 'has', 't', '-', 'aw']\n",
      "['O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['that', 'had', \"n't\", 'happ-', ',']\n",
      "['O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['that', 'had', \"n't\", 'happ', '-', ',']\n",
      "['O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Because', ',', 'I', 'r-']\n",
      "['O', 'O', 'O', 'O']\n",
      "detected\n",
      "['Because', ',', 'I', 'r', '-']\n",
      "['O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['oh', 'I', \"'m\", 'han-']\n",
      "['O', 'O', 'O', 'O']\n",
      "detected\n",
      "['oh', 'I', \"'m\", 'han', '-']\n",
      "['O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['So', 'it', \"'s\", 'just', ',', 'l-', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['So', 'it', \"'s\", 'just', ',', 'l', '-', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['And', 'how', 'the', 'inflammation', 'd-']\n",
      "['O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['And', 'how', 'the', 'inflammation', 'd', '-']\n",
      "['O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Was', 'this', 'last', 'crop', 'of', '**Tuftees**', 'good', '?']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['Was', 'this', 'last', 'crop', 'of', '**', 'Tuftees', '**', 'good', '?']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['It', \"'s\", 'one', 'of', 'these', 'sort', 'of', 'universi-', 'the', 'public', 'university', 'book', 'stuff', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['It', \"'s\", 'one', 'of', 'these', 'sort', 'of', 'universi', '-', 'the', 'public', 'university', 'book', 'stuff', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['the-', ',']\n",
      "['O', 'O']\n",
      "detected\n",
      "['the', '-', ',']\n",
      "['O', 'O', 'O']\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in unequal[10:20]:\n",
    "    print(\"actual\")\n",
    "    print(df.iloc[i,:].Actual_ners)\n",
    "    print(df.iloc[i,:].Actual_ner_types)\n",
    "    print(\"detected\")\n",
    "    print(df.iloc[i,:].Detected_ners)\n",
    "    print(df.iloc[i,:].Detected_ner_types)\n",
    "    print(\"-----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "demographic-north",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in unequal[10:20]:\n",
    "    df.iloc[i,:].Detected_ners = df.iloc[i,:].Actual_ners\n",
    "    df.iloc[i,:].Detected_ner_types = df.iloc[i,:].Actual_ner_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fitting-affairs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual\n",
      "['actually', ',', 'I', \"'m\", 'not', 'sure', 'if', 'we', \"'re\", 'shooting', 'for', 'op-', ',']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['actually', ',', 'I', \"'m\", 'not', 'sure', 'if', 'we', \"'re\", 'shooting', 'for', 'op', '-', ',']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['I', 'mean', 'the', 'thing', 'that', 'i-']\n",
      "['O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['I', 'mean', 'the', 'thing', 'that', 'i', '-']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['it', 'has', 'an', 'off', 'board', 'power', 'supply', 'which', 'they', 'did', \"n't\", 'steal', ',', 'which', 'makes', 'the', 'thing', 'that', 'they', '**stoled**', 'absolutely', 'worthless', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['it', 'has', 'an', 'off', 'board', 'power', 'supply', 'which', 'they', 'did', \"n't\", 'steal', ',', 'which', 'makes', 'the', 'thing', 'that', 'they', '**', 'stoled', '**', 'absolutely', 'worthless', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['but', 'I', 'can', 'pick', 'you', 'up', 'th-', ',']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['but', 'I', 'can', 'pick', 'you', 'up', 'th', '-', ',']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['And', ',', 'an-']\n",
      "['O', 'O', 'O']\n",
      "detected\n",
      "['And', ',', 'an', '-']\n",
      "['O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['the', 'mil-', ',']\n",
      "['O', 'O', 'O']\n",
      "detected\n",
      "['the', 'mil', '-', ',']\n",
      "['O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['it', 'was', 'i-', ',']\n",
      "['O', 'O', 'O', 'O']\n",
      "detected\n",
      "['it', 'was', 'i', '-', ',']\n",
      "['O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Although', 'g-']\n",
      "['O', 'O']\n",
      "detected\n",
      "['Although', 'g', '-']\n",
      "['O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Th-', ',']\n",
      "['O', 'O']\n",
      "detected\n",
      "['Th', '-', ',']\n",
      "['O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['See', 'I', 'think', 'y-', ',']\n",
      "['O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['See', 'I', 'think', 'y', '-', ',']\n",
      "['O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in unequal[20:30]:\n",
    "    print(\"actual\")\n",
    "    print(df.iloc[i,:].Actual_ners)\n",
    "    print(df.iloc[i,:].Actual_ner_types)\n",
    "    print(\"detected\")\n",
    "    print(df.iloc[i,:].Detected_ners)\n",
    "    print(df.iloc[i,:].Detected_ner_types)\n",
    "    print(\"-----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "spoken-happiness",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in unequal[20:30]:\n",
    "    df.iloc[i,:].Detected_ners = df.iloc[i,:].Actual_ners\n",
    "    df.iloc[i,:].Detected_ner_types = df.iloc[i,:].Actual_ner_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "about-mirror",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual\n",
      "['So', 'I', 'mean', 'any', 'income', 'that', 'y-']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['So', 'I', 'mean', 'any', 'income', 'that', 'y', '-']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['I', 'had', 'Kans-', ',']\n",
      "['O', 'O', 'O', 'O']\n",
      "detected\n",
      "['I', 'had', 'Kans', '-', ',']\n",
      "['O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['I', \"'ll\", 'give', 'you', 'a', 'call', 'when', 'we', 'arrive', 'in', 'h-', ',']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['I', \"'ll\", 'give', 'you', 'a', 'call', 'when', 'we', 'arrive', 'in', 'h', '-', ',']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['but', 'that', \"'s\", 'only', 'when', 'yo-', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['but', 'that', \"'s\", 'only', 'when', 'yo', '-', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['And', 'when', 'he', 'goes', 'to', 'work', 'he', 'brings', 'four', 'sandwiches', 'with', 'him', ',', 'uh-huh.', 'a', 'bag', 'of', 'potato', 'chips', 'uh-huh.', 'you', 'know', 'and', 'then', 'little', 'sweetie', 'things', 'chocolates', 'and', '**cakies**', 'and', 'stuff', 'like', 'that', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-CARDINAL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['And', 'when', 'he', 'goes', 'to', 'work', 'he', 'brings', 'four', 'sandwiches', 'with', 'him', ',', 'uh-huh.', 'a', 'bag', 'of', 'potato', 'chips', 'uh-huh.', 'you', 'know', 'and', 'then', 'little', 'sweetie', 'things', 'chocolates', 'and', '**', 'cakies', '**', 'and', 'stuff', 'like', 'that', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-CARDINAL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['But', '%uh', '291.01_291.28_B:', '%hm']\n",
      "['O', 'O', 'O', 'O']\n",
      "detected\n",
      "['But', '%uh', '291.01_291.28_B', ':', '%hm']\n",
      "['O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['how', 'fun-', '.']\n",
      "['O', 'O', 'O']\n",
      "detected\n",
      "['how', 'fun', '-', '.']\n",
      "['O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Well', 'I', 'kind', 'of', 'thou-', ',']\n",
      "['O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['Well', 'I', 'kind', 'of', 'thou', '-', ',']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['An-', ',']\n",
      "['O', 'O']\n",
      "detected\n",
      "['An', '-', ',']\n",
      "['O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['But', 'o-']\n",
      "['O', 'O']\n",
      "detected\n",
      "['But', 'o', '-']\n",
      "['O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Pe-']\n",
      "['O']\n",
      "detected\n",
      "['Pe', '-']\n",
      "['O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['and', 'the-', ',']\n",
      "['O', 'O', 'O']\n",
      "detected\n",
      "['and', 'the', '-', ',']\n",
      "['O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in unequal[30:]:\n",
    "    print(\"actual\")\n",
    "    print(df.iloc[i,:].Actual_ners)\n",
    "    print(df.iloc[i,:].Actual_ner_types)\n",
    "    print(\"detected\")\n",
    "    print(df.iloc[i,:].Detected_ners)\n",
    "    print(df.iloc[i,:].Detected_ner_types)\n",
    "    print(\"-----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "interstate-lodge",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in unequal[30:]:\n",
    "    df.iloc[i,:].Detected_ners = df.iloc[i,:].Actual_ners\n",
    "    df.iloc[i,:].Detected_ner_types = df.iloc[i,:].Actual_ner_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "known-suite",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ramybal/Desktop/untitled folder/neuroner/detect_onto_tc_ner_perturb1_perturb1.csv\n",
      "accuracy score\n",
      "0.9790083586626139\n",
      "0.7565337001375516\n"
     ]
    }
   ],
   "source": [
    "print(f)\n",
    "print(\"accuracy score\")\n",
    "print(accuracy_score(df.Actual_ner_types.tolist(),df.Detected_ner_types.tolist()))\n",
    "print(f1_score(df.Actual_ner_types.tolist(),df.Detected_ner_types.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "loved-bulgarian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ramybal/Desktop/untitled folder/neuroner/detect_onto_pt_ner_perturb1_perturb1.csv\n"
     ]
    }
   ],
   "source": [
    "f = flist[2]\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "appointed-cable",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f)\n",
    "df[['Detected_ners']] = df[['Detected_ners']].applymap(yaml.safe_load) \n",
    "df[['Detected_ner_types']] = df[['Detected_ner_types']].applymap(yaml.safe_load) \n",
    "df[['Actual_ners']] = df[['Actual_ners']].applymap(yaml.safe_load) \n",
    "df[['Actual_ner_types']] = df[['Actual_ner_types']].applymap(yaml.safe_load)\n",
    "  \n",
    "\n",
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "regional-marketing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "advised-examination",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_ner = []\n",
    "detect_type = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    detect_ner_temp = []\n",
    "    detect_type_temp = []\n",
    "    flag = 0\n",
    "    for j,d in enumerate(df.iloc[i,:].Detected_ners):\n",
    "        if (j < (len(df.iloc[i,:].Detected_ners) - 1) and d == \"'\"):\n",
    "            detect_ner_temp.append(\"'\" + df.iloc[i,:].Detected_ners[j+1])\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j])\n",
    "            flag = 1\n",
    "        elif flag == 1:\n",
    "            flag = 0\n",
    "            continue\n",
    "        else:\n",
    "            detect_ner_temp.append(d)\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j])\n",
    "    detect_ner.append(detect_ner_temp)\n",
    "    detect_type.append(detect_type_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "proved-generic",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Detected_ners = detect_ner\n",
    "df.Detected_ner_types = detect_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "compatible-princess",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "federal-sessions",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "gothic-contemporary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual\n",
      "['Jesus', 'answered', ',', 'You', 'must', 'not', 'murder', 'anyone', ',', 'you', 'must', 'not', 'commit', 'adultery', ',', 'you', 'must', 'not', 'steal', ',', 'you', 'must', 'not', 'tell', 'lies', 'about', 'others', ',', 'you', 'must', 'respect', 'your', 'father', 'and', 'mother', ',', 'and', \"'\", 'love', 'your', 'neighbor', 'the', 'same', 'as', 'you', 'love', 'yourself', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['Jesus', 'answered', ',', 'You', 'must', 'not', 'murder', 'anyone', ',', 'you', 'must', 'not', 'commit', 'adultery', ',', 'you', 'must', 'not', 'steal', ',', 'you', 'must', 'not', 'tell', 'lies', 'about', 'others', ',', 'you', 'must', 'respect', 'your', 'father', 'and', 'mother', ',', 'and', \"'love\", 'your', 'neighbor', 'the', 'same', 'as', 'you', 'love', 'yourself', '.']\n",
      "['B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Their', 'teeth', 'were', 'like', 'lions', \"'\", 'teeth', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['Their', 'teeth', 'were', 'like', 'lions', \"'teeth\", '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['A', 'third', 'of', 'all', 'the', 'people', 'on', 'earth', 'were', 'killed', 'by', 'these', 'three', 'plagues', 'coming', 'out', 'of', 'the', 'horses', \"'\", 'mouths', ':', 'the', 'fire', ',', 'the', 'smoke', ',', 'and', 'the', 'sulfur', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['A', 'third', 'of', 'all', 'the', 'people', 'on', 'earth', 'were', 'killed', 'by', 'these', 'three', 'plagues', 'coming', 'out', 'of', 'the', 'horses', \"'mouths\", ':', 'the', 'fire', ',', 'the', 'smoke', ',', 'and', 'the', 'sulfur', '.']\n",
      "['B-CARDINAL', 'I-CARDINAL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-CARDINAL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['The', 'horses', \"'\", 'power', 'was', 'in', 'their', 'mouths', 'and', 'also', 'in', 'their', 'tails', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['The', 'horses', \"'power\", 'was', 'in', 'their', 'mouths', 'and', 'also', 'in', 'their', 'tails', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['And', ',', 'Where', 'God', 'said', 'in', 'the', 'past', ',', 'You', 'are', 'not', 'my', 'people', \"'\", 'there', 'they', 'will', 'be', 'called', 'children', 'of', 'the', 'living', 'God', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['And', ',', 'Where', 'God', 'said', 'in', 'the', 'past', ',', 'You', 'are', 'not', 'my', 'people', \"'there\", 'they', 'will', 'be', 'called', 'children', 'of', 'the', 'living', 'God', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['But', 'you', 'have', 'changed', 'it', 'into', 'a', \"'\", 'hiding', 'place', 'for', 'thieves', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['But', 'you', 'have', 'changed', 'it', 'into', 'a', \"'hiding\", 'place', 'for', 'thieves', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Jesus', \"'\", 'followers', 'began', 'to', 'have', 'an', 'argument', 'about', 'which', 'one', 'of', 'them', 'was', 'the', 'greatest', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['Jesus', \"'followers\", 'began', 'to', 'have', 'an', 'argument', 'about', 'which', 'one', 'of', 'them', 'was', 'the', 'greatest', '.']\n",
      "['B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-CARDINAL', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Jesus', \"'\", 'followers', 'asked', 'him', ',', 'Teacher', ',', 'why', 'was', 'this', 'man', 'born', 'blind', '?']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['Jesus', \"'followers\", 'asked', 'him', ',', 'Teacher', ',', 'why', 'was', 'this', 'man', 'born', 'blind', '?']\n",
      "['B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Jesus', \"'\", 'mother', 'stood', 'near', 'his', 'cross', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['Jesus', \"'mother\", 'stood', 'near', 'his', 'cross', '.']\n",
      "['B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['So', 'after', 'that', ',', 'this', 'follower', 'took', 'Jesus', \"'\", 'mother', 'to', 'live', 'in', 'his', 'home', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['So', 'after', 'that', ',', 'this', 'follower', 'took', 'Jesus', \"'mother\", 'to', 'live', 'in', 'his', 'home', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in unequal[:10]:\n",
    "    print(\"actual\")\n",
    "    print(df.iloc[i,:].Actual_ners)\n",
    "    print(df.iloc[i,:].Actual_ner_types)\n",
    "    print(\"detected\")\n",
    "    print(df.iloc[i,:].Detected_ners)\n",
    "    print(df.iloc[i,:].Detected_ner_types)\n",
    "    print(\"-----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "juvenile-shopper",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_ner = []\n",
    "actual_type = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    actual_ner_temp = []\n",
    "    actual_type_temp = []\n",
    "    flag = 0\n",
    "    for j,d in enumerate(df.iloc[i,:].Actual_ners):\n",
    "        if (j < (len(df.iloc[i,:].Actual_ners) - 1) and d == \"'\"):\n",
    "            actual_ner_temp.append(\"'\" + df.iloc[i,:].Actual_ners[j+1])\n",
    "            actual_type_temp.append(df.iloc[i,:].Actual_ner_types[j])\n",
    "            flag = 1\n",
    "        elif flag == 1:\n",
    "            flag = 0\n",
    "            continue\n",
    "        else:\n",
    "            actual_ner_temp.append(d)\n",
    "            actual_type_temp.append(df.iloc[i,:].Actual_ner_types[j])\n",
    "    actual_ner.append(actual_ner_temp)\n",
    "    actual_type.append(actual_type_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "round-pattern",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Actual_ners = actual_ner\n",
    "df.Actual_ner_types = actual_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "stupid-audience",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "female-circulation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "above-processing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ramybal/Desktop/untitled folder/neuroner/detect_onto_pt_ner_perturb1_perturb1.csv\n",
      "accuracy score\n",
      "0.9405382210506957\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(f)\n",
    "print(\"accuracy score\")\n",
    "print(accuracy_score(df.Actual_ner_types.tolist(),df.Detected_ner_types.tolist()))\n",
    "print(f1_score(df.Actual_ner_types.tolist(),df.Detected_ner_types.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "widespread-match",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = flist[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "dental-cleaner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ramybal/Desktop/untitled folder/neuroner/detect_onto_bn_ner_perturb1_perturb1.csv'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "catholic-grammar",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f)\n",
    "df[['Detected_ners']] = df[['Detected_ners']].applymap(yaml.safe_load) \n",
    "df[['Detected_ner_types']] = df[['Detected_ner_types']].applymap(yaml.safe_load) \n",
    "df[['Actual_ners']] = df[['Actual_ners']].applymap(yaml.safe_load) \n",
    "df[['Actual_ner_types']] = df[['Actual_ner_types']].applymap(yaml.safe_load)\n",
    "  \n",
    "\n",
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "demonstrated-flower",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "308"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "incredible-diagnosis",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_ner = []\n",
    "detect_type = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    detect_ner_temp = []\n",
    "    detect_type_temp = []\n",
    "    flag = 0\n",
    "    for j,d in enumerate(df.iloc[i,:].Detected_ners):\n",
    "        if (j < (len(df.iloc[i,:].Detected_ners) - 1) and d == \"'\"):\n",
    "            detect_ner_temp.append(\"'\" + df.iloc[i,:].Detected_ners[j+1])\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j])\n",
    "            flag = 1\n",
    "        elif flag == 1:\n",
    "            flag = 0\n",
    "            continue\n",
    "        else:\n",
    "            detect_ner_temp.append(d)\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j])\n",
    "    detect_ner.append(detect_ner_temp)\n",
    "    detect_type.append(detect_type_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "oriental-sleeve",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Detected_ners = detect_ner\n",
    "df.Detected_ner_types = detect_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ordered-listing",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "confident-ecology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "funky-purchase",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual\n",
      "['Dodo', \"'s\", '1989', 'novel', '`', 'Soul', 'Mountain', \"'\", 'will', 'be', 'published', 'for', 'the', 'first', 'time', 'in', 'America', '.']\n",
      "['B-PERSON', 'O', 'B-DATE', 'O', 'B-WORK_OF_ART', 'I-WORK_OF_ART', 'I-WORK_OF_ART', 'I-WORK_OF_ART', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'O']\n",
      "detected\n",
      "['Dodo', \"'s\", '1989', 'novel', '`', 'Soul', 'Mountain', \"'will\", 'be', 'published', 'for', 'the', 'first', 'time', 'in', 'America', '.']\n",
      "['B-PERSON', 'O', 'B-DATE', 'O', 'O', 'B-WORK_OF_ART', 'I-WORK_OF_ART', 'O', 'O', 'O', 'O', 'O', 'B-ORDINAL', 'O', 'O', 'B-GPE', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['This', 'novel', '`', 'soul', 'mountain', \"'\", 'which', 'is', 'just', 'being', 'released', 'in', 'the', 'United', 'States', 'this', 'week', 'is', 'in', 'every', 'possible', 'way', 'a', 'celebration', 'of', 'what', 'freedom', 'means', '.']\n",
      "['O', 'O', 'B-WORK_OF_ART', 'I-WORK_OF_ART', 'I-WORK_OF_ART', 'I-WORK_OF_ART', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'I-GPE', 'I-GPE', 'B-DATE', 'I-DATE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['This', 'novel', '`', 'soul', 'mountain', \"'which\", 'is', 'just', 'being', 'released', 'in', 'the', 'United', 'States', 'this', 'week', 'is', 'in', 'every', 'possible', 'way', 'a', 'celebration', 'of', 'what', 'freedom', 'means', '.']\n",
      "['O', 'O', 'B-WORK_OF_ART', 'I-WORK_OF_ART', 'I-WORK_OF_ART', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'I-GPE', 'I-GPE', 'B-DATE', 'I-DATE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Former', 'U.S.', 'representative', 'Dodo', 'Dodo', 'has', 'died', '.']\n",
      "['O', 'B-GPE', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O']\n",
      "detected\n",
      "['Former', 'U.S', '.', 'representative', 'Dodo', 'Dodo', 'has', 'died', '.']\n",
      "['O', 'B-GPE', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Dodo', 'Dodo', 'was', 'first', 'elected', 'to', 'the', 'U.S.', 'house', 'in', '1948', ',', 'when', 'Dodo', 'Dodo', 'was', 'President', 'and', 'for', 'more', 'than', '4', 'decades', 'he', 'trounced', 'every', 'challenger', 'to', 'face', 'him', 'in', 'congressional', 'election', '.']\n",
      "['B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'O', 'O', 'B-DATE', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'B-DATE', 'I-DATE', 'I-DATE', 'I-DATE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['Dodo', 'Dodo', 'was', 'first', 'elected', 'to', 'the', 'U.S', '.', 'house', 'in', '1948', ',', 'when', 'Dodo', 'Dodo', 'was', 'President', 'and', 'for', 'more', 'than', '4', 'decades', 'he', 'trounced', 'every', 'challenger', 'to', 'face', 'him', 'in', 'congressional', 'election', '.']\n",
      "['B-PERSON', 'I-PERSON', 'O', 'B-ORDINAL', 'O', 'O', 'O', 'B-GPE', 'O', 'O', 'O', 'B-DATE', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'B-DATE', 'I-DATE', 'I-DATE', 'I-DATE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Well', ',', 'Mr.', 'Dodo', 'has', 'been', ',', 'as', 'you', 'say', ',', 'a', 'voice', 'of', 'moderation', '.']\n",
      "['O', 'O', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['Well', ',', 'Mr', '.', 'Dodo', 'has', 'been', ',', 'as', 'you', 'say', ',', 'a', 'voice', 'of', 'moderation', '.']\n",
      "['O', 'O', 'O', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['So', ',', 'I', 'think', 'terrorists', 'prevented', 'from', 'attacking', 'their', 'targets', 'using', 'their', 'more', 'conventional', 'means', '`', 'truck', 'bombs', \"'\", 'have', 'merely', 'adjusted', 'their', 'tactics', 'slightly', 'and', 'obviously', 'they', 'have', 'been', 'successful', 'with', 'it', 'today', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE', 'O']\n",
      "detected\n",
      "['So', ',', 'I', 'think', 'terrorists', 'prevented', 'from', 'attacking', 'their', 'targets', 'using', 'their', 'more', 'conventional', 'means', '`', 'truck', 'bombs', \"'have\", 'merely', 'adjusted', 'their', 'tactics', 'slightly', 'and', 'obviously', 'they', 'have', 'been', 'successful', 'with', 'it', 'today', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Regarding', 'the', 'United', 'States', \"'\", 'attitude', 'in', 'this', 'regard', ',', 'we', 'find', 'that', 'the', 'United', 'States', 'until', 'now', 'are', 'supporting', 'Israel', '.']\n",
      "['O', 'B-GPE', 'I-GPE', 'I-GPE', 'I-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'I-GPE', 'I-GPE', 'O', 'O', 'O', 'O', 'B-GPE', 'O']\n",
      "detected\n",
      "['Regarding', 'the', 'United', 'States', \"'attitude\", 'in', 'this', 'regard', ',', 'we', 'find', 'that', 'the', 'United', 'States', 'until', 'now', 'are', 'supporting', 'Israel', '.']\n",
      "['O', 'B-GPE', 'I-GPE', 'I-GPE', 'I-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'I-GPE', 'I-GPE', 'O', 'O', 'O', 'O', 'B-GPE', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['While', 'all', 'this', 'is', 'going', 'on', ',', 'Mr.', 'Dodo', 'is', 'overseas', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'O', 'O']\n",
      "detected\n",
      "['While', 'all', 'this', 'is', 'going', 'on', ',', 'Mr', '.', 'Dodo', 'is', 'overseas', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['This', 'is', 'Mr.', 'Dodo', \"'s\", 'third', 'visit', 'to', 'Northern', 'Ireland', ',', 'and', 'the', 'Irish', 'Republic', 'to', 'do', 'what', 'he', 'can', 'to', 'generate', 'a', 'lasting', 'peace', '.']\n",
      "['O', 'O', 'O', 'B-PERSON', 'O', 'B-ORDINAL', 'O', 'O', 'B-GPE', 'I-GPE', 'O', 'O', 'B-GPE', 'I-GPE', 'I-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['This', 'is', 'Mr', '.', 'Dodo', \"'s\", 'third', 'visit', 'to', 'Northern', 'Ireland', ',', 'and', 'the', 'Irish', 'Republic', 'to', 'do', 'what', 'he', 'can', 'to', 'generate', 'a', 'lasting', 'peace', '.']\n",
      "['O', 'O', 'O', 'O', 'B-PERSON', 'O', 'B-ORDINAL', 'O', 'O', 'B-GPE', 'I-GPE', 'O', 'O', 'B-GPE', 'I-GPE', 'I-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['I', 'urge', 'Mr.', 'Dodo', 'to', 'lift', 'the', 'siege', 'of', 'Palestinians', ',', 'to', 'speak', 'to', 'the', 'Palestinians', 'as', 'its', 'neighbors', 'because', 'they', 'are', 'his', 'neighbors', '.']\n",
      "['O', 'O', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['I', 'urge', 'Mr', '.', 'Dodo', 'to', 'lift', 'the', 'siege', 'of', 'Palestinians', ',', 'to', 'speak', 'to', 'the', 'Palestinians', 'as', 'its', 'neighbors', 'because', 'they', 'are', 'his', 'neighbors', '.']\n",
      "['O', 'O', 'O', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in unequal[:10]:\n",
    "    print(\"actual\")\n",
    "    print(df.iloc[i,:].Actual_ners)\n",
    "    print(df.iloc[i,:].Actual_ner_types)\n",
    "    print(\"detected\")\n",
    "    print(df.iloc[i,:].Detected_ners)\n",
    "    print(df.iloc[i,:].Detected_ner_types)\n",
    "    print(\"-----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "funny-young",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_ner = []\n",
    "actual_type = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    actual_ner_temp = []\n",
    "    actual_type_temp = []\n",
    "    flag = 0\n",
    "    for j,d in enumerate(df.iloc[i,:].Actual_ners):\n",
    "        if (j < (len(df.iloc[i,:].Actual_ners) - 1) and d == \"'\"):\n",
    "            actual_ner_temp.append(\"'\" + df.iloc[i,:].Actual_ners[j+1])\n",
    "            actual_type_temp.append(df.iloc[i,:].Actual_ner_types[j+1])\n",
    "            flag = 1\n",
    "        elif flag == 1:\n",
    "            flag = 0\n",
    "            continue\n",
    "        else:\n",
    "            actual_ner_temp.append(d)\n",
    "            actual_type_temp.append(df.iloc[i,:].Actual_ner_types[j])\n",
    "    actual_ner.append(actual_ner_temp)\n",
    "    actual_type.append(actual_type_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "expected-glossary",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Actual_ners = actual_ner\n",
    "df.Actual_ner_types = actual_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "statistical-space",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "enormous-compression",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "potential-designation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual\n",
      "['Former', 'U.S.', 'representative', 'Dodo', 'Dodo', 'has', 'died', '.']\n",
      "['O', 'B-GPE', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O']\n",
      "detected\n",
      "['Former', 'U.S', '.', 'representative', 'Dodo', 'Dodo', 'has', 'died', '.']\n",
      "['O', 'B-GPE', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Dodo', 'Dodo', 'was', 'first', 'elected', 'to', 'the', 'U.S.', 'house', 'in', '1948', ',', 'when', 'Dodo', 'Dodo', 'was', 'President', 'and', 'for', 'more', 'than', '4', 'decades', 'he', 'trounced', 'every', 'challenger', 'to', 'face', 'him', 'in', 'congressional', 'election', '.']\n",
      "['B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'O', 'O', 'B-DATE', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'B-DATE', 'I-DATE', 'I-DATE', 'I-DATE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['Dodo', 'Dodo', 'was', 'first', 'elected', 'to', 'the', 'U.S', '.', 'house', 'in', '1948', ',', 'when', 'Dodo', 'Dodo', 'was', 'President', 'and', 'for', 'more', 'than', '4', 'decades', 'he', 'trounced', 'every', 'challenger', 'to', 'face', 'him', 'in', 'congressional', 'election', '.']\n",
      "['B-PERSON', 'I-PERSON', 'O', 'B-ORDINAL', 'O', 'O', 'O', 'B-GPE', 'O', 'O', 'O', 'B-DATE', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'B-DATE', 'I-DATE', 'I-DATE', 'I-DATE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Well', ',', 'Mr.', 'Dodo', 'has', 'been', ',', 'as', 'you', 'say', ',', 'a', 'voice', 'of', 'moderation', '.']\n",
      "['O', 'O', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['Well', ',', 'Mr', '.', 'Dodo', 'has', 'been', ',', 'as', 'you', 'say', ',', 'a', 'voice', 'of', 'moderation', '.']\n",
      "['O', 'O', 'O', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['While', 'all', 'this', 'is', 'going', 'on', ',', 'Mr.', 'Dodo', 'is', 'overseas', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'O', 'O']\n",
      "detected\n",
      "['While', 'all', 'this', 'is', 'going', 'on', ',', 'Mr', '.', 'Dodo', 'is', 'overseas', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['This', 'is', 'Mr.', 'Dodo', \"'s\", 'third', 'visit', 'to', 'Northern', 'Ireland', ',', 'and', 'the', 'Irish', 'Republic', 'to', 'do', 'what', 'he', 'can', 'to', 'generate', 'a', 'lasting', 'peace', '.']\n",
      "['O', 'O', 'O', 'B-PERSON', 'O', 'B-ORDINAL', 'O', 'O', 'B-GPE', 'I-GPE', 'O', 'O', 'B-GPE', 'I-GPE', 'I-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['This', 'is', 'Mr', '.', 'Dodo', \"'s\", 'third', 'visit', 'to', 'Northern', 'Ireland', ',', 'and', 'the', 'Irish', 'Republic', 'to', 'do', 'what', 'he', 'can', 'to', 'generate', 'a', 'lasting', 'peace', '.']\n",
      "['O', 'O', 'O', 'O', 'B-PERSON', 'O', 'B-ORDINAL', 'O', 'O', 'B-GPE', 'I-GPE', 'O', 'O', 'B-GPE', 'I-GPE', 'I-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['I', 'urge', 'Mr.', 'Dodo', 'to', 'lift', 'the', 'siege', 'of', 'Palestinians', ',', 'to', 'speak', 'to', 'the', 'Palestinians', 'as', 'its', 'neighbors', 'because', 'they', 'are', 'his', 'neighbors', '.']\n",
      "['O', 'O', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['I', 'urge', 'Mr', '.', 'Dodo', 'to', 'lift', 'the', 'siege', 'of', 'Palestinians', ',', 'to', 'speak', 'to', 'the', 'Palestinians', 'as', 'its', 'neighbors', 'because', 'they', 'are', 'his', 'neighbors', '.']\n",
      "['O', 'O', 'O', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['The', 'next', 'morning', ',', 'August', '1998', ',', 'the', 'FBI', 'sent', 'out', 'a', 'classified', 'message', ',', 'under', 'Director', 'Dodo', 'Dodo', \"'s\", 'name', ',', 'warning', 'of', 'a', 'plot', 'to', 'attack', 'a', 'U.S.', 'Navy', 'ship', 'in', 'Yemen', '.']\n",
      "['B-TIME', 'I-TIME', 'I-TIME', 'O', 'B-DATE', 'I-DATE', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'B-GPE', 'O']\n",
      "detected\n",
      "['The', 'next', 'morning', ',', 'August', '1998', ',', 'the', 'FBI', 'sent', 'out', 'a', 'classified', 'message', ',', 'under', 'Director', 'Dodo', 'Dodo', \"'s\", 'name', ',', 'warning', 'of', 'a', 'plot', 'to', 'attack', 'a', 'U.S', '.', 'Navy', 'ship', 'in', 'Yemen', '.']\n",
      "['B-TIME', 'I-TIME', 'I-TIME', 'O', 'B-DATE', 'I-DATE', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'O', 'B-ORG', 'O', 'O', 'B-GPE', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Everybody', 'keeping', 'a', 'sharp', 'eye', 'on', 'these', 'recount', 'tallies', 'and', 'on', 'Sunday', \"'s\", 'deadline', 'at', '5:00', 'p.m.', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE', 'O', 'O', 'O', 'B-TIME', 'I-TIME', 'O']\n",
      "detected\n",
      "['Everybody', 'keeping', 'a', 'sharp', 'eye', 'on', 'these', 'recount', 'tallies', 'and', 'on', 'Sunday', \"'s\", 'deadline', 'at', '5:00', 'p.m', '.', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE', 'O', 'O', 'O', 'B-TIME', 'I-TIME', 'I-TIME', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Mr.', 'Dodo', 'promised', 'the', 'gathering', 'at', 'the', 'Norfolk', 'Naval', 'station', 'Wednesday', 'that', 'those', 'who', 'carried', 'out', 'the', 'deadly', 'attack', 'that', 'killed', '17', 'sailors', 'will', 'be', 'found', '.']\n",
      "['O', 'B-PERSON', 'O', 'O', 'O', 'O', 'B-FAC', 'I-FAC', 'I-FAC', 'I-FAC', 'B-DATE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-CARDINAL', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['Mr', '.', 'Dodo', 'promised', 'the', 'gathering', 'at', 'the', 'Norfolk', 'Naval', 'station', 'Wednesday', 'that', 'those', 'who', 'carried', 'out', 'the', 'deadly', 'attack', 'that', 'killed', '17', 'sailors', 'will', 'be', 'found', '.']\n",
      "['O', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'B-FAC', 'I-FAC', 'I-FAC', 'O', 'B-DATE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-CARDINAL', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Mr.', 'Dodo', 'also', 'has', 'said', 'that', 'a', 'lack', 'of', 'democracy', 'is', 'the', 'root', 'cause', 'of', 'many', 'contemporary', 'armed', 'conflicts', '.']\n",
      "['O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['Mr', '.', 'Dodo', 'also', 'has', 'said', 'that', 'a', 'lack', 'of', 'democracy', 'is', 'the', 'root', 'cause', 'of', 'many', 'contemporary', 'armed', 'conflicts', '.']\n",
      "['O', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in unequal[:10]:\n",
    "    print(\"actual\")\n",
    "    print(df.iloc[i,:].Actual_ners)\n",
    "    print(df.iloc[i,:].Actual_ner_types)\n",
    "    print(\"detected\")\n",
    "    print(df.iloc[i,:].Detected_ners)\n",
    "    print(df.iloc[i,:].Detected_ner_types)\n",
    "    print(\"-----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "baking-receipt",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_ner = []\n",
    "detect_type = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    detect_ner_temp = []\n",
    "    detect_type_temp = []\n",
    "    flag = 0\n",
    "    for j,d in enumerate(df.iloc[i,:].Detected_ners):\n",
    "        if (j < (len(df.iloc[i,:].Detected_ners) - 2)) and df.iloc[i,:].Detected_ners[j+1] == \".\":\n",
    "            detect_ner_temp.append(d + \".\")\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j])\n",
    "            flag = 1\n",
    "        elif d == \".\" and flag == 1:\n",
    "            flag = 0\n",
    "            continue\n",
    "        else:\n",
    "            detect_ner_temp.append(d)\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j])\n",
    "    detect_ner.append(detect_ner_temp)\n",
    "    detect_type.append(detect_type_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "boxed-colleague",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Detected_ners = detect_ner\n",
    "df.Detected_ner_types = detect_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "weird-adelaide",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "forward-latitude",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "challenging-happening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual\n",
      "['Good', 'to', 'be', '-LRB-', 'bleep', '-RRB-', 'King', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['Good', 'to', 'be', '-', 'LRB', '-', 'bleep', '-', 'RRB', '-', 'King', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in unequal:\n",
    "    print(\"actual\")\n",
    "    print(df.iloc[i,:].Actual_ners)\n",
    "    print(df.iloc[i,:].Actual_ner_types)\n",
    "    print(\"detected\")\n",
    "    print(df.iloc[i,:].Detected_ners)\n",
    "    print(df.iloc[i,:].Detected_ner_types)\n",
    "    print(\"-----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "communist-premises",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in unequal:\n",
    "    df.iloc[i,:].Detected_ners = df.iloc[i,:].Actual_ners\n",
    "    df.iloc[i,:].Detected_ner_types = df.iloc[i,:].Actual_ner_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "social-correspondence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ramybal/Desktop/untitled folder/neuroner/detect_onto_bn_ner_perturb1_perturb1.csv\n",
      "accuracy score\n",
      "0.9727092149581138\n",
      "0.8762080073630925\n"
     ]
    }
   ],
   "source": [
    "print(f)\n",
    "print(\"accuracy score\")\n",
    "print(accuracy_score(df.Actual_ner_types.tolist(),df.Detected_ner_types.tolist()))\n",
    "print(f1_score(df.Actual_ner_types.tolist(),df.Detected_ner_types.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "removable-yorkshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = flist[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "hispanic-blogger",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "illegal-impact",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Detected_sentence</th>\n",
       "      <th>Actual_ners</th>\n",
       "      <th>Detected_ners</th>\n",
       "      <th>Actual_ner_types</th>\n",
       "      <th>Detected_ner_types</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['basically , it was unanimously agreed upon b...</td>\n",
       "      <td>['basically', ',', 'it', 'was', 'unanimously',...</td>\n",
       "      <td>['basically', ',', 'it', 'was', 'unanimously',...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['To express its determination , the Chinese s...</td>\n",
       "      <td>['To', 'express', 'its', 'determination', ',',...</td>\n",
       "      <td>['To', 'express', 'its', 'determination', ',',...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'O', ...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'O', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['It takes time to prove whether the stock ref...</td>\n",
       "      <td>['It', 'takes', 'time', 'to', 'prove', 'whethe...</td>\n",
       "      <td>['It', 'takes', 'time', 'to', 'prove', 'whethe...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['Dear viewers , the China News program will e...</td>\n",
       "      <td>['Dear', 'viewers', ',', 'the', 'China', 'News...</td>\n",
       "      <td>['Dear', 'viewers', ',', 'the', 'China', 'News...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['This is Dodo Dodo .']</td>\n",
       "      <td>['This', 'is', 'Dodo', 'Dodo', '.']</td>\n",
       "      <td>['This', 'is', 'Dodo', 'Dodo', '.']</td>\n",
       "      <td>['O', 'O', 'B-PERSON', 'I-PERSON', 'O']</td>\n",
       "      <td>['O', 'O', 'B-WORK_OF_ART', 'I-WORK_OF_ART', 'O']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Detected_sentence  \\\n",
       "0  ['basically , it was unanimously agreed upon b...   \n",
       "1  ['To express its determination , the Chinese s...   \n",
       "2  ['It takes time to prove whether the stock ref...   \n",
       "3  ['Dear viewers , the China News program will e...   \n",
       "4                            ['This is Dodo Dodo .']   \n",
       "\n",
       "                                         Actual_ners  \\\n",
       "0  ['basically', ',', 'it', 'was', 'unanimously',...   \n",
       "1  ['To', 'express', 'its', 'determination', ',',...   \n",
       "2  ['It', 'takes', 'time', 'to', 'prove', 'whethe...   \n",
       "3  ['Dear', 'viewers', ',', 'the', 'China', 'News...   \n",
       "4                ['This', 'is', 'Dodo', 'Dodo', '.']   \n",
       "\n",
       "                                       Detected_ners  \\\n",
       "0  ['basically', ',', 'it', 'was', 'unanimously',...   \n",
       "1  ['To', 'express', 'its', 'determination', ',',...   \n",
       "2  ['It', 'takes', 'time', 'to', 'prove', 'whethe...   \n",
       "3  ['Dear', 'viewers', ',', 'the', 'China', 'News...   \n",
       "4                ['This', 'is', 'Dodo', 'Dodo', '.']   \n",
       "\n",
       "                                    Actual_ner_types  \\\n",
       "0  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...   \n",
       "1  ['O', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'O', ...   \n",
       "2  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...   \n",
       "3  ['O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O...   \n",
       "4            ['O', 'O', 'B-PERSON', 'I-PERSON', 'O']   \n",
       "\n",
       "                                  Detected_ner_types  \n",
       "0  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n",
       "1  ['O', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'O', ...  \n",
       "2  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n",
       "3  ['O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O...  \n",
       "4  ['O', 'O', 'B-WORK_OF_ART', 'I-WORK_OF_ART', 'O']  "
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "challenging-affiliation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f)\n",
    "df[['Detected_ners']] = df[['Detected_ners']].applymap(yaml.safe_load) \n",
    "df[['Detected_ner_types']] = df[['Detected_ner_types']].applymap(yaml.safe_load) \n",
    "df[['Actual_ners']] = df[['Actual_ners']].applymap(yaml.safe_load) \n",
    "df[['Actual_ner_types']] = df[['Actual_ner_types']].applymap(yaml.safe_load)\n",
    "  \n",
    "\n",
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "composed-consultation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1305"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "jewish-hygiene",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ramybal/Desktop/untitled folder/neuroner/detect_onto_bc_ner_perturb1_perturb1.csv'"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "handled-struggle",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_ner = []\n",
    "detect_type = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    detect_ner_temp = []\n",
    "    detect_type_temp = []\n",
    "    flag = 0\n",
    "    for j,d in enumerate(df.iloc[i,:].Detected_ners):\n",
    "        if (j < (len(df.iloc[i,:].Detected_ners) - 1) and d == \"'\"):\n",
    "            detect_ner_temp.append(\"'\" + df.iloc[i,:].Detected_ners[j+1])\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j])\n",
    "            flag = 1\n",
    "        elif flag == 1:\n",
    "            flag = 0\n",
    "            continue\n",
    "        else:\n",
    "            detect_ner_temp.append(d)\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j])\n",
    "    detect_ner.append(detect_ner_temp)\n",
    "    detect_type.append(detect_type_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "intermediate-thought",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Detected_ners = detect_ner\n",
    "df.Detected_ner_types = detect_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "quarterly-adventure",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "altered-patient",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1276"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "associate-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_ner = []\n",
    "detect_type = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    detect_ner_temp = []\n",
    "    detect_type_temp = []\n",
    "    flag = 0\n",
    "    for j,d in enumerate(df.iloc[i,:].Detected_ners):\n",
    "        if (j < (len(df.iloc[i,:].Detected_ners) - 2)) and df.iloc[i,:].Detected_ners[j+1] == \".\":\n",
    "            detect_ner_temp.append(d + \".\")\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j])\n",
    "            flag = 1\n",
    "        elif d == \".\" and flag == 1:\n",
    "            flag = 0\n",
    "            continue\n",
    "        else:\n",
    "            detect_ner_temp.append(d)\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j])\n",
    "    detect_ner.append(detect_ner_temp)\n",
    "    detect_type.append(detect_type_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "civilian-documentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Detected_ners = detect_ner\n",
    "df.Detected_ner_types = detect_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "departmental-library",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "fixed-cannon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1273"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "valued-blade",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_ner = []\n",
    "actual_type = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    actual_ner_temp = []\n",
    "    actual_type_temp = []\n",
    "    flag = 0\n",
    "    for j,d in enumerate(df.iloc[i,:].Actual_ners):\n",
    "        if (j < (len(df.iloc[i,:].Actual_ners) - 1) and d == \"'\"):\n",
    "            actual_ner_temp.append(\"'\" + df.iloc[i,:].Actual_ners[j+1])\n",
    "            actual_type_temp.append(df.iloc[i,:].Actual_ner_types[j+1])\n",
    "            flag = 1\n",
    "        elif flag == 1:\n",
    "            flag = 0\n",
    "            continue\n",
    "        else:\n",
    "            actual_ner_temp.append(d)\n",
    "            actual_type_temp.append(df.iloc[i,:].Actual_ner_types[j])\n",
    "    actual_ner.append(actual_ner_temp)\n",
    "    actual_type.append(actual_type_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "deadly-input",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Actual_ners = actual_ner\n",
    "df.Actual_ner_types = actual_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "approved-roommate",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "annual-premiere",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1267"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "removed-racing",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_ner = []\n",
    "actual_type = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    actual_ner_temp = []\n",
    "    actual_type_temp = []\n",
    "    flag = 0\n",
    "    for j,d in enumerate(df.iloc[i,:].Actual_ners):\n",
    "        if (j < (len(df.iloc[i,:].Actual_ners) - 2)) and df.iloc[i,:].Actual_ners[j+1] == \".\":\n",
    "            actual_ner_temp.append(d + \".\")\n",
    "            actual_type_temp.append(df.iloc[i,:].Actual_ner_types[j])\n",
    "            flag = 1\n",
    "        elif d == \".\" and flag == 1:\n",
    "            flag = 0\n",
    "            continue\n",
    "        else:\n",
    "            actual_ner_temp.append(d)\n",
    "            actual_type_temp.append(df.iloc[i,:].Actual_ner_types[j])\n",
    "    actual_ner.append(actual_ner_temp)\n",
    "    actual_type.append(actual_type_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "apart-promotion",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Actual_ners = actual_ner\n",
    "df.Actual_ner_types = actual_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "third-father",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "right-spine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1266"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "desirable-might",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual\n",
      "['Dealing', 'with', 'serial', 'crimes', 'per', 'se', '/.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['Dealing', 'with', 'serial', 'crimes', 'per', 'se', '/', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['We', 'can', 'see', 'the', 'emerging', 'behavior', '/.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['We', 'can', 'see', 'the', 'emerging', 'behavior', '/', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['we', 'can', 'see', 'that', 'this', 'is', 'a', 'behavior', 'that', 'is', 'not', 'going', 'to', 'stop', '/.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['we', 'can', 'see', 'that', 'this', 'is', 'a', 'behavior', 'that', 'is', 'not', 'going', 'to', 'stop', '/', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['You', 'can', 'have', 'hundreds', 'of', 'individuals', 'as', 'suspects', 'and', 'can', 'narrow', 'the', 'focus', 'of', 'your', 'investigation', 'to', 'a', 'smaller', 'pool', 'of', 'people', '/.']\n",
      "['O', 'O', 'O', 'B-CARDINAL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['You', 'can', 'have', 'hundreds', 'of', 'individuals', 'as', 'suspects', 'and', 'can', 'narrow', 'the', 'focus', 'of', 'your', 'investigation', 'to', 'a', 'smaller', 'pool', 'of', 'people', '/', '.']\n",
      "['O', 'O', 'O', 'B-CARDINAL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['And', 'it', 'gives', 'you', 'a', 'starting', 'point', '/.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['And', 'it', 'gives', 'you', 'a', 'starting', 'point', '/', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['The', 'good', 'news', 'is', 'even', 'though', 'at', 'any', 'given', 'point', 'in', 'time', 'that', 'there', 'are', 'these', 'people', 'out', 'there', 'perpetrating', 'these', 'crimes', 'we', 'are', 'getting', 'better', 'at', 'catching', 'them', 'and', 'better', 'at', 'catching', 'them', 'sooner', 'So', 'that', 'instead', 'of', 'waiting', 'until', 'they', \"'ve\", 'committed', 'twelve', 'crimes', 'or', 'instead', 'of', 'having', 'twelve', 'murders', 'take', 'place', 'before', 'we', 'catch', 'somebody', 'now', 'we', 'may', 'catch', 'them', 'after', 'the', 'first', 'or', 'second', 'murder', '/.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-CARDINAL', 'O', 'O', 'O', 'O', 'O', 'B-CARDINAL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORDINAL', 'O', 'B-ORDINAL', 'O', 'O']\n",
      "detected\n",
      "['The', 'good', 'news', 'is', 'even', 'though', 'at', 'any', 'given', 'point', 'in', 'time', 'that', 'there', 'are', 'these', 'people', 'out', 'there', 'perpetrating', 'these', 'crimes', 'we', 'are', 'getting', 'better', 'at', 'catching', 'them', 'and', 'better', 'at', 'catching', 'them', 'sooner', 'So', 'that', 'instead', 'of', 'waiting', 'until', 'they', \"'ve\", 'committed', 'twelve', 'crimes', 'or', 'instead', 'of', 'having', 'twelve', 'murders', 'take', 'place', 'before', 'we', 'catch', 'somebody', 'now', 'we', 'may', 'catch', 'them', 'after', 'the', 'first', 'or', 'second', 'murder', '/', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-CARDINAL', 'O', 'O', 'O', 'O', 'O', 'B-CARDINAL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORDINAL', 'O', 'B-ORDINAL', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['I', 'will', 'never', 'in', 'my', 'lifetime', 'learn', 'why', 'a', 'serial', 'killer', 'becomes', 'a', 'serial', 'killer', '/.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['I', 'will', 'never', 'in', 'my', 'lifetime', 'learn', 'why', 'a', 'serial', 'killer', 'becomes', 'a', 'serial', 'killer', '/', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['But', 'maybe', 'the', 'work', 'that', 'I', \"'m\", 'doing', 'now', 'will', 'be', 'able', 'to', 'take', 'other', 'people', 'down', 'avenues', 'to', 'explore', 'with', 'more', 'tools', 'with', 'more', 'ability', 'to', 'experiment', 'with', 'more', 'ability', 'to', 'study', 'on', 'a', 'hands', '-', 'on', 'basis', '/.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['But', 'maybe', 'the', 'work', 'that', 'I', \"'m\", 'doing', 'now', 'will', 'be', 'able', 'to', 'take', 'other', 'people', 'down', 'avenues', 'to', 'explore', 'with', 'more', 'tools', 'with', 'more', 'ability', 'to', 'experiment', 'with', 'more', 'ability', 'to', 'study', 'on', 'a', 'hands', '-', 'on', 'basis', '/', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['But', 'I', 'will', 'never', 'learn', 'that', '/.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['But', 'I', 'will', 'never', 'learn', 'that', '/', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['As', 'a', 'psychologist', 'through', 'all', 'the', 'interviews', 'that', 'I', \"'ve\", 'conducted', 'all', 'the', 'cases', 'that', 'I', \"'ve\", 'reviewed', 'what', 'I', \"'ve\", 'learned', 'is', 'that', 'these', 'people', 'while', 'bright', 'um', 'and', 'while', 'at', 'some', 'level', 'charming', 'are', 'emotionally', 'and', 'spiritually', 'bankrupt', '/.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['As', 'a', 'psychologist', 'through', 'all', 'the', 'interviews', 'that', 'I', \"'ve\", 'conducted', 'all', 'the', 'cases', 'that', 'I', \"'ve\", 'reviewed', 'what', 'I', \"'ve\", 'learned', 'is', 'that', 'these', 'people', 'while', 'bright', 'um', 'and', 'while', 'at', 'some', 'level', 'charming', 'are', 'emotionally', 'and', 'spiritually', 'bankrupt', '/', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in unequal[:10]:\n",
    "    print(\"actual\")\n",
    "    print(df.iloc[i,:].Actual_ners)\n",
    "    print(df.iloc[i,:].Actual_ner_types)\n",
    "    print(\"detected\")\n",
    "    print(df.iloc[i,:].Detected_ners)\n",
    "    print(df.iloc[i,:].Detected_ner_types)\n",
    "    print(\"-----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "flexible-water",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in unequal:\n",
    "    if df.iloc[i,:].Actual_ners[-1] == \"/.\":\n",
    "        df.iloc[i,:].Detected_ners = df.iloc[i,:].Detected_ners[:-1]\n",
    "        df.iloc[i,:].Detected_ner_types = df.iloc[i,:].Detected_ner_types[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "dangerous-frequency",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "visible-implementation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "assigned-innocent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual\n",
      "['Can', 'this', 'man', 'be', 'stopped', '/?']\n",
      "['O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['Can', 'this', 'man', 'be', 'stopped', '/', '?']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['What', 'is', 'the', 'Dodo', 'administration', 'going', 'to', 'do', 'about', 'it', '/?']\n",
      "['O', 'O', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['What', 'is', 'the', 'Dodo', 'administration', 'going', 'to', 'do', 'about', 'it', '/', '?']\n",
      "['O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Will', 'the', 'United', 'States', 'insist', 'that', 'the', 'United', 'Nations', 'impose', 'sanctions', 'against', 'North', 'Korea', '/?']\n",
      "['O', 'B-GPE', 'I-GPE', 'I-GPE', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'B-GPE', 'I-GPE', 'O']\n",
      "detected\n",
      "['Will', 'the', 'United', 'States', 'insist', 'that', 'the', 'United', 'Nations', 'impose', 'sanctions', 'against', 'North', 'Korea', '/', '?']\n",
      "['O', 'B-GPE', 'I-GPE', 'I-GPE', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'B-GPE', 'I-GPE', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Will', 'the', 'US', 'absolutely', 'insist', 'that', 'there', 'be', 'sanctions', 'in', 'the', 'UN', 'resolution', '/?']\n",
      "['O', 'O', 'B-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O']\n",
      "detected\n",
      "['Will', 'the', 'US', 'absolutely', 'insist', 'that', 'there', 'be', 'sanctions', 'in', 'the', 'UN', 'resolution', '/', '?']\n",
      "['O', 'O', 'B-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Is', 'it', 'the', 'policy', 'of', 'the', 'Dodo', 'administration', 'that', 'we', \"'d\", 'like', 'to', 'see', 'regime', 'change', 'in', 'North', 'Korea', '/?']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'I-GPE', 'O']\n",
      "detected\n",
      "['Is', 'it', 'the', 'policy', 'of', 'the', 'Dodo', 'administration', 'that', 'we', \"'d\", 'like', 'to', 'see', 'regime', 'change', 'in', 'North', 'Korea', '/', '?']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'I-GPE', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Will', 'the', 'United', 'States', 'give', 'North', 'Korea', 'security', 'assurances', 'that', 'we', 'will', 'not', 'attack', 'their', 'country', 'or', 'seek', 'to', 'undermine', 'their', 'regime', '/?']\n",
      "['O', 'B-GPE', 'I-GPE', 'I-GPE', 'O', 'B-GPE', 'I-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['Will', 'the', 'United', 'States', 'give', 'North', 'Korea', 'security', 'assurances', 'that', 'we', 'will', 'not', 'attack', 'their', 'country', 'or', 'seek', 'to', 'undermine', 'their', 'regime', '/', '?']\n",
      "['O', 'B-GPE', 'I-GPE', 'I-GPE', 'O', 'B-GPE', 'I-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['But', 'we', 'would', 'be', 'willing', 'to', 'give', 'North', 'Korea', 'increased', 'economic', 'aid', 'perhaps', 'light', 'nuclear', 'reactors', 'for', 'peaceful', 'means', 'and', 'security', 'assurance', 'if', 'in', 'fact', 'they', 'sat', 'down', 'and', 'negotiated', '/?']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'I-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['But', 'we', 'would', 'be', 'willing', 'to', 'give', 'North', 'Korea', 'increased', 'economic', 'aid', 'perhaps', 'light', 'nuclear', 'reactors', 'for', 'peaceful', 'means', 'and', 'security', 'assurance', 'if', 'in', 'fact', 'they', 'sat', 'down', 'and', 'negotiated', '/', '?']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'I-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Why', 'do', 'you', 'think', 'the', 'North', 'Koreans', 'chose', 'July', 'Fourth', '/?']\n",
      "['O', 'O', 'O', 'O', 'B-NORP', 'I-NORP', 'I-NORP', 'O', 'B-DATE', 'I-DATE', 'O']\n",
      "detected\n",
      "['Why', 'do', 'you', 'think', 'the', 'North', 'Koreans', 'chose', 'July', 'Fourth', '/', '?']\n",
      "['O', 'O', 'O', 'O', 'B-NORP', 'I-NORP', 'I-NORP', 'O', 'B-EVENT', 'I-EVENT', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['The', 'group', \"'s\", 'assessment', 'based', 'on', 'analysis', 'of', 'satellite', 'imagery', 'media', 'reports', 'and', 'statements', 'by', 'North', 'Korean', 'officials', 'which', 'lead', 'Dodo', 'Dodo', 'a', 'conservative', 'critic', 'from', 'the', 'American', 'Enterprise', 'Institute', 'these', 'are', 'not', 'Democrats', '/-']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'I-NORP', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'B-NORP', 'O']\n",
      "detected\n",
      "['The', 'group', \"'s\", 'assessment', 'based', 'on', 'analysis', 'of', 'satellite', 'imagery', 'media', 'reports', 'and', 'statements', 'by', 'North', 'Korean', 'officials', 'which', 'lead', 'Dodo', 'Dodo', 'a', 'conservative', 'critic', 'from', 'the', 'American', 'Enterprise', 'Institute', 'these', 'are', 'not', 'Democrats', '/', '-']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'I-NORP', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'B-NORP', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Would', 'you', 'acknowledge', 'a', 'significant', 'increase', 'in', 'the', 'nuclear', 'capability', 'by', 'North', 'Korea', 'on', 'the', 'watch', 'of', 'President', 'Dodo', '/?']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'I-GPE', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'O']\n",
      "detected\n",
      "['Would', 'you', 'acknowledge', 'a', 'significant', 'increase', 'in', 'the', 'nuclear', 'capability', 'by', 'North', 'Korea', 'on', 'the', 'watch', 'of', 'President', 'Dodo', '/', '?']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'I-GPE', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'O']\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in unequal[:10]:\n",
    "    print(\"actual\")\n",
    "    print(df.iloc[i,:].Actual_ners)\n",
    "    print(df.iloc[i,:].Actual_ner_types)\n",
    "    print(\"detected\")\n",
    "    print(df.iloc[i,:].Detected_ners)\n",
    "    print(df.iloc[i,:].Detected_ner_types)\n",
    "    print(\"-----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "professional-unknown",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in unequal:\n",
    "    if df.iloc[i,:].Actual_ners[-1] == \"/?\":\n",
    "        df.iloc[i,:].Detected_ners = df.iloc[i,:].Detected_ners[:-1]\n",
    "        df.iloc[i,:].Detected_ner_types = df.iloc[i,:].Detected_ner_types[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "interracial-suspension",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "otherwise-ordering",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "widespread-convenience",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual\n",
      "['The', 'group', \"'s\", 'assessment', 'based', 'on', 'analysis', 'of', 'satellite', 'imagery', 'media', 'reports', 'and', 'statements', 'by', 'North', 'Korean', 'officials', 'which', 'lead', 'Dodo', 'Dodo', 'a', 'conservative', 'critic', 'from', 'the', 'American', 'Enterprise', 'Institute', 'these', 'are', 'not', 'Democrats', '/-']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'I-NORP', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'B-NORP', 'O']\n",
      "detected\n",
      "['The', 'group', \"'s\", 'assessment', 'based', 'on', 'analysis', 'of', 'satellite', 'imagery', 'media', 'reports', 'and', 'statements', 'by', 'North', 'Korean', 'officials', 'which', 'lead', 'Dodo', 'Dodo', 'a', 'conservative', 'critic', 'from', 'the', 'American', 'Enterprise', 'Institute', 'these', 'are', 'not', 'Democrats', '/', '-']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'I-NORP', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'B-NORP', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Um', 'the', 'reason', 'for', 'that', '/-']\n",
      "['O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['Um', 'the', 'reason', 'for', 'that', '/', '-']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['but', 'I', 'think', 'it', \"'s\", 'essential', 'to', 'have', 'face', 'to', '*face', 'private', 'bilateral', 'talks', 'between', 'United', 'States', 'and', 'North', 'Korea', '/.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'I-GPE', 'O', 'B-GPE', 'I-GPE', 'O']\n",
      "detected\n",
      "['but', 'I', 'think', 'it', \"'s\", 'essential', 'to', 'have', 'face', 'to', '*', 'face', 'private', 'bilateral', 'talks', 'between', 'United', 'States', 'and', 'North', 'Korea', '/']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'I-GPE', 'O', 'B-GPE', 'I-GPE', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['And', 'what', 'I', 'sense', 'in', 'my', 'negotiations', 'in', 'dealing', 'with', 'North', 'Koreans', '/-']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'I-NORP', 'O']\n",
      "detected\n",
      "['And', 'what', 'I', 'sense', 'in', 'my', 'negotiations', 'in', 'dealing', 'with', 'North', 'Koreans', '/', '-']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'I-NORP', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Among', 'the', 'journalistic', 'revelations,', 'Dodo', 'released', 'from', 'jail', 'last', 'month', 'says', 'she', 'pushed', 'for', 'a', 'story', 'on', 'the', 'outing', 'of', 'Dodo', 'Dodo', 'back', 'in', 'two', 'thousand', 'three', '/.']\n",
      "['O', 'O', 'O', 'O', 'B-PERSON', 'O', 'O', 'O', 'B-DATE', 'I-DATE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'B-DATE', 'I-DATE', 'I-DATE', 'O']\n",
      "detected\n",
      "['Among', 'the', 'journalistic', 'revelations', ',', 'Dodo', 'released', 'from', 'jail', 'last', 'month', 'says', 'she', 'pushed', 'for', 'a', 'story', 'on', 'the', 'outing', 'of', 'Dodo', 'Dodo', 'back', 'in', 'two', 'thousand', 'three', '/']\n",
      "['O', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'O', 'O', 'B-DATE', 'I-DATE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'B-DATE', 'I-DATE', 'I-DATE', 'I-DATE']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Why', 'was', 'that', 'waiver', 'that', 'Dodo', 'was', 'apparently', 'granted', 'by', 'uh', 'Dodo', 'Dodo', 'a', 'year', 'ago', '/-']\n",
      "['O', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'B-DATE', 'I-DATE', 'I-DATE', 'O']\n",
      "detected\n",
      "['Why', 'was', 'that', 'waiver', 'that', 'Dodo', 'was', 'apparently', 'granted', 'by', 'uh', 'Dodo', 'Dodo', 'a', 'year', 'ago', '/', '-']\n",
      "['O', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE', 'I-DATE', 'I-DATE', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Even', 'when', 'she', 'went', 'to', 'jail', 'and', 'w-', '/.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['Even', 'when', 'she', 'went', 'to', 'jail', 'and', 'w', '-', '/']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['You', 'know', 'I', 'do', \"n't\", '/-']\n",
      "['O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['You', 'know', 'I', 'do', \"n't\", '/', '-']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['N-', 'you', 'n-', '/.']\n",
      "['O', 'O', 'O', 'O']\n",
      "detected\n",
      "['N', '-', 'you', 'n', '-', '/']\n",
      "['O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['And', 'we', \"'re\", 'trying', 'to', '/-']\n",
      "['O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['And', 'we', \"'re\", 'trying', 'to', '/', '-']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in unequal[:10]:\n",
    "    print(\"actual\")\n",
    "    print(df.iloc[i,:].Actual_ners)\n",
    "    print(df.iloc[i,:].Actual_ner_types)\n",
    "    print(\"detected\")\n",
    "    print(df.iloc[i,:].Detected_ners)\n",
    "    print(df.iloc[i,:].Detected_ner_types)\n",
    "    print(\"-----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "instrumental-uganda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2,4,6,8\n",
    "for i in [unequal[0],unequal[1],unequal[3],unequal[5],unequal[7],unequal[9]]:    \n",
    "    df.iloc[i,:].Detected_ners = df.iloc[i,:].Detected_ners[:-1]\n",
    "    df.iloc[i,:].Detected_ner_types = df.iloc[i,:].Detected_ner_types[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "controlled-convert",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual\n",
      "['And', 'on', 'that', 'point', 'Dodo', 'on', 'that', 'point', 'she', 'says', 'sh-', '/-']\n",
      "['O', 'O', 'O', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['And', 'on', 'that', 'point', 'Dodo', 'on', 'that', 'point', 'she', 'says', 'sh', '-', '/', '-']\n",
      "['O', 'O', 'O', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['But', 'it', 'uh', 'is', 'very', 'very', 'you', 'know', 'eh', 'irre-', '/-']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['But', 'it', 'uh', 'is', 'very', 'very', 'you', 'know', 'eh', 'irre', '-', '/', '-']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Sir', 'in', 'north', 'central', 'Iraq', 'voter', 'regis-', '/-']\n",
      "['O', 'O', 'O', 'O', 'B-GPE', 'O', 'O', 'O']\n",
      "detected\n",
      "['Sir', 'in', 'north', 'central', 'Iraq', 'voter', 'regis', '-', '/', '-']\n",
      "['O', 'O', 'O', 'O', 'B-GPE', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Why', 'was', \"n't\", '/-']\n",
      "['O', 'O', 'O', 'O']\n",
      "detected\n",
      "['Why', 'was', \"n't\", '/', '-']\n",
      "['O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['And', 'as', 'a', 'reporter', 'as', 'a', 'columnist', 'who', 'really', 'cares', 'about', 'this', 'story', 'I', 'find', 'that', 'really', 'frustra-', '/-']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['And', 'as', 'a', 'reporter', 'as', 'a', 'columnist', 'who', 'really', 'cares', 'about', 'this', 'story', 'I', 'find', 'that', 'really', 'frustra', '-', '/', '-']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Uh', 'but', 'one', 'of', 'the', 'criticisms', '/-']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['Uh', 'but', 'one', 'of', 'the', 'criticisms', '/', '-']\n",
      "['O', 'O', 'B-CARDINAL', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['So', 'um', '/-']\n",
      "['O', 'O', 'O']\n",
      "detected\n",
      "['So', 'um', '/', '-']\n",
      "['O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['And', 'everything', 'was', 'going', 'smoothly', 'until', '/-']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['And', 'everything', 'was', 'going', 'smoothly', 'until', '/', '-']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in unequal[10:]:\n",
    "    print(\"actual\")\n",
    "    print(df.iloc[i,:].Actual_ners)\n",
    "    print(df.iloc[i,:].Actual_ner_types)\n",
    "    print(\"detected\")\n",
    "    print(df.iloc[i,:].Detected_ners)\n",
    "    print(df.iloc[i,:].Detected_ner_types)\n",
    "    print(\"-----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "completed-leonard",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in unequal[10:]:    \n",
    "    df.iloc[i,:].Detected_ners = df.iloc[i,:].Detected_ners[:-1]\n",
    "    df.iloc[i,:].Detected_ner_types = df.iloc[i,:].Detected_ner_types[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "passive-preference",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "fallen-bunch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "tender-hundred",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual\n",
      "['but', 'I', 'think', 'it', \"'s\", 'essential', 'to', 'have', 'face', 'to', '*face', 'private', 'bilateral', 'talks', 'between', 'United', 'States', 'and', 'North', 'Korea', '/.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'I-GPE', 'O', 'B-GPE', 'I-GPE', 'O']\n",
      "detected\n",
      "['but', 'I', 'think', 'it', \"'s\", 'essential', 'to', 'have', 'face', 'to', '*', 'face', 'private', 'bilateral', 'talks', 'between', 'United', 'States', 'and', 'North', 'Korea', '/']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'I-GPE', 'O', 'B-GPE', 'I-GPE', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Among', 'the', 'journalistic', 'revelations,', 'Dodo', 'released', 'from', 'jail', 'last', 'month', 'says', 'she', 'pushed', 'for', 'a', 'story', 'on', 'the', 'outing', 'of', 'Dodo', 'Dodo', 'back', 'in', 'two', 'thousand', 'three', '/.']\n",
      "['O', 'O', 'O', 'O', 'B-PERSON', 'O', 'O', 'O', 'B-DATE', 'I-DATE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'B-DATE', 'I-DATE', 'I-DATE', 'O']\n",
      "detected\n",
      "['Among', 'the', 'journalistic', 'revelations', ',', 'Dodo', 'released', 'from', 'jail', 'last', 'month', 'says', 'she', 'pushed', 'for', 'a', 'story', 'on', 'the', 'outing', 'of', 'Dodo', 'Dodo', 'back', 'in', 'two', 'thousand', 'three', '/']\n",
      "['O', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'O', 'O', 'B-DATE', 'I-DATE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'B-DATE', 'I-DATE', 'I-DATE', 'I-DATE']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Even', 'when', 'she', 'went', 'to', 'jail', 'and', 'w-', '/.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['Even', 'when', 'she', 'went', 'to', 'jail', 'and', 'w', '-', '/']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['N-', 'you', 'n-', '/.']\n",
      "['O', 'O', 'O', 'O']\n",
      "detected\n",
      "['N', '-', 'you', 'n', '-', '/']\n",
      "['O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['And', 'on', 'that', 'point', 'Dodo', 'on', 'that', 'point', 'she', 'says', 'sh-', '/-']\n",
      "['O', 'O', 'O', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['And', 'on', 'that', 'point', 'Dodo', 'on', 'that', 'point', 'she', 'says', 'sh', '-', '/']\n",
      "['O', 'O', 'O', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['But', 'it', 'uh', 'is', 'very', 'very', 'you', 'know', 'eh', 'irre-', '/-']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['But', 'it', 'uh', 'is', 'very', 'very', 'you', 'know', 'eh', 'irre', '-', '/']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Sir', 'in', 'north', 'central', 'Iraq', 'voter', 'regis-', '/-']\n",
      "['O', 'O', 'O', 'O', 'B-GPE', 'O', 'O', 'O']\n",
      "detected\n",
      "['Sir', 'in', 'north', 'central', 'Iraq', 'voter', 'regis', '-', '/']\n",
      "['O', 'O', 'O', 'O', 'B-GPE', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['And', 'as', 'a', 'reporter', 'as', 'a', 'columnist', 'who', 'really', 'cares', 'about', 'this', 'story', 'I', 'find', 'that', 'really', 'frustra-', '/-']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['And', 'as', 'a', 'reporter', 'as', 'a', 'columnist', 'who', 'really', 'cares', 'about', 'this', 'story', 'I', 'find', 'that', 'really', 'frustra', '-', '/']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in unequal:\n",
    "    print(\"actual\")\n",
    "    print(df.iloc[i,:].Actual_ners)\n",
    "    print(df.iloc[i,:].Actual_ner_types)\n",
    "    print(\"detected\")\n",
    "    print(df.iloc[i,:].Detected_ners)\n",
    "    print(df.iloc[i,:].Detected_ner_types)\n",
    "    print(\"-----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "lesser-apollo",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in unequal:\n",
    "    if i != unequal[1]:\n",
    "        df.iloc[i,:].Detected_ners = df.iloc[i,:].Actual_ners\n",
    "        df.iloc[i,:].Detected_ner_types = df.iloc[i,:].Actual_ner_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "treated-carnival",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "threaded-party",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "radical-offering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual\n",
      "['Among', 'the', 'journalistic', 'revelations,', 'Dodo', 'released', 'from', 'jail', 'last', 'month', 'says', 'she', 'pushed', 'for', 'a', 'story', 'on', 'the', 'outing', 'of', 'Dodo', 'Dodo', 'back', 'in', 'two', 'thousand', 'three', '/.']\n",
      "['O', 'O', 'O', 'O', 'B-PERSON', 'O', 'O', 'O', 'B-DATE', 'I-DATE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'B-DATE', 'I-DATE', 'I-DATE', 'O']\n",
      "detected\n",
      "['Among', 'the', 'journalistic', 'revelations', ',', 'Dodo', 'released', 'from', 'jail', 'last', 'month', 'says', 'she', 'pushed', 'for', 'a', 'story', 'on', 'the', 'outing', 'of', 'Dodo', 'Dodo', 'back', 'in', 'two', 'thousand', 'three', '/']\n",
      "['O', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'O', 'O', 'B-DATE', 'I-DATE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'B-DATE', 'I-DATE', 'I-DATE', 'I-DATE']\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in unequal:\n",
    "    print(\"actual\")\n",
    "    print(df.iloc[i,:].Actual_ners)\n",
    "    print(df.iloc[i,:].Actual_ner_types)\n",
    "    print(\"detected\")\n",
    "    print(df.iloc[i,:].Detected_ners)\n",
    "    print(df.iloc[i,:].Detected_ner_types)\n",
    "    print(\"-----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "responsible-saturday",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in unequal: \n",
    "    df.iloc[i,:].Detected_ners = ['Among', 'the', 'journalistic', 'revelations,', 'Dodo', 'released', 'from', 'jail', 'last', 'month', 'says', 'she', 'pushed', 'for', 'a', 'story', 'on', 'the', 'outing', 'of', 'Dodo', 'Dodo', 'back', 'in', 'two', 'thousand', 'three', '/']\n",
    "    df.iloc[i,:].Detected_ner_types = ['O', 'O', 'O', 'O', 'B-PERSON', 'O', 'O', 'O', 'B-DATE', 'I-DATE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'B-DATE', 'I-DATE', 'I-DATE', 'I-DATE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "empty-touch",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "contrary-stress",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "casual-tamil",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ramybal/Desktop/untitled folder/neuroner/detect_onto_bc_ner_perturb1_perturb1.csv\n",
      "accuracy score\n",
      "0.9783017994382542\n",
      "0.8336842105263158\n"
     ]
    }
   ],
   "source": [
    "print(f)\n",
    "print(\"accuracy score\")\n",
    "print(accuracy_score(df.Actual_ner_types.tolist(),df.Detected_ner_types.tolist()))\n",
    "print(f1_score(df.Actual_ner_types.tolist(),df.Detected_ner_types.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "emotional-guitar",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = flist[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "intense-racing",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f)\n",
    "df[['Detected_ners']] = df[['Detected_ners']].applymap(yaml.safe_load) \n",
    "df[['Detected_ner_types']] = df[['Detected_ner_types']].applymap(yaml.safe_load) \n",
    "df[['Actual_ners']] = df[['Actual_ners']].applymap(yaml.safe_load) \n",
    "df[['Actual_ner_types']] = df[['Actual_ner_types']].applymap(yaml.safe_load)\n",
    "  \n",
    "\n",
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "unlike-berlin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ramybal/Desktop/untitled folder/neuroner/detect_onto_wb_ner_perturb1_perturb1.csv'"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "operating-prompt",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "244"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "german-beach",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_ner = []\n",
    "detect_type = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    detect_ner_temp = []\n",
    "    detect_type_temp = []\n",
    "    flag = 0\n",
    "    for j,d in enumerate(df.iloc[i,:].Detected_ners):\n",
    "        if (j < (len(df.iloc[i,:].Detected_ners) - 1) and d == \"'\"):\n",
    "            detect_ner_temp.append(\"'\" + df.iloc[i,:].Detected_ners[j+1])\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j])\n",
    "            flag = 1\n",
    "        elif flag == 1:\n",
    "            flag = 0\n",
    "            continue\n",
    "        else:\n",
    "            detect_ner_temp.append(d)\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j])\n",
    "    detect_ner.append(detect_ner_temp)\n",
    "    detect_type.append(detect_type_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "supreme-teach",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Detected_ners = detect_ner\n",
    "df.Detected_ner_types = detect_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "postal-rocket",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "norman-sleep",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "scientific-concern",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual\n",
      "['The', 'Hebrew', 'channel', ',', 'I', 'meant', 'the', 'Al', '-', 'Arabiya', 'channel', ',', 'did', 'not', 'dare', ',', 'to', 'broadcast', 'this', 'film', 'or', 'even', 'mention', 'it', 'and', 'the', 'reasons', 'are', 'famously', 'unknown', '..']\n",
      "['O', 'B-LANGUAGE', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['The', 'Hebrew', 'channel', ',', 'I', 'meant', 'the', 'Al', '-', 'Arabiya', 'channel', ',', 'did', 'not', 'dare', ',', 'to', 'broadcast', 'this', 'film', 'or', 'even', 'mention', 'it', 'and', 'the', 'reasons', 'are', 'famously', 'unknown', '.', '.']\n",
      "['O', 'B-NORP', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['This', 'is', 'a', 'unique', 'precedent', 'for', 'al', '-', 'Jazeera', '..']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O']\n",
      "detected\n",
      "['This', 'is', 'a', 'unique', 'precedent', 'for', 'al', '-', 'Jazeera', '.', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['There', 'are', 'many', 'questions', ',', 'amongst', 'them', 'the', 'timing', 'of', 'its', 'being', 'shown', 'at', 'this', 'very', 'time', ',', 'following', 'the', 'conflict', 'in', 'interests', 'between', 'the', 'Sons', 'of', 'Monkeys', 'and', 'Pigs', 'and', 'the', 'Sons', 'of', 'Temporary', 'Marriages', '...']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['There', 'are', 'many', 'questions', ',', 'amongst', 'them', 'the', 'timing', 'of', 'its', 'being', 'shown', 'at', 'this', 'very', 'time', ',', 'following', 'the', 'conflict', 'in', 'interests', 'between', 'the', 'Sons', 'of', 'Monkeys', 'and', 'Pigs', 'and', 'the', 'Sons', 'of', 'Temporary', 'Marriages', '.', '.', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['I', 'leave', 'you', 'with', 'the', 'film', 'which', 'saddens', 'the', 'heart', 'and', 'makes', 'it', 'bleed', '....']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['I', 'leave', 'you', 'with', 'the', 'film', 'which', 'saddens', 'the', 'heart', 'and', 'makes', 'it', 'bleed', '.', '.', '.', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['the', 'link', 'to', 'the', 'film', '..']\n",
      "['O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['the', 'link', 'to', 'the', 'film', '.', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['http://z08.zupload.com/download.php?...filepath=48993']\n",
      "['O']\n",
      "detected\n",
      "['http://z08.zupload.com/download.php', '?.', '.', '.', 'filepath=48993']\n",
      "['O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['You', 'are', 'like', 'a', 'Dodo', '-LSB-']\n",
      "['O', 'O', 'O', 'O', 'B-PERSON', 'O']\n",
      "detected\n",
      "['You', 'are', 'like', 'a', 'Dodo', '-', 'LSB', '-']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['As', 'regards', 'some', 'of', 'the', 'faults', 'they', 'are', 'many', '-', 'especially', 'its', 'view', 'of', 'Saudi', 'Arabia', '..']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'I-GPE', 'O']\n",
      "detected\n",
      "['As', 'regards', 'some', 'of', 'the', 'faults', 'they', 'are', 'many', '-', 'especially', 'its', 'view', 'of', 'Saudi', 'Arabia', '.', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'I-GPE', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['As', 'we', 'have', 'said', 'this', 'is', 'a', 'unique', 'precedent', 'for', 'it', '...']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['As', 'we', 'have', 'said', 'this', 'is', 'a', 'unique', 'precedent', 'for', 'it', '.', '.', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['My', 'brother', 'Dodo', 'Dodo', 'Dodo', 'Dodo', '.', 'The', 'truth', 'is', 'that', 'I', 'saw', 'the', 'film', 'and', 'it', 'was', 'really', 'terrifying', 'to', 'the', 'extent', 'that', 'I', 'thought', 'I', 'was', 'watching', 'a', 'fictional', 'film', '...', 'because', 'I', 'could', 'not', 'imagine', 'the', 'extent', 'of', 'the', 'Safavid', 'hatred', 'and', 'criminality', '.']\n",
      "['O', 'O', 'B-PERSON', 'I-PERSON', 'I-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['My', 'brother', 'Dodo', 'Dodo', 'Dodo', 'Dodo', '.', 'The', 'truth', 'is', 'that', 'I', 'saw', 'the', 'film', 'and', 'it', 'was', 'really', 'terrifying', 'to', 'the', 'extent', 'that', 'I', 'thought', 'I', 'was', 'watching', 'a', 'fictional', 'film', '.', '.', '.', 'because', 'I', 'could', 'not', 'imagine', 'the', 'extent', 'of', 'the', 'Safavid', 'hatred', 'and', 'criminality', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in unequal[:10]:\n",
    "    print(\"actual\")\n",
    "    print(df.iloc[i,:].Actual_ners)\n",
    "    print(df.iloc[i,:].Actual_ner_types)\n",
    "    print(\"detected\")\n",
    "    print(df.iloc[i,:].Detected_ners)\n",
    "    print(df.iloc[i,:].Detected_ner_types)\n",
    "    print(\"-----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "realistic-spending",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_ner = []\n",
    "actual_type = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    actual_ner_temp = []\n",
    "    actual_type_temp = []\n",
    "    flag = 0\n",
    "    for j,d in enumerate(df.iloc[i,:].Actual_ners):\n",
    "        if (j < (len(df.iloc[i,:].Actual_ners) - 1) and d == \"'\"):\n",
    "            actual_ner_temp.append(\"'\" + df.iloc[i,:].Actual_ners[j+1])\n",
    "            actual_type_temp.append(df.iloc[i,:].Actual_ner_types[j+1])\n",
    "            flag = 1\n",
    "        elif flag == 1:\n",
    "            flag = 0\n",
    "            continue\n",
    "        else:\n",
    "            actual_ner_temp.append(d)\n",
    "            actual_type_temp.append(df.iloc[i,:].Actual_ner_types[j])\n",
    "    actual_ner.append(actual_ner_temp)\n",
    "    actual_type.append(actual_type_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "coated-tablet",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Actual_ners = actual_ner\n",
    "df.Actual_ner_types = actual_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "environmental-aerospace",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "standing-damages",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "noticed-equation",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_ner = []\n",
    "detect_type = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    detect_ner_temp = []\n",
    "    detect_type_temp = []\n",
    "    flag = 0\n",
    "    for j,d in enumerate(df.iloc[i,:].Detected_ners):\n",
    "        if (j < (len(df.iloc[i,:].Detected_ners) - 2)) and df.iloc[i,:].Detected_ners[j+1] == \".\":\n",
    "            detect_ner_temp.append(d + \".\")\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j])\n",
    "            flag = 1\n",
    "        elif d == \".\" and flag == 1:\n",
    "            flag = 0\n",
    "            continue\n",
    "        else:\n",
    "            detect_ner_temp.append(d)\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j])\n",
    "    detect_ner.append(detect_ner_temp)\n",
    "    detect_type.append(detect_type_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "biblical-standard",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Detected_ners = detect_ner\n",
    "df.Detected_ner_types = detect_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "coral-federal",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "peaceful-humidity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "suspended-knock",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_ner = []\n",
    "actual_type = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    actual_ner_temp = []\n",
    "    actual_type_temp = []\n",
    "    flag = 0\n",
    "    for j,d in enumerate(df.iloc[i,:].Actual_ners):\n",
    "        if (j < (len(df.iloc[i,:].Actual_ners) - 2)) and df.iloc[i,:].Actual_ners[j+1] == \".\":\n",
    "            actual_ner_temp.append(d + \".\")\n",
    "            actual_type_temp.append(df.iloc[i,:].Actual_ner_types[j])\n",
    "            flag = 1\n",
    "        elif d == \".\" and flag == 1:\n",
    "            flag = 0\n",
    "            continue\n",
    "        else:\n",
    "            actual_ner_temp.append(d)\n",
    "            actual_type_temp.append(df.iloc[i,:].Actual_ner_types[j])\n",
    "    actual_ner.append(actual_ner_temp)\n",
    "    actual_type.append(actual_type_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "viral-figure",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Actual_ners = actual_ner\n",
    "df.Actual_ner_types = actual_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "sized-green",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "divine-receipt",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "collective-success",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual\n",
      "['There', 'are', 'many', 'questions', ',', 'amongst', 'them', 'the', 'timing', 'of', 'its', 'being', 'shown', 'at', 'this', 'very', 'time', ',', 'following', 'the', 'conflict', 'in', 'interests', 'between', 'the', 'Sons', 'of', 'Monkeys', 'and', 'Pigs', 'and', 'the', 'Sons', 'of', 'Temporary', 'Marriages', '...']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['There', 'are', 'many', 'questions', ',', 'amongst', 'them', 'the', 'timing', 'of', 'its', 'being', 'shown', 'at', 'this', 'very', 'time', ',', 'following', 'the', 'conflict', 'in', 'interests', 'between', 'the', 'Sons', 'of', 'Monkeys', 'and', 'Pigs', 'and', 'the', 'Sons', 'of', 'Temporary', 'Marriages.', '..', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['I', 'leave', 'you', 'with', 'the', 'film', 'which', 'saddens', 'the', 'heart', 'and', 'makes', 'it', 'bleed', '....']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['I', 'leave', 'you', 'with', 'the', 'film', 'which', 'saddens', 'the', 'heart', 'and', 'makes', 'it', 'bleed.', '..', '..', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['http://z08.zupload.com/download.php?...filepath=48993']\n",
      "['O']\n",
      "detected\n",
      "['http://z08.zupload.com/download.php', '?..', '..', 'filepath=48993']\n",
      "['O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['You', 'are', 'like', 'a', 'Dodo', '-LSB-']\n",
      "['O', 'O', 'O', 'O', 'B-PERSON', 'O']\n",
      "detected\n",
      "['You', 'are', 'like', 'a', 'Dodo', '-', 'LSB', '-']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['As', 'we', 'have', 'said', 'this', 'is', 'a', 'unique', 'precedent', 'for', 'it', '...']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['As', 'we', 'have', 'said', 'this', 'is', 'a', 'unique', 'precedent', 'for', 'it.', '..', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['My', 'brother', 'Dodo', 'Dodo', 'Dodo', 'Dodo.', 'The', 'truth', 'is', 'that', 'I', 'saw', 'the', 'film', 'and', 'it', 'was', 'really', 'terrifying', 'to', 'the', 'extent', 'that', 'I', 'thought', 'I', 'was', 'watching', 'a', 'fictional', 'film', '...', 'because', 'I', 'could', 'not', 'imagine', 'the', 'extent', 'of', 'the', 'Safavid', 'hatred', 'and', 'criminality', '.']\n",
      "['O', 'O', 'B-PERSON', 'I-PERSON', 'I-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['My', 'brother', 'Dodo', 'Dodo', 'Dodo', 'Dodo.', 'The', 'truth', 'is', 'that', 'I', 'saw', 'the', 'film', 'and', 'it', 'was', 'really', 'terrifying', 'to', 'the', 'extent', 'that', 'I', 'thought', 'I', 'was', 'watching', 'a', 'fictional', 'film.', '..', '..', 'because', 'I', 'could', 'not', 'imagine', 'the', 'extent', 'of', 'the', 'Safavid', 'hatred', 'and', 'criminality', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Try', 'again', 'perhaps', 'we', 'can', 'understand', 'what', 'you', 'wrote', '...']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['Try', 'again', 'perhaps', 'we', 'can', 'understand', 'what', 'you', 'wrote.', '..', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['The', 'Al', '-', 'Arabiya', 'started', 'as', 'a', 'rival', 'to', 'Al', '-', 'Jazeera', 'but', 'it', 'failed', 'and', 'the', 'reason', 'is', 'famously', 'unknown', '...', 'you', 'find', 'it', 'in', 'the', 'word', 'Hebrew']\n",
      "['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LANGUAGE']\n",
      "detected\n",
      "['The', 'Al', '-', 'Arabiya', 'started', 'as', 'a', 'rival', 'to', 'Al', '-', 'Jazeera', 'but', 'it', 'failed', 'and', 'the', 'reason', 'is', 'famously', 'unknown.', '..', '..', 'you', 'find', 'it', 'in', 'the', 'word', 'Hebrew']\n",
      "['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['The', 'hot', 'dialogue', '...', 'that', 'went', 'on', 'between', '-LSB-', 'Dodo', 'Dodo', 'and', 'Dodo', '-RSB-', 'at', 'the', 'airport', 'prison', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['The', 'hot', 'dialogue.', '..', '..', 'that', 'went', 'on', 'between', '-', 'LSB', '-', 'Dodo', 'Dodo', 'and', 'Dodo', '-', 'RSB', '-', 'at', 'the', 'airport', 'prison', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Details', 'of', 'the', 'minutes', 'of', 'the', 'meeting', 'between', 'Dodo', 'and', 'Dodo', 'Dodo', 'at', 'the', 'Airport', 'Prison', '...']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'B-PERSON', 'I-PERSON', 'O', 'B-FAC', 'I-FAC', 'I-FAC', 'O']\n",
      "detected\n",
      "['Details', 'of', 'the', 'minutes', 'of', 'the', 'meeting', 'between', 'Dodo', 'and', 'Dodo', 'Dodo', 'at', 'the', 'Airport', 'Prison.', '..', '.']\n",
      "['O', 'O', 'B-TIME', 'I-TIME', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'B-PERSON', 'I-PERSON', 'O', 'B-FAC', 'I-FAC', 'I-FAC', 'O', 'O']\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in unequal[:10]:\n",
    "    print(\"actual\")\n",
    "    print(df.iloc[i,:].Actual_ners)\n",
    "    print(df.iloc[i,:].Actual_ner_types)\n",
    "    print(\"detected\")\n",
    "    print(df.iloc[i,:].Detected_ners)\n",
    "    print(df.iloc[i,:].Detected_ner_types)\n",
    "    print(\"-----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "stupid-asthma",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def multicount_re(searchlist):\n",
    "    temp = []\n",
    "    for i,s in enumerate(searchlist):\n",
    "        if len(re.findall(r'^[.][.]+',s)):\n",
    "            temp.append(i)\n",
    "    return temp\n",
    "\n",
    "detect_ner = []\n",
    "detect_type = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    ref_list = multicount_re(df.iloc[i,:].Detected_ners)\n",
    "    detect_ner_temp = []\n",
    "    detect_type_temp = []\n",
    "    if len(ref_list) > 1:\n",
    "        counter = 0\n",
    "        while (counter<len(df.iloc[i,:].Detected_ners)):\n",
    "            flag = 0\n",
    "            while((counter<len(df.iloc[i,:].Detected_ners) - 1) and counter in ref_list):            \n",
    "                counter += 1\n",
    "                flag += 1\n",
    "            if flag > 0:\n",
    "                detect_ner_temp.append(\"...\")\n",
    "                detect_type_temp.append(\"O\")\n",
    "            while((counter<len(df.iloc[i,:].Detected_ners) - 1) and counter not in ref_list):\n",
    "                detect_ner_temp.append(df.iloc[i,:].Detected_ners[counter])\n",
    "                detect_type_temp.append(df.iloc[i,:].Detected_ner_types[counter])\n",
    "                if (counter<len(df.iloc[i,:].Detected_ners) - 1):\n",
    "                    counter += 1\n",
    "            if counter == (len(df.iloc[i,:].Detected_ners) - 1):\n",
    "                detect_ner_temp.append(df.iloc[i,:].Detected_ners[counter])\n",
    "                detect_type_temp.append(df.iloc[i,:].Detected_ner_types[counter])\n",
    "                detect_ner.append(detect_ner_temp)\n",
    "                detect_type.append(detect_type_temp)\n",
    "                break\n",
    "    else:\n",
    "        detect_ner.append(df.iloc[i,:].Detected_ners)\n",
    "        detect_type.append(df.iloc[i,:].Detected_ner_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "usual-backup",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Detected_ners = detect_ner\n",
    "df.Detected_ner_types = detect_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "funny-possibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "informative-headline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "processed-immunology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual\n",
      "['There', 'are', 'many', 'questions', ',', 'amongst', 'them', 'the', 'timing', 'of', 'its', 'being', 'shown', 'at', 'this', 'very', 'time', ',', 'following', 'the', 'conflict', 'in', 'interests', 'between', 'the', 'Sons', 'of', 'Monkeys', 'and', 'Pigs', 'and', 'the', 'Sons', 'of', 'Temporary', 'Marriages', '...']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['There', 'are', 'many', 'questions', ',', 'amongst', 'them', 'the', 'timing', 'of', 'its', 'being', 'shown', 'at', 'this', 'very', 'time', ',', 'following', 'the', 'conflict', 'in', 'interests', 'between', 'the', 'Sons', 'of', 'Monkeys', 'and', 'Pigs', 'and', 'the', 'Sons', 'of', 'Temporary', 'Marriages.', '..', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['I', 'leave', 'you', 'with', 'the', 'film', 'which', 'saddens', 'the', 'heart', 'and', 'makes', 'it', 'bleed', '....']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['I', 'leave', 'you', 'with', 'the', 'film', 'which', 'saddens', 'the', 'heart', 'and', 'makes', 'it', 'bleed.', '...', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['http://z08.zupload.com/download.php?...filepath=48993']\n",
      "['O']\n",
      "detected\n",
      "['http://z08.zupload.com/download.php', '?..', '..', 'filepath=48993']\n",
      "['O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['You', 'are', 'like', 'a', 'Dodo', '-LSB-']\n",
      "['O', 'O', 'O', 'O', 'B-PERSON', 'O']\n",
      "detected\n",
      "['You', 'are', 'like', 'a', 'Dodo', '-', 'LSB', '-']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['As', 'we', 'have', 'said', 'this', 'is', 'a', 'unique', 'precedent', 'for', 'it', '...']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['As', 'we', 'have', 'said', 'this', 'is', 'a', 'unique', 'precedent', 'for', 'it.', '..', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Try', 'again', 'perhaps', 'we', 'can', 'understand', 'what', 'you', 'wrote', '...']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['Try', 'again', 'perhaps', 'we', 'can', 'understand', 'what', 'you', 'wrote.', '..', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['The', 'hot', 'dialogue', '...', 'that', 'went', 'on', 'between', '-LSB-', 'Dodo', 'Dodo', 'and', 'Dodo', '-RSB-', 'at', 'the', 'airport', 'prison', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['The', 'hot', 'dialogue.', '...', 'that', 'went', 'on', 'between', '-', 'LSB', '-', 'Dodo', 'Dodo', 'and', 'Dodo', '-', 'RSB', '-', 'at', 'the', 'airport', 'prison', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Details', 'of', 'the', 'minutes', 'of', 'the', 'meeting', 'between', 'Dodo', 'and', 'Dodo', 'Dodo', 'at', 'the', 'Airport', 'Prison', '...']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'B-PERSON', 'I-PERSON', 'O', 'B-FAC', 'I-FAC', 'I-FAC', 'O']\n",
      "detected\n",
      "['Details', 'of', 'the', 'minutes', 'of', 'the', 'meeting', 'between', 'Dodo', 'and', 'Dodo', 'Dodo', 'at', 'the', 'Airport', 'Prison.', '..', '.']\n",
      "['O', 'O', 'B-TIME', 'I-TIME', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'B-PERSON', 'I-PERSON', 'O', 'B-FAC', 'I-FAC', 'I-FAC', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Dodo', '-LRB-', 'trying', 'to', 'suppress', 'his', 'anger', '-RRB-', 'What', \"'s\", 'past', 'is', 'past', ',', 'I', 'came', 'especially', 'to', 'make', 'you', 'a', 'clear', 'and', 'specific', 'offer', 'and', 'I', 'want', 'to', 'hear', 'from', 'you', 'a', 'clear', 'and', 'definite', 'answer', '.']\n",
      "['B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['Dodo', '-', 'LRB', '-', 'trying', 'to', 'suppress', 'his', 'anger', '-', 'RRB', '-', 'What', \"'s\", 'past', 'is', 'past', ',', 'I', 'came', 'especially', 'to', 'make', 'you', 'a', 'clear', 'and', 'specific', 'offer', 'and', 'I', 'want', 'to', 'hear', 'from', 'you', 'a', 'clear', 'and', 'definite', 'answer', '.']\n",
      "['B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Dodo', 'Dodo', '-LRB-', 'mockingly', '-RRB-', 'I', 'thought', 'you', 'had', 'come', 'to', 'apologize', 'and', 'restore', 'power', 'to', 'the', 'Iraqis', '.']\n",
      "['B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'O']\n",
      "detected\n",
      "['Dodo', 'Dodo', '-', 'LRB', '-', 'mockingly', '-', 'RRB', '-', 'I', 'thought', 'you', 'had', 'come', 'to', 'apologize', 'and', 'restore', 'power', 'to', 'the', 'Iraqis', '.']\n",
      "['B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'O']\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in unequal[:10]:\n",
    "    print(\"actual\")\n",
    "    print(df.iloc[i,:].Actual_ners)\n",
    "    print(df.iloc[i,:].Actual_ner_types)\n",
    "    print(\"detected\")\n",
    "    print(df.iloc[i,:].Detected_ners)\n",
    "    print(df.iloc[i,:].Detected_ner_types)\n",
    "    print(\"-----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "korean-cancellation",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_ner = []\n",
    "detect_type = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    detect_ner_temp = []\n",
    "    detect_type_temp = []\n",
    "    flag = 0\n",
    "    for j,d in enumerate(df.iloc[i,:].Detected_ners):\n",
    "        if (j < (len(df.iloc[i,:].Detected_ners) - 2) and d == \"-\" and df.iloc[i,:].Detected_ners[j+1] in [\"LRB\",\"RRB\",\"LCB\",\"RCB\",\"LSB\",\"RSB\"]):\n",
    "            detect_ner_temp.append(\"-\" + df.iloc[i,:].Detected_ners[j+1] + \"-\")\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j+1])\n",
    "            flag = 1\n",
    "        elif flag == 1:\n",
    "            flag = 2\n",
    "            continue\n",
    "        elif flag == 2:\n",
    "            flag = 0\n",
    "            continue   \n",
    "        else:\n",
    "            detect_ner_temp.append(d)\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j])\n",
    "    detect_ner.append(detect_ner_temp)\n",
    "    detect_type.append(detect_type_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "cardiovascular-privilege",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Detected_ners = detect_ner\n",
    "df.Detected_ner_types = detect_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "blessed-discussion",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "inner-conservative",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "congressional-bridges",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual\n",
      "['There', 'are', 'many', 'questions', ',', 'amongst', 'them', 'the', 'timing', 'of', 'its', 'being', 'shown', 'at', 'this', 'very', 'time', ',', 'following', 'the', 'conflict', 'in', 'interests', 'between', 'the', 'Sons', 'of', 'Monkeys', 'and', 'Pigs', 'and', 'the', 'Sons', 'of', 'Temporary', 'Marriages', '...']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['There', 'are', 'many', 'questions', ',', 'amongst', 'them', 'the', 'timing', 'of', 'its', 'being', 'shown', 'at', 'this', 'very', 'time', ',', 'following', 'the', 'conflict', 'in', 'interests', 'between', 'the', 'Sons', 'of', 'Monkeys', 'and', 'Pigs', 'and', 'the', 'Sons', 'of', 'Temporary', 'Marriages.', '..', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['I', 'leave', 'you', 'with', 'the', 'film', 'which', 'saddens', 'the', 'heart', 'and', 'makes', 'it', 'bleed', '....']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['I', 'leave', 'you', 'with', 'the', 'film', 'which', 'saddens', 'the', 'heart', 'and', 'makes', 'it', 'bleed.', '...', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['http://z08.zupload.com/download.php?...filepath=48993']\n",
      "['O']\n",
      "detected\n",
      "['http://z08.zupload.com/download.php', '?..', '..', 'filepath=48993']\n",
      "['O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['As', 'we', 'have', 'said', 'this', 'is', 'a', 'unique', 'precedent', 'for', 'it', '...']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['As', 'we', 'have', 'said', 'this', 'is', 'a', 'unique', 'precedent', 'for', 'it.', '..', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Try', 'again', 'perhaps', 'we', 'can', 'understand', 'what', 'you', 'wrote', '...']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['Try', 'again', 'perhaps', 'we', 'can', 'understand', 'what', 'you', 'wrote.', '..', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Details', 'of', 'the', 'minutes', 'of', 'the', 'meeting', 'between', 'Dodo', 'and', 'Dodo', 'Dodo', 'at', 'the', 'Airport', 'Prison', '...']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'B-PERSON', 'I-PERSON', 'O', 'B-FAC', 'I-FAC', 'I-FAC', 'O']\n",
      "detected\n",
      "['Details', 'of', 'the', 'minutes', 'of', 'the', 'meeting', 'between', 'Dodo', 'and', 'Dodo', 'Dodo', 'at', 'the', 'Airport', 'Prison.', '..', '.']\n",
      "['O', 'O', 'B-TIME', 'I-TIME', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'B-PERSON', 'I-PERSON', 'O', 'B-FAC', 'I-FAC', 'I-FAC', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Dodo', ':', 'Stop', 'from', 'this', 'drivel', ',', 'I', 'am', 'offering', 'you', '...']\n",
      "['B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['Dodo', ':', 'Stop', 'from', 'this', 'drivel', ',', 'I', 'am', 'offering', 'you.', '..', '.']\n",
      "['B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['He', 'is', 'really', 'delusional', '...']\n",
      "['O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['He', 'is', 'really', 'delusional.', '..', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['I', 'have', 'reservations', 'about', 'what', 'appeared', 'in', 'these', 'minutes', '...', 'because', 'I', 'think', 'it', 'unlikely', 'that', 'what', 'happened', 'at', 'that', 'meeting', 'would', 'leak', 'out', 'this', 'easily', '...']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['I', 'have', 'reservations', 'about', 'what', 'appeared', 'in', 'these', 'minutes.', '...', 'because', 'I', 'think', 'it', 'unlikely', 'that', 'what', 'happened', 'at', 'that', 'meeting', 'would', 'leak', 'out', 'this', 'easily.', '...', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-TIME', 'I-TIME', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['And', 'I', 'do', 'not', 'believe', 'that', 'Dodo', 'would', 'meet', 'Dodo', 'unless', 'Dodo', 'himself', 'made', 'signs', '...', 'the', 'important', 'thing', 'is', 'that', 'the', 'expression', 'quoted', 'above', 'tells', 'of', 'a', 'reality', 'that', 'can', 'not', 'be', 'but', 'accepted', '...']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'O', 'B-PERSON', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['And', 'I', 'do', 'not', 'believe', 'that', 'Dodo', 'would', 'meet', 'Dodo', 'unless', 'Dodo', 'himself', 'made', 'signs.', '...', 'the', 'important', 'thing', 'is', 'that', 'the', 'expression', 'quoted', 'above', 'tells', 'of', 'a', 'reality', 'that', 'can', 'not', 'be', 'but', 'accepted.', '...', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'O', 'B-PERSON', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in unequal[:10]:\n",
    "    print(\"actual\")\n",
    "    print(df.iloc[i,:].Actual_ners)\n",
    "    print(df.iloc[i,:].Actual_ner_types)\n",
    "    print(\"detected\")\n",
    "    print(df.iloc[i,:].Detected_ners)\n",
    "    print(df.iloc[i,:].Detected_ner_types)\n",
    "    print(\"-----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "preceding-second",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'^.[.]?.$','..Hfda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "aquatic-mexican",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in unequal:\n",
    "    if len(re.findall(r'^.[.]?.$',df.iloc[i,:].Detected_ners[-2])) > 0:\n",
    "        df.iloc[i,:].Detected_ners = df.iloc[i,:].Detected_ners[:-1]\n",
    "        df.iloc[i,:].Detected_ner_types = df.iloc[i,:].Detected_ner_types[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "saved-picture",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "reserved-atlanta",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "narrow-indonesia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual\n",
      "['http://z08.zupload.com/download.php?...filepath=48993']\n",
      "['O']\n",
      "detected\n",
      "['http://z08.zupload.com/download.php', '?..', '..']\n",
      "['O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['It', \"'s\", 'the', 'most', 'disappointingly', '*cheesy*', '1960s', 'sci', '-', 'fi', 'kind', 'of', 'name', 'for', 'an', 'astral', 'entity', 'to', 'use', ',', 'that', \"'s\", 'for', 'sure', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-DATE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['It', \"'s\", 'the', 'most', 'disappointingly', '*', 'cheesy', '*', '1960s', 'sci', '-', 'fi', 'kind', 'of', 'name', 'for', 'an', 'astral', 'entity', 'to', 'use', ',', 'that', \"'s\", 'for', 'sure', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['The', 'way', 'I', 'work', 'it', \"'s\", 'gon', 'na', 'keep', 'you', \"cumin'\"]\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['The', 'way', 'I', 'work', 'it', \"'s\", 'gon', 'na', 'keep', 'you', 'cumin', \"'\"]\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['The', 'sentence', 'I', 'put', 'in', 'boldface', 'is', '*extremely*', 'interesting', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['The', 'sentence', 'I', 'put', 'in', 'boldface', 'is', '*', 'extremely', '*', 'interesting', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['However', ',', 'there', 'is', 'more', 'to', 'this', 'matter', ',', 'the', 'whole', 'world', 'has', 'to', 'share', 'the', 'various', 'negative', 'effects', 'caused', 'by', 'the', 'US', 'excessive', 'energy', 'consumption', ':', 'global', 'warming', ',', 'and', 'wars', 'caused', 'by', 'oil', ',', 'etc.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['However', ',', 'there', 'is', 'more', 'to', 'this', 'matter', ',', 'the', 'whole', 'world', 'has', 'to', 'share', 'the', 'various', 'negative', 'effects', 'caused', 'by', 'the', 'US', 'excessive', 'energy', 'consumption', ':', 'global', 'warming', ',', 'and', 'wars', 'caused', 'by', 'oil', ',', 'etc', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Then', 'I', 'went', 'straight', 'for', 'the', 'physical', ',', 'and', 'I', 'filled', 'out', 'the', 'application', 'form', ',', 'reference', 'list', ',', 'etc.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['Then', 'I', 'went', 'straight', 'for', 'the', 'physical', ',', 'and', 'I', 'filled', 'out', 'the', 'application', 'form', ',', 'reference', 'list', ',', 'etc', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['MSN', ':', 'p...@hotmail.com']\n",
      "['O', 'O', 'O']\n",
      "detected\n",
      "['MSN', ':', 'p', '...']\n",
      "['B-ORG', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['email', ':', 'youyutianshi...@sina.com']\n",
      "['O', 'O', 'O']\n",
      "detected\n",
      "['email', ':', 'youyutianshi.', '...']\n",
      "['O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in unequal:\n",
    "    print(\"actual\")\n",
    "    print(df.iloc[i,:].Actual_ners)\n",
    "    print(df.iloc[i,:].Actual_ner_types)\n",
    "    print(\"detected\")\n",
    "    print(df.iloc[i,:].Detected_ners)\n",
    "    print(df.iloc[i,:].Detected_ner_types)\n",
    "    print(\"-----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "bearing-excellence",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in unequal:\n",
    "    if i != unequal[6]:\n",
    "        df.iloc[i,:].Detected_ners = df.iloc[i,:].Actual_ners\n",
    "        df.iloc[i,:].Detected_ner_types = df.iloc[i,:].Actual_ner_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "irish-relations",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "following-medication",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "arbitrary-guess",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual\n",
      "['MSN', ':', 'p...@hotmail.com']\n",
      "['O', 'O', 'O']\n",
      "detected\n",
      "['MSN', ':', 'p', '...']\n",
      "['B-ORG', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in unequal:\n",
    "    print(\"actual\")\n",
    "    print(df.iloc[i,:].Actual_ners)\n",
    "    print(df.iloc[i,:].Actual_ner_types)\n",
    "    print(\"detected\")\n",
    "    print(df.iloc[i,:].Detected_ners)\n",
    "    print(df.iloc[i,:].Detected_ner_types)\n",
    "    print(\"-----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "celtic-sudan",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = unequal[0]\n",
    "df.iloc[i,:].Detected_ners = ['MSN', ':', 'p']\n",
    "df.iloc[i,:].Detected_ner_types = ['B-ORG', 'O', 'O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "sonic-deployment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ramybal/Desktop/untitled folder/neuroner/detect_onto_wb_ner_perturb1_perturb1.csv\n",
      "accuracy score\n",
      "0.9589107056872291\n",
      "0.7434362045140488\n"
     ]
    }
   ],
   "source": [
    "print(f)\n",
    "print(\"accuracy score\")\n",
    "print(accuracy_score(df.Actual_ner_types.tolist(),df.Detected_ner_types.tolist()))\n",
    "print(f1_score(df.Actual_ner_types.tolist(),df.Detected_ner_types.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "static-istanbul",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = flist[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "great-fraud",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ramybal/Desktop/untitled folder/neuroner/detect_onto_nw_ner_perturb1_perturb1.csv'"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "empty-shell",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f)\n",
    "df[['Detected_ners']] = df[['Detected_ners']].applymap(yaml.safe_load) \n",
    "df[['Detected_ner_types']] = df[['Detected_ner_types']].applymap(yaml.safe_load) \n",
    "df[['Actual_ners']] = df[['Actual_ners']].applymap(yaml.safe_load) \n",
    "df[['Actual_ner_types']] = df[['Actual_ner_types']].applymap(yaml.safe_load)\n",
    "  \n",
    "\n",
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "structured-assignment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "740"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "accomplished-quantum",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_ner = []\n",
    "detect_type = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    detect_ner_temp = []\n",
    "    detect_type_temp = []\n",
    "    flag = 0\n",
    "    for j,d in enumerate(df.iloc[i,:].Detected_ners):\n",
    "        if (j < (len(df.iloc[i,:].Detected_ners) - 1) and d == \"'\"):\n",
    "            detect_ner_temp.append(\"'\" + df.iloc[i,:].Detected_ners[j+1])\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j])\n",
    "            flag = 1\n",
    "        elif flag == 1:\n",
    "            flag = 0\n",
    "            continue\n",
    "        else:\n",
    "            detect_ner_temp.append(d)\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j])\n",
    "    detect_ner.append(detect_ner_temp)\n",
    "    detect_type.append(detect_type_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "genetic-standing",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Detected_ners = detect_ner\n",
    "df.Detected_ner_types = detect_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "dangerous-richmond",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "alone-valuation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "449"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "sharing-botswana",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_ner = []\n",
    "detect_type = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    detect_ner_temp = []\n",
    "    detect_type_temp = []\n",
    "    flag = 0\n",
    "    for j,d in enumerate(df.iloc[i,:].Detected_ners):\n",
    "        if (j < (len(df.iloc[i,:].Detected_ners) - 2)) and df.iloc[i,:].Detected_ners[j+1] == \".\":\n",
    "            detect_ner_temp.append(d + \".\")\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j])\n",
    "            flag = 1\n",
    "        elif d == \".\" and flag == 1:\n",
    "            flag = 0\n",
    "            continue\n",
    "        else:\n",
    "            detect_ner_temp.append(d)\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j])\n",
    "    detect_ner.append(detect_ner_temp)\n",
    "    detect_type.append(detect_type_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "marked-mixture",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Detected_ners = detect_ner\n",
    "df.Detected_ner_types = detect_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "conservative-prerequisite",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "favorite-webcam",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "ignored-compilation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual\n",
      "['Mrs.', 'Dodo', \"'\", 'first', 'trip', 'to', 'Japan', 'as', 'America', \"'s\", 'chief', 'trade', 'negotiator', 'had', 'a', 'completely', 'different', 'tone', 'from', 'last', 'month', \"'s\", 'visit', 'by', 'Commerce', 'Secretary', 'Dodo', 'Dodo', 'Dodo', '.']\n",
      "['O', 'B-PERSON', 'O', 'B-ORDINAL', 'O', 'O', 'B-GPE', 'O', 'B-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE', 'I-DATE', 'I-DATE', 'O', 'O', 'B-ORG', 'O', 'B-PERSON', 'I-PERSON', 'I-PERSON', 'O']\n",
      "detected\n",
      "['Mrs.', 'Dodo', \"'first\", 'trip', 'to', 'Japan', 'as', 'America', \"'s\", 'chief', 'trade', 'negotiator', 'had', 'a', 'completely', 'different', 'tone', 'from', 'last', 'month', \"'s\", 'visit', 'by', 'Commerce', 'Secretary', 'Dodo', 'Dodo', 'Dodo', '.']\n",
      "['O', 'B-PERSON', 'O', 'O', 'O', 'B-GPE', 'O', 'B-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE', 'I-DATE', 'I-DATE', 'O', 'O', 'B-ORG', 'O', 'B-PERSON', 'I-PERSON', 'I-PERSON', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['She', 'added', 'that', 'she', 'expected', '``', 'perhaps', 'to', 'have', 'a', 'down', 'payment', '...', 'some', 'small', 'step', 'to', 'convince', 'the', 'American', 'people', 'and', 'the', 'Japanese', 'people', 'that', 'we', \"'re\", 'moving', 'in', 'earnest', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['She', 'added', 'that', 'she', 'expected', '``', 'perhaps', 'to', 'have', 'a', 'down', 'payment.', '..', '..', 'some', 'small', 'step', 'to', 'convince', 'the', 'American', 'people', 'and', 'the', 'Japanese', 'people', 'that', 'we', \"'re\", 'moving', 'in', 'earnest', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Mrs.', 'Dodo', \"'\", 'remarks', 'did', 'raise', 'questions', ',', 'at', 'least', 'among', 'some', 'U.S.', 'officials', ',', 'about', 'what', 'exactly', 'her', 'stance', 'is', 'on', 'U.S.', 'access', 'to', 'the', 'Japanese', 'semiconductor', 'market', '.']\n",
      "['O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O']\n",
      "detected\n",
      "['Mrs.', 'Dodo', \"'remarks\", 'did', 'raise', 'questions', ',', 'at', 'least', 'among', 'some', 'U.S.', 'officials', ',', 'about', 'what', 'exactly', 'her', 'stance', 'is', 'on', 'U.S.', 'access', 'to', 'the', 'Japanese', 'semiconductor', 'market', '.']\n",
      "['O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['I', 'think', 'the', 'resurgence', '-LCB-', 'in', 'inflation', '-RCB-', 'is', 'going', 'to', 'continue', 'for', 'a', 'few', 'months', ',', 'said', 'Dodo', 'Dodo', ',', 'chief', 'economist', 'at', 'Bell', 'Mueller', 'Cannon', ',', 'a', 'Washington', 'economic', 'forecasting', 'firm', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE', 'I-DATE', 'I-DATE', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'B-GPE', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['I', 'think', 'the', 'resurgence', '-', 'LCB', '-', 'in', 'inflation', '-', 'RCB', '-', 'is', 'going', 'to', 'continue', 'for', 'a', 'few', 'months', ',', 'said', 'Dodo', 'Dodo', ',', 'chief', 'economist', 'at', 'Bell', 'Mueller', 'Cannon', ',', 'a', 'Washington', 'economic', 'forecasting', 'firm', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE', 'I-DATE', 'I-DATE', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'B-GPE', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Here', 'are', 'the', 'Labor', 'Department', \"'s\", 'producer', 'price', 'indexes', '-LRB-', '1982', '=', '100', '-RRB-', 'for', 'September', ',', 'before', 'seasonal', 'adjustment', ',', 'and', 'the', 'percentage', 'changes', 'from', 'September', ',', '1988', '.']\n",
      "['O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'B-DATE', 'O', 'B-CARDINAL', 'O', 'O', 'B-DATE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE', 'O', 'B-DATE', 'O']\n",
      "detected\n",
      "['Here', 'are', 'the', 'Labor', 'Department', \"'s\", 'producer', 'price', 'indexes', '-', 'LRB', '-', '1982', '=', '100', '-', 'RRB', '-', 'for', 'September', ',', 'before', 'seasonal', 'adjustment', ',', 'and', 'the', 'percentage', 'changes', 'from', 'September', ',', '1988', '.']\n",
      "['O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE', 'O', 'B-CARDINAL', 'O', 'O', 'O', 'O', 'B-DATE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE', 'I-DATE', 'I-DATE', 'O']\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in unequal[:5]:\n",
    "    print(\"actual\")\n",
    "    print(df.iloc[i,:].Actual_ners)\n",
    "    print(df.iloc[i,:].Actual_ner_types)\n",
    "    print(\"detected\")\n",
    "    print(df.iloc[i,:].Detected_ners)\n",
    "    print(df.iloc[i,:].Detected_ner_types)\n",
    "    print(\"-----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "handy-sending",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_ner = []\n",
    "detect_type = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    detect_ner_temp = []\n",
    "    detect_type_temp = []\n",
    "    flag = 0\n",
    "    for j,d in enumerate(df.iloc[i,:].Detected_ners):\n",
    "        if (j < (len(df.iloc[i,:].Detected_ners) - 2) and d == \"-\" and df.iloc[i,:].Detected_ners[j+1] in [\"LRB\",\"RRB\",\"LCB\",\"RCB\",\"LSB\",\"RSB\"]):\n",
    "            detect_ner_temp.append(\"-\" + df.iloc[i,:].Detected_ners[j+1] + \"-\")\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j+1])\n",
    "            flag = 1\n",
    "        elif flag == 1:\n",
    "            flag = 2\n",
    "            continue\n",
    "        elif flag == 2:\n",
    "            flag = 0\n",
    "            continue   \n",
    "        else:\n",
    "            detect_ner_temp.append(d)\n",
    "            detect_type_temp.append(df.iloc[i,:].Detected_ner_types[j])\n",
    "    detect_ner.append(detect_ner_temp)\n",
    "    detect_type.append(detect_type_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "fresh-suspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Detected_ners = detect_ner\n",
    "df.Detected_ner_types = detect_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "sharing-patrol",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "challenging-committee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "european-minute",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_ner = []\n",
    "actual_type = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    actual_ner_temp = []\n",
    "    actual_type_temp = []\n",
    "    flag = 0\n",
    "    for j,d in enumerate(df.iloc[i,:].Actual_ners):\n",
    "        if (j < (len(df.iloc[i,:].Actual_ners) - 1) and d == \"'\"):\n",
    "            actual_ner_temp.append(\"'\" + df.iloc[i,:].Actual_ners[j+1])\n",
    "            actual_type_temp.append(df.iloc[i,:].Actual_ner_types[j+1])\n",
    "            flag = 1\n",
    "        elif flag == 1:\n",
    "            flag = 0\n",
    "            continue\n",
    "        else:\n",
    "            actual_ner_temp.append(d)\n",
    "            actual_type_temp.append(df.iloc[i,:].Actual_ner_types[j])\n",
    "    actual_ner.append(actual_ner_temp)\n",
    "    actual_type.append(actual_type_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "textile-trance",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Actual_ners = actual_ner\n",
    "df.Actual_ner_types = actual_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "indie-stopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "lined-attack",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "adult-novel",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_ner = []\n",
    "actual_type = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    actual_ner_temp = []\n",
    "    actual_type_temp = []\n",
    "    flag = 0\n",
    "    for j,d in enumerate(df.iloc[i,:].Actual_ners):\n",
    "        if (j < (len(df.iloc[i,:].Actual_ners) - 2)) and df.iloc[i,:].Actual_ners[j+1] == \".\":\n",
    "            actual_ner_temp.append(d + \".\")\n",
    "            actual_type_temp.append(df.iloc[i,:].Actual_ner_types[j])\n",
    "            flag = 1\n",
    "        elif d == \".\" and flag == 1:\n",
    "            flag = 0\n",
    "            continue\n",
    "        else:\n",
    "            actual_ner_temp.append(d)\n",
    "            actual_type_temp.append(df.iloc[i,:].Actual_ner_types[j])\n",
    "    actual_ner.append(actual_ner_temp)\n",
    "    actual_type.append(actual_type_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "third-ozone",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Actual_ners = actual_ner\n",
    "df.Actual_ner_types = actual_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "recreational-garden",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "accompanied-chocolate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "variable-recovery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual\n",
      "['She', 'added', 'that', 'she', 'expected', '``', 'perhaps', 'to', 'have', 'a', 'down', 'payment', '...', 'some', 'small', 'step', 'to', 'convince', 'the', 'American', 'people', 'and', 'the', 'Japanese', 'people', 'that', 'we', \"'re\", 'moving', 'in', 'earnest', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['She', 'added', 'that', 'she', 'expected', '``', 'perhaps', 'to', 'have', 'a', 'down', 'payment.', '..', '..', 'some', 'small', 'step', 'to', 'convince', 'the', 'American', 'people', 'and', 'the', 'Japanese', 'people', 'that', 'we', \"'re\", 'moving', 'in', 'earnest', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O', 'B-NORP', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['My', 'colleagues', 'and', 'I', 'fully', 'realize', 'we', 'are', 'not', 'a', 'court', '...', 'etc', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['My', 'colleagues', 'and', 'I', 'fully', 'realize', 'we', 'are', 'not', 'a', 'court.', '..', '..', 'etc', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['No', ',', 'to', 'my', 'mind', ',', 'the', 'Journal', 'did', 'not', '``', 'defend', 'sleaze', ',', 'fraud', ',', 'waste', ',', 'embezzlement', ',', 'influence', '-', 'peddling', 'and', 'abuse', 'of', 'the', 'public', 'trust', '...']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['No', ',', 'to', 'my', 'mind', ',', 'the', 'Journal', 'did', 'not', '``', 'defend', 'sleaze', ',', 'fraud', ',', 'waste', ',', 'embezzlement', ',', 'influence', '-', 'peddling', 'and', 'abuse', 'of', 'the', 'public', 'trust.', '..', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Ad', 'Notes', '...']\n",
      "['O', 'O', 'O']\n",
      "detected\n",
      "['Ad', 'Notes.', '..', '.']\n",
      "['O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['Per', 'capita', 'personal', 'income', 'ranged', 'from', '$', '11,116', 'in', 'Mississippi', 'to', '$', '23,059', 'in', 'Connecticut', '...']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MONEY', 'O', 'B-GPE', 'O', 'O', 'B-MONEY', 'O', 'B-GPE', 'O']\n",
      "detected\n",
      "['Per', 'capita', 'personal', 'income', 'ranged', 'from', '$', '11,116', 'in', 'Mississippi', 'to', '$', '23,059', 'in', 'Connecticut.', '..', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MONEY', 'O', 'B-GPE', 'O', 'O', 'B-MONEY', 'O', 'B-GPE', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['There', 'is', 'nothing', 'wrong', 'with', 'the', 'economy', '...', 'all', 'the', 'indices', 'are', 'up', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['There', 'is', 'nothing', 'wrong', 'with', 'the', 'economy.', '..', '..', 'all', 'the', 'indices', 'are', 'up', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['After', 'the', '1929', 'crash', ',', 'Dodo', 'Dodo', 'said', ':', 'The', 'fundamental', 'business', 'of', 'the', 'country', '...', 'is', 'on', 'a', 'sound', 'and', 'prosperous', 'basis', '.']\n",
      "['O', 'O', 'B-DATE', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "detected\n",
      "['After', 'the', '1929', 'crash', ',', 'Dodo', 'Dodo', 'said', ':', 'The', 'fundamental', 'business', 'of', 'the', 'country.', '..', '..', 'is', 'on', 'a', 'sound', 'and', 'prosperous', 'basis', '.']\n",
      "['O', 'O', 'B-DATE', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "-----------------------------------------------------------\n",
      "actual\n",
      "['A', 'month', 'ago', ',', 'Hertz', ',', 'of', 'Park', 'Ridge', ',', 'N.J.', ',', 'said', 'that', 'it', 'would', 'drop', 'its', 'marketing', 'agreements', 'at', 'year', 'end', 'with', 'Delta', ',', 'America', 'West', 'and', 'Texas', 'Air', 'Corp.', \"'s\", 'Continental', 'Airlines', 'and', 'Eastern', 'Airlines', ',', 'and', 'that', 'pacts', 'with', 'American', 'Airlines', ',', 'UAL', 'Inc', \"'s\", 'United', 'Airlines', 'and', 'USAir', 'also', 'would', 'be', 'ended', '...', 'sometime', 'after', 'Dec.', '31', '.']\n",
      "['B-DATE', 'I-DATE', 'I-DATE', 'O', 'B-ORG', 'O', 'O', 'B-GPE', 'I-GPE', 'O', 'B-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE', 'I-DATE', 'O', 'B-ORG', 'O', 'B-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'B-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'B-ORG', 'I-ORG', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE', 'I-DATE', 'O']\n",
      "detected\n",
      "['A', 'month', 'ago', ',', 'Hertz', ',', 'of', 'Park', 'Ridge', ',', 'N.J.', ',', 'said', 'that', 'it', 'would', 'drop', 'its', 'marketing', 'agreements', 'at', 'year', 'end', 'with', 'Delta', ',', 'America', 'West', 'and', 'Texas', 'Air', 'Corp.', \"'s\", 'Continental', 'Airlines', 'and', 'Eastern', 'Airlines', ',', 'and', 'that', 'pacts', 'with', 'American', 'Airlines', ',', 'UAL', 'Inc', \"'s\", 'United', 'Airlines', 'and', 'USAir', 'also', 'would', 'be', 'ended.', '..', '..', 'sometime', 'after', 'Dec.', '31', '.']\n",
      "['B-DATE', 'I-DATE', 'I-DATE', 'O', 'B-ORG', 'O', 'O', 'B-GPE', 'I-GPE', 'O', 'B-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE', 'I-DATE', 'O', 'B-ORG', 'O', 'B-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'B-ORG', 'I-ORG', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE', 'I-DATE', 'O']\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in unequal:\n",
    "    print(\"actual\")\n",
    "    print(df.iloc[i,:].Actual_ners)\n",
    "    print(df.iloc[i,:].Actual_ner_types)\n",
    "    print(\"detected\")\n",
    "    print(df.iloc[i,:].Detected_ners)\n",
    "    print(df.iloc[i,:].Detected_ner_types)\n",
    "    print(\"-----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "built-potter",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in unequal[:-1]:\n",
    "    df.iloc[i,:].Detected_ners = df.iloc[i,:].Actual_ners\n",
    "    df.iloc[i,:].Detected_ner_types = df.iloc[i,:].Actual_ner_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "expanded-craft",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "portable-showcase",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "moving-rabbit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual\n",
      "['A', 'month', 'ago', ',', 'Hertz', ',', 'of', 'Park', 'Ridge', ',', 'N.J.', ',', 'said', 'that', 'it', 'would', 'drop', 'its', 'marketing', 'agreements', 'at', 'year', 'end', 'with', 'Delta', ',', 'America', 'West', 'and', 'Texas', 'Air', 'Corp.', \"'s\", 'Continental', 'Airlines', 'and', 'Eastern', 'Airlines', ',', 'and', 'that', 'pacts', 'with', 'American', 'Airlines', ',', 'UAL', 'Inc', \"'s\", 'United', 'Airlines', 'and', 'USAir', 'also', 'would', 'be', 'ended', '...', 'sometime', 'after', 'Dec.', '31', '.']\n",
      "['B-DATE', 'I-DATE', 'I-DATE', 'O', 'B-ORG', 'O', 'O', 'B-GPE', 'I-GPE', 'O', 'B-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE', 'I-DATE', 'O', 'B-ORG', 'O', 'B-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'B-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'B-ORG', 'I-ORG', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE', 'I-DATE', 'O']\n",
      "detected\n",
      "['A', 'month', 'ago', ',', 'Hertz', ',', 'of', 'Park', 'Ridge', ',', 'N.J.', ',', 'said', 'that', 'it', 'would', 'drop', 'its', 'marketing', 'agreements', 'at', 'year', 'end', 'with', 'Delta', ',', 'America', 'West', 'and', 'Texas', 'Air', 'Corp.', \"'s\", 'Continental', 'Airlines', 'and', 'Eastern', 'Airlines', ',', 'and', 'that', 'pacts', 'with', 'American', 'Airlines', ',', 'UAL', 'Inc', \"'s\", 'United', 'Airlines', 'and', 'USAir', 'also', 'would', 'be', 'ended.', '..', '..', 'sometime', 'after', 'Dec.', '31', '.']\n",
      "['B-DATE', 'I-DATE', 'I-DATE', 'O', 'B-ORG', 'O', 'O', 'B-GPE', 'I-GPE', 'O', 'B-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE', 'I-DATE', 'O', 'B-ORG', 'O', 'B-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'B-ORG', 'I-ORG', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE', 'I-DATE', 'O']\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in unequal:\n",
    "    print(\"actual\")\n",
    "    print(df.iloc[i,:].Actual_ners)\n",
    "    print(df.iloc[i,:].Actual_ner_types)\n",
    "    print(\"detected\")\n",
    "    print(df.iloc[i,:].Detected_ners)\n",
    "    print(df.iloc[i,:].Detected_ner_types)\n",
    "    print(\"-----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "rubber-astrology",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in unequal:\n",
    "   \n",
    "    df.iloc[i,:].Detected_ners = ['A', 'month', 'ago', ',', 'Hertz', ',', 'of', 'Park', 'Ridge', ',', 'N.J.', ',', 'said', 'that', 'it', 'would', 'drop', 'its', 'marketing', 'agreements', 'at', 'year', 'end', 'with', 'Delta', ',', 'America', 'West', 'and', 'Texas', 'Air', 'Corp.', \"'s\", 'Continental', 'Airlines', 'and', 'Eastern', 'Airlines', ',', 'and', 'that', 'pacts', 'with', 'American', 'Airlines', ',', 'UAL', 'Inc', \"'s\", 'United', 'Airlines', 'and', 'USAir', 'also', 'would', 'be', 'ended.', '...', 'sometime', 'after', 'Dec.', '31', '.']\n",
    "    df.iloc[i,:].Detected_ner_types = ['B-DATE', 'I-DATE', 'I-DATE', 'O', 'B-ORG', 'O', 'O', 'B-GPE', 'I-GPE', 'O', 'B-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE', 'I-DATE', 'O', 'B-ORG', 'O', 'B-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'B-ORG', 'I-ORG', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE', 'I-DATE', 'O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "criminal-platform",
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal = []\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df.iloc[i,:].Actual_ner_types) != len(df.iloc[i,:].Detected_ner_types):\n",
    "        unequal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "broad-prayer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "joint-corner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ramybal/Desktop/untitled folder/neuroner/detect_onto_nw_ner_perturb1_perturb1.csv\n",
      "accuracy score\n",
      "0.9737996663165049\n",
      "0.8891021539773939\n"
     ]
    }
   ],
   "source": [
    "print(f)\n",
    "print(\"accuracy score\")\n",
    "print(accuracy_score(df.Actual_ner_types.tolist(),df.Detected_ner_types.tolist()))\n",
    "print(f1_score(df.Actual_ner_types.tolist(),df.Detected_ner_types.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottom-particular",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
