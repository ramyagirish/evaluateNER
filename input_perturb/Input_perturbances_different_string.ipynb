{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "grand-celebrity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Spark NLP\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "import sparknlp\n",
    "\n",
    "# Start Spark Session with Spark NLP\n",
    "# start() functions has two parameters: gpu and spark23\n",
    "# sparknlp.start(gpu=True) will start the session with GPU support\n",
    "# sparknlp.start(spark23=True) is when you have Apache Spark 2.3.x installed\n",
    "spark = sparknlp.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "valued-modification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP version 2.7.3\n",
      "Apache Spark version: 2.4.4\n"
     ]
    }
   ],
   "source": [
    "print(\"Spark NLP version\", sparknlp.version())\n",
    "print(\"Apache Spark version:\", spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "scenic-person",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text files with the input\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"/Users/ramybal/Downloads/bio/spark/test/onto_bc_ner.txt\",delimiter=\"\\t\", quoting=csv.QUOTE_NONE, encoding='utf-8',header=None,names=[\"Word\",\"POS\",\"DEREP\",\"TYPE\",\"SENT_NO\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "enabling-bowling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32488 entries, 0 to 32487\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Word     32488 non-null  object\n",
      " 1   POS      32488 non-null  object\n",
      " 2   DEREP    32488 non-null  object\n",
      " 3   TYPE     32488 non-null  object\n",
      " 4   SENT_NO  32488 non-null  int64 \n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "celtic-horizontal",
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "fake = Faker()\n",
    "\n",
    "words = []\n",
    "for i in range(df.shape[0]):\n",
    "    if df.iloc[i,:].TYPE == 'B-PERSON':\n",
    "        words.append(fake.name().split()[0])\n",
    "    elif df.iloc[i,:].TYPE == 'I-PERSON':\n",
    "        words.append(fake.name().split()[-1])\n",
    "    else:\n",
    "        words.append(df.iloc[i,:].Word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "planned-discharge",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Word = words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "radical-township",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"/Users/ramybal/Downloads/bio/spark/test/onto_bc_ner_perturb3.txt\",sep=\"\\t\",index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "innocent-humidity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pathlib\n",
    "path = pathlib.Path(\"/Users/ramybal/Downloads/bio/spark/test\")\n",
    "flist = [str(f) for f in path.rglob(\"*.txt\") if str(f).endswith(\"_ner.txt\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "extraordinary-blackjack",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/ramybal/Downloads/bio/spark/test/onto_nw_ner.txt',\n",
       " '/Users/ramybal/Downloads/bio/spark/test/onto_bc_ner.txt',\n",
       " '/Users/ramybal/Downloads/bio/spark/test/onto_wb_ner.txt',\n",
       " '/Users/ramybal/Downloads/bio/spark/test/onto_mz_ner.txt',\n",
       " '/Users/ramybal/Downloads/bio/spark/test/onto_pt_ner.txt',\n",
       " '/Users/ramybal/Downloads/bio/spark/test/onto_bn_ner.txt',\n",
       " '/Users/ramybal/Downloads/bio/spark/test/onto_tc_ner.txt']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "prime-crash",
   "metadata": {},
   "outputs": [],
   "source": [
    "flist.remove('/Users/ramybal/Downloads/bio/spark/test/onto_bc_ner.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "combined-worth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/ramybal/Downloads/bio/spark/test/onto_nw_ner.txt',\n",
       " '/Users/ramybal/Downloads/bio/spark/test/onto_wb_ner.txt',\n",
       " '/Users/ramybal/Downloads/bio/spark/test/onto_mz_ner.txt',\n",
       " '/Users/ramybal/Downloads/bio/spark/test/onto_pt_ner.txt',\n",
       " '/Users/ramybal/Downloads/bio/spark/test/onto_bn_ner.txt',\n",
       " '/Users/ramybal/Downloads/bio/spark/test/onto_tc_ner.txt']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "formal-overhead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ramybal/Downloads/bio/spark/test/onto_nw_ner.txt\n",
      "49235\n",
      "49235\n",
      "/Users/ramybal/Downloads/bio/spark/test/onto_wb_ner.txt\n",
      "18945\n",
      "18945\n",
      "/Users/ramybal/Downloads/bio/spark/test/onto_mz_ner.txt\n",
      "17875\n",
      "17875\n",
      "/Users/ramybal/Downloads/bio/spark/test/onto_pt_ner.txt\n",
      "16851\n",
      "16851\n",
      "/Users/ramybal/Downloads/bio/spark/test/onto_bn_ner.txt\n",
      "23209\n",
      "23209\n",
      "/Users/ramybal/Downloads/bio/spark/test/onto_tc_ner.txt\n",
      "10976\n",
      "10976\n"
     ]
    }
   ],
   "source": [
    "for f in flist:\n",
    "    print(f)\n",
    "    df = pd.read_csv(f,delimiter=\"\\t\", quoting=csv.QUOTE_NONE, encoding='utf-8',header=None,names=[\"Word\",\"POS\",\"DEREP\",\"TYPE\",\"SENT_NO\"])\n",
    "    words = []\n",
    "    for i in range(df.shape[0]):\n",
    "        if df.iloc[i,:].TYPE == 'B-PERSON':\n",
    "            words.append(fake.name().split()[0])\n",
    "        elif df.iloc[i,:].TYPE == 'I-PERSON':\n",
    "            words.append(fake.name().split()[-1])\n",
    "        else:\n",
    "            words.append(df.iloc[i,:].Word)\n",
    "    print(len(words))\n",
    "    print(df.shape[0])\n",
    "    df.Word = words\n",
    "    new_filename = f.replace(\".txt\",\"_perturb3.txt\")\n",
    "    df.to_csv(new_filename,sep=\"\\t\",index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "encouraging-hunter",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/ramybal/Downloads/bio/spark/test/onto_bc_ner.txt\",delimiter=\"\\t\", quoting=csv.QUOTE_NONE, encoding='utf-8',header=None,names=[\"Word\",\"POS\",\"DEREP\",\"TYPE\",\"SENT_NO\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "impressive-digit",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for i in range(df.shape[0]):\n",
    "    if df.iloc[i,:].TYPE == 'B-PERSON':\n",
    "        words.append(fake.name().split()[0])\n",
    "    elif df.iloc[i,:].TYPE == 'I-PERSON':\n",
    "        words.append(fake.name().split()[-1])\n",
    "    else:\n",
    "        words.append(df.iloc[i,:].Word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cellular-silicon",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Word = words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "nuclear-mount",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in df.groupby(\"SENT_NO\").groups.items():\n",
    "    temp = df.iloc[v,:]\n",
    "    temp.to_csv(\"/Users/ramybal/Downloads/bio/spark/test/onto_bc_ner_perturb4.txt\",mode='a',sep=\"\\t\",index=False,header=False)\n",
    "    with open(\"/Users/ramybal/Downloads/bio/spark/test/onto_bc_ner_perturb4.txt\",\"a\") as f:\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "graduate-synthetic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/ramybal/Downloads/bio/spark/test/onto_nw_ner.txt',\n",
       " '/Users/ramybal/Downloads/bio/spark/test/onto_wb_ner.txt',\n",
       " '/Users/ramybal/Downloads/bio/spark/test/onto_mz_ner.txt',\n",
       " '/Users/ramybal/Downloads/bio/spark/test/onto_pt_ner.txt',\n",
       " '/Users/ramybal/Downloads/bio/spark/test/onto_bn_ner.txt',\n",
       " '/Users/ramybal/Downloads/bio/spark/test/onto_tc_ner.txt']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "sophisticated-essay",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ramybal/Downloads/bio/spark/test/onto_nw_ner.txt\n",
      "49235\n",
      "49235\n",
      "/Users/ramybal/Downloads/bio/spark/test/onto_wb_ner.txt\n",
      "18945\n",
      "18945\n",
      "/Users/ramybal/Downloads/bio/spark/test/onto_mz_ner.txt\n",
      "17875\n",
      "17875\n",
      "/Users/ramybal/Downloads/bio/spark/test/onto_pt_ner.txt\n",
      "16851\n",
      "16851\n",
      "/Users/ramybal/Downloads/bio/spark/test/onto_bn_ner.txt\n",
      "23209\n",
      "23209\n",
      "/Users/ramybal/Downloads/bio/spark/test/onto_tc_ner.txt\n",
      "10976\n",
      "10976\n"
     ]
    }
   ],
   "source": [
    "for f in flist:\n",
    "    print(f)\n",
    "    df = pd.read_csv(f,delimiter=\"\\t\", quoting=csv.QUOTE_NONE, encoding='utf-8',header=None,names=[\"Word\",\"POS\",\"DEREP\",\"TYPE\",\"SENT_NO\"])\n",
    "    words = []\n",
    "    for i in range(df.shape[0]):\n",
    "        if df.iloc[i,:].TYPE == 'B-PERSON':\n",
    "            words.append(fake.name().split()[0])\n",
    "        elif df.iloc[i,:].TYPE == 'I-PERSON':\n",
    "            words.append(fake.name().split()[-1])\n",
    "        else:\n",
    "            words.append(df.iloc[i,:].Word)\n",
    "    print(len(words))\n",
    "    print(df.shape[0])\n",
    "    df.Word = words\n",
    "    new_filename = f.replace(\".txt\",\"_perturb4.txt\")\n",
    "    for k, v in df.groupby(\"SENT_NO\").groups.items():\n",
    "        temp = df.iloc[v,:]\n",
    "        temp.to_csv(new_filename,mode='a',sep=\"\\t\",index=False,header=False)\n",
    "        with open(new_filename,\"a\") as f:\n",
    "            f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uniform-briefing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
